{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626ea4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle Titanic Dataset - 타이타닉 생존자 예측 프로젝트\n",
    "\n",
    "# 딥러닝 개발 프로세스\n",
    "# Loading the Data\n",
    "# - 데이터셋 다운로드 및 로드\n",
    "# Data Preprocessing(Feature Engineering)\n",
    "# - 주어진 데이터셋의 12개의 feature를 분석한 후에 12개의 feature 와 함께 타이타닉 승객의 생존율에 영향을 미칠 수 있는 새로운 5개 feature 정의\n",
    "# - feature / label 분리 후 딥러닝 학습에 필수적인 표준화(Standadization) 수행\n",
    "# Building Model\n",
    "# - input layer / hidden layer / output layer 로 구성된 인공신경망(ANN) 구축\n",
    "# Training Model\n",
    "# - 평균정확도 80% 나올수 있도록 하이퍼 파라미터를 튜닝하면서 모델 학습 진행\n",
    "# Survival Prediction\n",
    "# - test 데이터로 생존율을 예측(Prediction)하고 결과를 kaggle에 제출(Submit)하여 전 세계 상위 5% 안에 들 수 있는 정확도(Survival Prediction Score) 달성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ead800b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Version :  2.7.1+cu118 , Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리, GPU 설정\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, zipfile, shutil\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('Pytorch Version : ', torch.__version__, ', Device : ', DEVICE)\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e32ac5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\titanic is removed\n"
     ]
    }
   ],
   "source": [
    "# 데이터 폴더 존재시 삭제\n",
    "if os.path.exists('.\\\\data\\\\titanic'):\n",
    "    shutil.rmtree('.\\\\data\\\\titanic')\n",
    "    print('.\\\\data\\\\titanic is removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5bb2321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle titanic dataset 압축풀기\n",
    "with zipfile.ZipFile(file='.\\\\data\\\\titanic.zip') as target_file:\n",
    "    target_file.extractall(path='.\\\\data\\\\titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e011d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train = pd.read_csv('.\\\\data\\\\titanic\\\\train.csv')\n",
    "test = pd.read_csv('.\\\\data\\\\titanic\\\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf370c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "def preprocess_data(df):\n",
    "    # 결측치 처리\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "    df['Fare'] = df['Fare'].fillna(df['Fare'].mean())\n",
    "    \n",
    "    # 범주형 변수 처리\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "    \n",
    "    # 필요한 특성 선택\n",
    "    features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "    return df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea9f21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 데이터셋 클래스\n",
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, features, targets=None):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.targets = torch.FloatTensor(targets) if targets is not None else None\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.targets is not None:\n",
    "            return self.features[idx], self.targets[idx]\n",
    "        return self.features[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ec57da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델 정의\n",
    "class TitanicNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(TitanicNet, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710e4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 및 스케일링\n",
    "X = preprocess_data(train)\n",
    "y = train['Survived'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21797f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 학습/검증 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3644930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 7) (712,)\n",
      "(179, 7) (179,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "375bf999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 및 데이터로더 생성\n",
    "train_dataset = TitanicDataset(X_train, y_train)\n",
    "val_dataset = TitanicDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a0d7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be9efeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = TitanicNet(input_size=X_train.shape[1]).to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d48de10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 0.5822, Validation Accuracy: 0.8101\n",
      "Epoch [20/200], Loss: 0.5944, Validation Accuracy: 0.8268\n",
      "Epoch [30/200], Loss: 0.6718, Validation Accuracy: 0.8045\n",
      "Epoch [40/200], Loss: 0.3529, Validation Accuracy: 0.8101\n",
      "Epoch [50/200], Loss: 0.1885, Validation Accuracy: 0.8156\n",
      "Epoch [60/200], Loss: 0.9046, Validation Accuracy: 0.8156\n",
      "Epoch [70/200], Loss: 0.5334, Validation Accuracy: 0.8156\n",
      "Epoch [80/200], Loss: 0.2497, Validation Accuracy: 0.8212\n",
      "Epoch [90/200], Loss: 0.1719, Validation Accuracy: 0.8101\n",
      "Epoch [100/200], Loss: 0.7826, Validation Accuracy: 0.8101\n",
      "Epoch [110/200], Loss: 0.3600, Validation Accuracy: 0.8101\n",
      "Epoch [120/200], Loss: 0.3784, Validation Accuracy: 0.8156\n",
      "Epoch [130/200], Loss: 0.2306, Validation Accuracy: 0.8101\n",
      "Epoch [140/200], Loss: 0.3575, Validation Accuracy: 0.8156\n",
      "Epoch [150/200], Loss: 0.4106, Validation Accuracy: 0.8101\n",
      "Epoch [160/200], Loss: 0.3173, Validation Accuracy: 0.7989\n",
      "Epoch [170/200], Loss: 0.1499, Validation Accuracy: 0.8101\n",
      "Epoch [180/200], Loss: 0.2748, Validation Accuracy: 0.8101\n",
      "Epoch [190/200], Loss: 1.0965, Validation Accuracy: 0.7989\n",
      "Epoch [200/200], Loss: 0.5541, Validation Accuracy: 0.8101\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for features, targets in train_loader:\n",
    "        features, targets = features.to(DEVICE), targets.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 검증\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for features, targets in val_loader:\n",
    "                features, targets = features.to(DEVICE), targets.to(DEVICE)\n",
    "                outputs = model(features)\n",
    "                predicted = (outputs.squeeze() >= 0.5).float()\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            accuracy = correct / total\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfe7bb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "제출 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 예측\n",
    "test_processed = preprocess_data(test)\n",
    "test_scaled = scaler.transform(test_processed)\n",
    "test_dataset = TitanicDataset(test_scaled)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for features in test_loader:\n",
    "        features = features.to(DEVICE)\n",
    "        outputs = model(features)\n",
    "        predicted = (outputs.squeeze() >= 0.5).float()\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "submission.to_csv('.\\\\data\\\\titanic\\\\submission.csv', index=False)\n",
    "print('\\n제출 파일이 생성되었습니다.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
