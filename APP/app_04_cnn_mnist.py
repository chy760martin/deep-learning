# CNN ëª¨ë¸ MNIST ìˆ«ì ë¶„ë¥˜ê¸° ì›¹ì•± ë°ëª¨
# ì‚¬ìš©ë²• : ./APP> streamlit run app_02_mlp_model.py
# 1. ì‚¬ìš©ì ì…ë ¥ ë°©ì‹
# - í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ë¬´ì‘ìœ„ ì´ë¯¸ì§€ ì„ íƒ
# - ì‚¬ìš©ìê°€ ì§ì ‘ ì´ë¯¸ì§€ ì—…ë¡œë“œ
# - ì‚¬ìš©ìê°€ ì§ì ‘ ê·¸ë¦¬ê¸°
# 2. ëª¨ë¸ ì¶”ë¡ 
# - í•™ìŠµëœ CNN ëª¨ë¸ ë¡œë”© (torch.load)
# - ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í›„ ì˜ˆì¸¡ ìˆ˜í–‰
# 3. ê²°ê³¼ ì‹œê°í™”
# - ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥ (ì •ë‹µ vs ì˜ˆì¸¡)
# - Confusion Matrix ë° ì˜¤ì°¨ ë¶„ì„
# - í‹€ë¦° ì˜ˆì¸¡ ìƒ˜í”Œ ì‹œê°í™”

import streamlit as st
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from sklearn.metrics import confusion_matrix, classification_report
from PIL import Image, ImageOps, ImageEnhance
from streamlit_drawable_canvas import st_canvas
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os

# ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜
# Conv->ReLU->Pool->Dropout ->Conv->ReLU->Pool->Dropout ->FC->ReLU->Dropout ->FC
class CNNModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)        
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)        
        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)        
        self.fc1 = nn.Linear(7 * 7 * 64, 256)
        self.fc2 = nn.Linear(256, 10)
        self.dropout25 = nn.Dropout(p=0.25)
        self.dropout50 = nn.Dropout(p=0.5)
    
    def forward(self, x):
        # conv1, data shape = (H, W, C) = (28, 28, 1)
        x = self.conv1(x) # (28, 28, 1)
        x = torch.relu(x) # (28, 28, 32)
        x = self.pooling(x) # (28, 28, 32)
        x = self.dropout25(x) # (14, 14, 32)
        # conv2
        x = self.conv2(x) # (14, 14, 32)
        x = torch.relu(x) # (14, 14, 64)
        x = self.pooling(x) # (14, 14, 64)
        x = self.dropout25(x) # (7, 7, 64)
        # data shape
        # x = x.view(-1, 7 * 7 * 64) # ê³ ì •ëœ í¬ê¸°ì—ëŠ” ë§ìœ¼ë‚˜ ì…ë ¥ í¬ê¸°ê°€ ë³€ê²½ì‹œ ì˜¤ë¥˜ ë°œìƒ í•  ìˆ˜ ìˆìŒ
        x = x.view(x.size(0), -1) # - x.size(0)ëŠ” í˜„ì¬ ë°°ì¹˜ í¬ê¸°ë¥¼ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ë¯€ë¡œ, ë°°ì¹˜ ì‚¬ì´ì¦ˆê°€ ë°”ë€Œì–´ë„ ì˜¤ë¥˜ ì—†ì´ ì‘ë™, - -1ì€ ë‚˜ë¨¸ì§€ ì°¨ì›ì„ ìë™ìœ¼ë¡œ ê³„ì‚°í•´ì£¼ê¸° ë•Œë¬¸ì— ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°ë‚˜ Conv êµ¬ì¡°ê°€ ë°”ë€Œì–´ë„ ëŒ€ì‘ ê°€ëŠ¥

        # Linear
        x = self.fc1(x)
        x = torch.relu(x)
        x = self.dropout50(x)
        
        x = self.fc2(x)

        return x

# GPU ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ê²½ë¡œ êµ¬ì„±
base_dir = os.path.dirname(__file__)  # í˜„ì¬ íŒŒì¼ ê¸°ì¤€ ë””ë ‰í† ë¦¬
model_path = os.path.join(base_dir, '..', 'models', 'model_cnn_mnist.ckpt')

# ëª¨ë¸ ë¡œë”©
model = CNNModel().to(DEVICE)
model.load_state_dict(torch.load(model_path))
model.eval()

# MNIST í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë”©
transform = transforms.ToTensor()
test_dataset = datasets.MNIST(root='../data/MNIST_data', train=False, transform=transform, download=True)

# Streamlit UI
st.title('CNN MNIST ìˆ«ì ë¶„ë¥˜ê¸° ì›¹ì•±')
st.write("í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ë¬´ì‘ìœ„ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ê±°ë‚˜, ì§ì ‘ ì†ê¸€ì”¨ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ë³´ì„¸ìš”!")

# íƒ­ êµ¬ì„±
# tab1, tab2, tab3 = st.tabs(['í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡', 'ì´ë¯¸ì§€ ì—…ë¡œë“œ', 'ì§ì ‘ ê·¸ë¦¬ê¸°'])
mode = st.selectbox("ëª¨ë“œ ì„ íƒ", ["í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡", "ì´ë¯¸ì§€ ì—…ë¡œë“œ", "ì§ì ‘ ê·¸ë¦¬ê¸°"])


# í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ íƒ­
if mode == "í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡":
    # ë¬´ì‘ìœ„ ì´ë¯¸ì§€ ì„ íƒ
    sample_idx = st.slider('ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ì„ íƒ', 0, len(test_dataset)-1, 0)
    image, label = test_dataset[sample_idx]

    # ëª¨ë¸ ì¶”ë¡ 
    with torch.no_grad(): # ë¯¸ë¶„ ì—°ì‚°í•˜ì§€ ì•ŠìŒ
        # input_tensor = image.view(-1, 28 * 28).to(DEVICE) # MLP ëª¨ë¸ í˜•íƒœ
        # input_tensor = image.view(-1, 1, 28, 28).to(DEVICE) # CNN ëª¨ë¸ í˜•íƒœ
        input_tensor = image.unsqueeze(0).to(DEVICE) # - image.unsqueeze(0)ëŠ” ì°¨ì› ìƒì„±
        output = model(input_tensor)
        pred = torch.argmax(output, dim=1).item()
        
    # ì‹œê°í™”
    st.image(image.squeeze().numpy(), caption=f'ì‹¤ì œ ë¼ë²¨: {label}, ì˜ˆì¸¡: {pred}', width=150, channels='GRAY')

    # Confusion Matrix ë²„íŠ¼
    if st.button('ì „ì²´ Confusion Matrix ë³´ê¸°'):
        all_preds = []
        all_labels = []
        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

        with torch.no_grad():
            for imgs, labels in test_loader:
                x = imgs.to(DEVICE) # ì´ë¯¸ [batch, 1, 28, 28] í˜•íƒœë¥¼ ê°–ì¶”ê³  ìˆìŒ
                y = labels.to(DEVICE) # ì •ë‹µë°ì´í„°

                outputs = model(x) # ëª¨ë¸ ì˜ˆì¸¡
                _, preds = torch.max(outputs, 1) # ëª¨ë¸ ì˜ˆì¸¡ ê°’ ì¶”ì¶œ

                all_preds.extend(preds.cpu().numpy()) # GPU í…ì„œë¥¼ CPUë¡œ ì˜®ê¸°ê³  ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜
                all_labels.extend(y.cpu().numpy())
        
        cm = confusion_matrix(all_labels, all_preds)
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
        st.pyplot(fig)

        st.text('Classification Report:')
        st.text(classification_report(all_labels, all_preds, digits=4))

# ì´ë¯¸ì§€ ì—…ë¡œë“œ íƒ­
elif mode == "ì´ë¯¸ì§€ ì—…ë¡œë“œ":
    uploaded_file = st.file_uploader('ì†ê¸€ì”¨ ìˆ«ì ì´ë¯¸ì§€ ì—…ë¡œë“œ (PNG/JPG)', type=['png', 'jpg', 'jpeg'])
    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert('L') # í‘ë°± ë³€í™˜
        image = ImageOps.invert(image) # MNIST ìŠ¤íƒ€ì¼ ë°˜ì „
        image = image.resize( (28, 28) ) # MNIST í¬ê¸°ë¡œ ì¡°ì •

        st.image(image, caption='ì—…ë¡œë“œ ì´ë¯¸ì§€', width=150)

        transform = transforms.Compose([
            transforms.ToTensor(), # 0~255 ì´ë¯¸ì§€ ê°’ì„ 0~1 ì‚¬ì´ê°’ì„ ë³€í™˜
            transforms.Normalize((0.1307,), (0.3081,)) # ì •ê·œí™”
        ])
        # input_tensor = transform(image).view(-1, 28 * 28).to(DEVICE)
        # input_tensor = transform(image).view(-1, 1, 28, 28).to(DEVICE) # CNN ëª¨ë¸ í˜•íƒœ
        input_tensor = transform(image).unsqueeze(0).to(DEVICE) # [1, 1, 28, 28] image.unsqueeze(0)ëŠ” ì°¨ì› ìƒì„±

        with torch.no_grad(): # ë¯¸ë¶„ ì—°ì‚°í•˜ì§€ ì•ŠìŒ
            output = model(input_tensor) # ëª¨ë¸ ì˜ˆì¸¡
            pred = torch.argmax(output, dim=1).item() # ëª¨ë¸ ì˜ˆì¸¡ê°’ ì¶”ì¶œ
        
        st.success(f'ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼: {pred}')


# ì§ì ‘ ê·¸ë¦¬ê¸° íƒ­
elif mode == "ì§ì ‘ ê·¸ë¦¬ê¸°":
    st.write("ğŸ–Œï¸ ì•„ë˜ ìº”ë²„ìŠ¤ì— ìˆ«ìë¥¼ ì§ì ‘ ê·¸ë ¤ë³´ì„¸ìš”")

    canvas_result = st_canvas(
        fill_color="white",
        stroke_width=10,
        stroke_color="black",
        background_color="white",
        height=280,
        width=280,
        drawing_mode="freedraw",
        key="canvas_test",
        update_streamlit=True
    )

    if canvas_result.image_data is not None:
        image_data = canvas_result.image_data

        def center_image(img):
            img = np.array(img)
            coords = np.column_stack(np.where(img > 0))
            if coords.size == 0:
                return Image.fromarray(img)
            y_min, x_min = coords.min(axis=0)
            y_max, x_max = coords.max(axis=0)
            cropped = img[y_min:y_max+1, x_min:x_max+1]
            canvas = np.zeros((28, 28), dtype=np.uint8)
            h, w = cropped.shape
            y_offset = (28 - h) // 2
            x_offset = (28 - w) // 2
            canvas[y_offset:y_offset+h, x_offset:x_offset+w] = cropped
            return Image.fromarray(canvas)

        if np.std(image_data) < 1:
            st.warning("ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¬ë¯¸í•˜ê±°ë‚˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìˆ«ìë¥¼ êµµê²Œ ê·¸ë ¤ì£¼ì„¸ìš”.")
        else:
            image = Image.fromarray((image_data[:, :, :3]).astype('uint8')).convert('L')
            image = ImageOps.invert(image)
            image = image.resize((28, 28))
            image = center_image(image)

            st.image(image, caption='ê·¸ë¦° ìˆ«ì', width=150)

            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((0.1307,), (0.3081,))
            ])
            # input_tensor = transform(image).view(-1, 28 * 28)
            # input_tensor = transform(image).view(-1, 1, 28, 28).to(DEVICE) # CNN ëª¨ë¸ í˜•íƒœ
            input_tensor = transform(image).unsqueeze(0).to(DEVICE) # [1, 1, 28, 28]

            # ëª¨ë¸ ì¶”ë¡  (ëª¨ë¸ì€ ë¯¸ë¦¬ ë¡œë”©ë˜ì–´ ìˆì–´ì•¼ í•¨)
            with torch.no_grad():
                # outputì€ ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥ í…ì„œ, ë³´í†µ shapeì€ [1, 10](ìˆ«ì 0~9ì— ëŒ€í•œ ë¡œì§“ ê°’)
                output = model(input_tensor)
                # pred = torch.argmax(output, dim=1).item()
                # softmax()ë¥¼ í†µí•´ ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥ ë¡œ ë³€í™˜, squeeze()ëŠ” ë°°ì¹˜ ì°¨ì›ì„ ì œê±°í•´ 1D ë°°ì—´ë¡œ ë§Œë“ ë‹¤, numpy()ëŠ” ë„˜íŒŒì´ ë°ì´í„°ë¡œ ë§Œë“ ë‹¤.
                # .squeeze()ëŠ” ë¶ˆí•„ìš”í•œ ì°¨ì›ì„ ì œê±° [1, 10] -> [10]ìœ¼ë¡œ ë°”ê¿”ì„œ 1D ë°°ì—´ë¡œ ë§Œë“ ë‹¤.
                probabilities = torch.nn.functional.softmax(output, dim=1).squeeze().cpu().numpy()
                pred = int(np.argmax(probabilities))

            st.success(f'ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼: {pred}')
            st.markdown(f"### âœï¸ ëª¨ë¸ì´ ì¸ì‹í•œ ìˆ«ì: `{pred}`")

            # ì˜ˆì¸¡ í™•ë¥  ë§‰ëŒ€ê·¸ë˜í”„
            fig, ax = plt.subplots()
            ax.bar(range(10), probabilities, color='skyblue')
            ax.set_xticks(range(10))
            ax.set_xlabel('Num Class')
            ax.set_ylabel('Prediction')
            ax.set_title('Model Prediction')

            st.pyplot(fig)