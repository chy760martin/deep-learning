# MNIST ìˆ«ì ë¶„ë¥˜ê¸° ì›¹ì•± ë°ëª¨
# ì‚¬ìš©ë²• : ./APP> streamlit run app_02_mlp_model.py
# 1. ì‚¬ìš©ì ì…ë ¥ ë°©ì‹
# - í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ë¬´ì‘ìœ„ ì´ë¯¸ì§€ ì„ íƒ
# - ì‚¬ìš©ìê°€ ì§ì ‘ ì´ë¯¸ì§€ ì—…ë¡œë“œ
# 2. ëª¨ë¸ ì¶”ë¡ 
# - í•™ìŠµëœ MLP ëª¨ë¸ ë¡œë”© (torch.load)
# - ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í›„ ì˜ˆì¸¡ ìˆ˜í–‰
# 3. ê²°ê³¼ ì‹œê°í™”
# - ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥ (ì •ë‹µ vs ì˜ˆì¸¡)
# - Confusion Matrix ë° ì˜¤ì°¨ ë¶„ì„
# - í‹€ë¦° ì˜ˆì¸¡ ìƒ˜í”Œ ì‹œê°í™”

import streamlit as st
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from sklearn.metrics import confusion_matrix, classification_report
from PIL import Image, ImageOps, ImageEnhance
from streamlit_drawable_canvas import st_canvas
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜
class MLPDeepLearningModel(nn.Module):
    # model ì •ì˜ - ì•„í‚¤í…ì²˜ë¥¼ êµ¬ì„±í•˜ëŠ” ë‹¤ì–‘í•œ ê³„ì¸µ(layer)ì„ ì •ì˜
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(784, 256)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.3)
        self.fc2 = nn.Linear(256, 10)
    
    def forward(self, x):
        x = self.flatten(x) # ì…ë ¥ì¸µ
        x = self.fc1(x) # ì€ë‹‰ì¸µ
        x = self.relu(x) # í™œì„±í™”í•¨ìˆ˜ ReLU(ë¹„ì„ í˜•í•¨ìˆ˜)
        x = self.dropout(x) # overfitting ë°©ì§€
        x = self.fc2(x) # ì¶œë ¥ì¸µ
        return x

# GPU ì„¤ì •
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ëª¨ë¸ ë¡œë”©
model = MLPDeepLearningModel().to(DEVICE)
model.load_state_dict(torch.load('../models/model_mlp_mnist.ckpt'))
model.eval()

# MNIST í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë”©
transform = transforms.ToTensor()
test_dataset = datasets.MNIST(root='../data/MNIST_data', train=False, transform=transform, download=True)

# Streamlit UI
st.title('MNIST ìˆ«ì ë¶„ë¥˜ê¸° ì›¹ì•±')
st.write("í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ë¬´ì‘ìœ„ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ê±°ë‚˜, ì§ì ‘ ì†ê¸€ì”¨ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ë³´ì„¸ìš”!")

# íƒ­ êµ¬ì„±
# tab1, tab2, tab3 = st.tabs(['í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡', 'ì´ë¯¸ì§€ ì—…ë¡œë“œ', 'ì§ì ‘ ê·¸ë¦¬ê¸°'])
mode = st.selectbox("ëª¨ë“œ ì„ íƒ", ["í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡", "ì´ë¯¸ì§€ ì—…ë¡œë“œ", "ì§ì ‘ ê·¸ë¦¬ê¸°"])


# í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ íƒ­
if mode == "í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡":
    # ë¬´ì‘ìœ„ ì´ë¯¸ì§€ ì„ íƒ
    sample_idx = st.slider('ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ì„ íƒ', 0, len(test_dataset)-1, 0)
    image, label = test_dataset[sample_idx]

    # ëª¨ë¸ ì¶”ë¡ 
    with torch.no_grad(): # ë¯¸ë¶„ ì—°ì‚°í•˜ì§€ ì•ŠìŒ
        input_tensor = image.view(-1, 28 * 28).to(DEVICE)
        output = model(input_tensor)
        pred = torch.argmax(output, dim=1).item()
        
    # ì‹œê°í™”
    st.image(image.squeeze().numpy(), caption=f'ì‹¤ì œ ë¼ë²¨: {label}, ì˜ˆì¸¡: {pred}', width=150, channels='GRAY')

    # Confusion Matrix ë²„íŠ¼
    if st.button('ì „ì²´ Confusion Matrix ë³´ê¸°'):
        all_preds = []
        all_labels = []
        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

        with torch.no_grad():
            for imgs, labels in test_loader:
                x = imgs.view(-1, 28 * 28).to(DEVICE) # í•™ìŠµë°ì´í„°
                y = labels.to(DEVICE) # ì •ë‹µë°ì´í„°

                outputs = model(x) # ëª¨ë¸ ì˜ˆì¸¡
                _, preds = torch.max(outputs, 1) # ëª¨ë¸ ì˜ˆì¸¡ ê°’ ì¶”ì¶œ

                all_preds.extend(preds.cpu().numpy()) # GPU í…ì„œë¥¼ CPUë¡œ ì˜®ê¸°ê³  ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜
                all_labels.extend(y.cpu().numpy())
        
        cm = confusion_matrix(all_labels, all_preds)
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
        st.pyplot(fig)

        st.text('Classification Report:')
        st.text(classification_report(all_labels, all_preds, digits=4))

# ì´ë¯¸ì§€ ì—…ë¡œë“œ íƒ­
elif mode == "ì´ë¯¸ì§€ ì—…ë¡œë“œ":
    uploaded_file = st.file_uploader('ì†ê¸€ì”¨ ìˆ«ì ì´ë¯¸ì§€ ì—…ë¡œë“œ (PNG/JPG)', type=['png', 'jpg', 'jpeg'])
    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert('L') # í‘ë°± ë³€í™˜
        image = ImageOps.invert(image) # MNIST ìŠ¤íƒ€ì¼ ë°˜ì „
        image = image.resize( (28, 28) ) # MNIST í¬ê¸°ë¡œ ì¡°ì •

        st.image(image, caption='ì—…ë¡œë“œ ì´ë¯¸ì§€', width=150)

        transform = transforms.Compose([
            transforms.ToTensor(), # 0~255 ì´ë¯¸ì§€ ê°’ì„ 0~1 ì‚¬ì´ê°’ì„ ë³€í™˜
            transforms.Normalize((0.1307,), (0.3081,)) # ì •ê·œí™”
        ])
        input_tensor = transform(image).view(-1, 28 * 28).to(DEVICE)

        with torch.no_grad(): # ë¯¸ë¶„ ì—°ì‚°í•˜ì§€ ì•ŠìŒ
            output = model(input_tensor) # ëª¨ë¸ ì˜ˆì¸¡
            pred = torch.argmax(output, dim=1).item() # ëª¨ë¸ ì˜ˆì¸¡ê°’ ì¶”ì¶œ
        
        st.success(f'ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼: {pred}')

# ì§ì ‘ ê·¸ë¦¬ê¸° íƒ­
elif mode == "ì§ì ‘ ê·¸ë¦¬ê¸°":
    st.write("ğŸ–Œï¸ ì•„ë˜ ìº”ë²„ìŠ¤ì— ìˆ«ìë¥¼ ì§ì ‘ ê·¸ë ¤ë³´ì„¸ìš”")

    canvas_result = st_canvas(
        fill_color="white",
        stroke_width=10,
        stroke_color="black",
        background_color="white",
        height=280,
        width=280,
        drawing_mode="freedraw",
        key="canvas_test",
        update_streamlit=True
    )

    if canvas_result.image_data is not None:
        image_data = canvas_result.image_data

        if np.std(image_data) < 1:
            st.warning("ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¬ë¯¸í•˜ê±°ë‚˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìˆ«ìë¥¼ êµµê²Œ ê·¸ë ¤ì£¼ì„¸ìš”.")
        else:
            image = Image.fromarray((image_data[:, :, :3]).astype('uint8')).convert('L')
            image = ImageOps.invert(image)
            image = image.resize((28, 28))

            st.image(image, caption='ê·¸ë¦° ìˆ«ì', width=150)

            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((0.1307,), (0.3081,))
            ])
            input_tensor = transform(image).view(-1, 28 * 28)

            # ëª¨ë¸ ì¶”ë¡  (ëª¨ë¸ì€ ë¯¸ë¦¬ ë¡œë”©ë˜ì–´ ìˆì–´ì•¼ í•¨)
            with torch.no_grad():
                output = model(input_tensor)
                pred = torch.argmax(output, dim=1).item()

            st.success(f'ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼: {pred}')