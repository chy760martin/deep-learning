{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "765acad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer 다국어 기계 번역 모델 & 파인 튜닝 \n",
    "# - Hugging Face 라이브러리 적용\n",
    "# - AI HUB 금융 공시 정보 다국어 번역 데이터셋 적용\n",
    "# - 입력된 문장을 다국어 기계 번역 모델을 통한 영어->한국어, 한국어->번역\n",
    "# 1. 학습 목표\n",
    "# - 구조 최적화 및 파이프라인 단순화\n",
    "# - AI HUB 금융 공시 정보 다국어 번역 데이터셋 전처리\n",
    "# - 병렬 문장쌍 데이터셋 변환 전처리\n",
    "# - 토크나이징 및 토크나이징 전처리\n",
    "# - 베이스 모델 로드\n",
    "# - LoRA(Low-Rank Adaptation) 설정, 특정 레이어에 작은 저차원 행렬(랭크 r)을 삽입해서 학습\n",
    "# - LoRA(Low-Rank Adaptation) 모델, 메모리 효율성/빠른 학습/도메인 적용, base 모델에 여러 LoRA 모듈을 붙였다 떼었다 할 수 있음\n",
    "# - 학습 args 설정\n",
    "# - Trainer 정의\n",
    "# - Trainer 실행\n",
    "# - LoRA 적용된 모델 저장, LoRA모델/토크나이저\n",
    "# - LoRA 적용된 모델 불러오기, 베이스모델/LoRA모델/토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bf0361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0 cpu\n",
      "CUDA 사용 가능 여부: False\n",
      "PyTorch CUDA 버전: None\n",
      "빌드 정보: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm as notebook_tqdm\n",
    "import numpy as np\n",
    "import glob, json, re, os, random, csv, zipfile\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(torch.__version__, device)\n",
    "\n",
    "print(\"CUDA 사용 가능 여부:\", torch.cuda.is_available())\n",
    "print(\"PyTorch CUDA 버전:\", torch.version.cuda)\n",
    "print(\"빌드 정보:\", torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"사용 중인 GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e21569f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "압축 해제 완료: ./llm_data/ai_hub_disclosure\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 전처리 - AI HUB 금융 공시 정보 다국어 번역 데이터셋\n",
    "zip_path = './llm_data/TL_5. 공시정보_1. 영어.zip'\n",
    "extract_dir = './llm_data/ai_hub_disclosure'\n",
    "\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# 압축 풀기\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print('압축 해제 완료:', extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49046719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 문장쌍 개수: 80005, 80005\n",
      "7회차 전환사채의 경우, 조정가액 적용일이 6월 26일이었으나 비영업일이었던 관계로 당일(6월 28일)을 적용일로 기재하였습니다.\n",
      "For the 7th convertible bond, the adjustment date was June 26th. However, as it was a non-business day, the application date was recorded as the following day, June 28th.\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 전처리 - AI HUB 금융 공시 정보 다국어 번역 데이터셋\n",
    "ko_lines, en_lines = [], []\n",
    "folders = [ # 폴더 리스트 정의\n",
    "    './llm_data/ai_hub_disclosure/*.json'\n",
    "]\n",
    "\n",
    "# 모든 JSON 읽기\n",
    "for folder in folders:\n",
    "    for path in glob.glob(folder): # 특정 디렉토리에서 지정한 패턴과 일치하는 모든 파일 경로를 리스트로 반환\n",
    "        with open(path, encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f) # 파일 전체 로드(dict 구조)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "            # sents 리스트에서 문장쌍 추출\n",
    "            for sent in data.get('sents', []):\n",
    "                en = sent.get('mtpe') # 원문(영어)\n",
    "                ko = sent.get('source_cleaned') # 최종번역문(한국어) 추출\n",
    "\n",
    "                if en and ko and ko != 'N/A':\n",
    "                    en_lines.append(en.strip())\n",
    "                    ko_lines.append(ko.strip())\n",
    "\n",
    "# 1. Detokenize 함수 정의\n",
    "def detokenize_sentence(sentence: str) -> str:\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub(r\"\\s+([?.!,])\", r\"\\1\", sentence)  # \" ?\" → \"?\"\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)            # 여러 공백 → 하나\n",
    "    return sentence\n",
    "\n",
    "# 2. 데이터셋 전처리\n",
    "en_lines = [detokenize_sentence(s) for s in en_lines]\n",
    "ko_lines = [detokenize_sentence(s) for s in ko_lines]\n",
    "\n",
    "\n",
    "print(f'총 문장쌍 개수: {len(ko_lines)}, {len(en_lines)}')\n",
    "print(ko_lines[0])\n",
    "print(en_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "879c0f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 문장쌍 개수: 79991, 79991\n",
      "7회차 전환사채의 경우, 조정가액 적용일이 6월 26일이었으나 비영업일이었던 관계로 당일(6월 28일)을 적용일로 기재하였습니다.\n",
      "For the 7th convertible bond, the adjustment date was June 26th. However, as it was a non-business day, the application date was recorded as the following day, June 28th.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 - 중복 제거 및 순서 유지\n",
    "# pairs = list(set(zip(en_lines, ko_lines)))\n",
    "# en_lines, ko_lines = zip(*pairs) # 다시 분리\n",
    "seen = set()\n",
    "pairs = []\n",
    "for en, ko in zip(en_lines, ko_lines):\n",
    "    if (en, ko) not in seen:\n",
    "        # 새로운 문장쌍을 집합에 기록, 이후 같은 문장쌍이 나오면 if 조건에서 걸러져 추가되지 않는다\n",
    "        seen.add( (en, ko) )\n",
    "        \n",
    "        # 중복이 아닌 문장쌍을 리스트에 추가, 원래 순서대로 중복 없는 문장쌍 리스트가 만들어 진다\n",
    "        # - pairs는 [(\"Hello\",\"안녕\"), (\"Goodbye\",\"잘가\")] \n",
    "        pairs.append( (en, ko) )\n",
    "\n",
    "# 이를 다시 분리 - 영어 문장들만 모아 (\"Hello\",\"Goodbye\"), 한국어 문장들만 모아 (\"안녕\",\"잘가\")\n",
    "en_lines, ko_lines = zip(*pairs)\n",
    "\n",
    "print(f'중복 제거 후 문장쌍 개수: {len(ko_lines)}, {len(en_lines)}')\n",
    "print(ko_lines[0])\n",
    "print(en_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc2927c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플링 후 문장쌍 개수: 79991, 79991\n",
      "7회차 전환사채의 경우, 조정가액 적용일이 6월 26일이었으나 비영업일이었던 관계로 당일(6월 28일)을 적용일로 기재하였습니다.\n",
      "For the 7th convertible bond, the adjustment date was June 26th. However, as it was a non-business day, the application date was recorded as the following day, June 28th.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 - 샘플링 추가\n",
    "\n",
    "# 샘플링 최대 50,000 문장만 사용\n",
    "# sample_size = 50000\n",
    "sample_size = len(en_lines)\n",
    "if len(ko_lines) > sample_size:\n",
    "    indices = random.sample(range(len(ko_lines)), sample_size)\n",
    "    ko_lines = [ ko_lines[i] for i in indices ]\n",
    "    en_lines = [ en_lines[i] for i in indices ]\n",
    "\n",
    "print(f'샘플링 후 문장쌍 개수: {len(ko_lines)}, {len(en_lines)}')\n",
    "print(ko_lines[0])\n",
    "print(en_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "756e86f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴더 생성 완료: ./llm_data/ai_hub_disclosure_translation\n",
      "저장 완료 ./llm_data/ai_hub_disclosure_translation/train_ko.txt ./llm_data/ai_hub_disclosure_translation/train_en.txt\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 - 저장\n",
    "out_dir = './llm_data/ai_hub_disclosure_translation'\n",
    "\n",
    "# 폴더 없을시 생성\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    print(f'폴더 생성 완료: {out_dir}')\n",
    "else:\n",
    "    print(f'이미 존재하는 폴더: {out_dir}')\n",
    "\n",
    "ko_path = f'{out_dir}/train_ko.txt'\n",
    "en_path = f'{out_dir}/train_en.txt'\n",
    "\n",
    "with open(ko_path, 'w', encoding='utf-8') as fko, \\\n",
    "    open(en_path, 'w', encoding='utf-8') as fen:\n",
    "    for k, e in zip(ko_lines, en_lines):\n",
    "        fko.write(k + '\\n')\n",
    "        fen.write(e + '\\n')\n",
    "print('저장 완료', ko_path, en_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55675c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martin/AI/deep-learning/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/martin/AI/deep-learning/env/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/martin/AI/deep-learning/env/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <9B280146-BBD7-3F77-9873-F9740F2A5329> /Users/martin/AI/deep-learning/env/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <078DF3B7-D63C-3CEF-94C1-C063C5E5A468> /Users/martin/AI/deep-learning/env/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# AI Hub 금융 공시 정보 데이터셋(train_ko.txt, train_en.txt) -> CSV로 변환해 파인 튜닝\n",
    "# 원본 데이터는 train_ko.txt, train_en.txt로 분리 -> 병렬 문장쌍을 만들어야 함\n",
    "# 파인튜닝시 양방향 번역을 지원하려면 같은 문장쌍은 en->ko, ko->en 두방향으로 모두 포함해야 함\n",
    "# CSV 구조 예시\n",
    "# - src,tgt,src_lang,tgt_lang\n",
    "# - You can buy it from a convenience store try it out.,편의점에서 사실 수 있으니 시도해보시길 바랍니다.,en,ko\n",
    "# - 편의점에서 사실 수 있으니 시도해보시길 바랍니다.,You can buy it from a convenience store try it out.,ko,en\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# 전체 데이터 로드 - AI Hub 금융 공시 정보 데이터셋(train_ko.txt, train_en.txt)\n",
    "with open('./llm_data/ai_hub_disclosure_translation/train_en.txt', 'r', encoding='utf-8') as f_en, \\\n",
    "    open('./llm_data/ai_hub_disclosure_translation/train_ko.txt', 'r', encoding='utf-8') as f_ko:\n",
    "    en_lines = f_en.read().splitlines()\n",
    "    ko_lines = f_ko.read().splitlines()\n",
    "\n",
    "# 데이터 개수 제한 (예: 100개)\n",
    "limit = 500\n",
    "en_lines = en_lines[:limit]\n",
    "ko_lines = ko_lines[:limit]\n",
    "\n",
    "# train/valid split(90 : 10)\n",
    "split_idx = int(len(en_lines) * 0.9)\n",
    "train_en, valid_en = en_lines[:split_idx], en_lines[split_idx:]\n",
    "train_ko, valid_ko = ko_lines[:split_idx], ko_lines[split_idx:]\n",
    "\n",
    "print(len(train_en))\n",
    "print(len(valid_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efef8f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 7th convertible bond, the adjustment date was June 26th. However, as it was a non-business day, the application date was recorded as the following day, June 28th.\n",
      "7회차 전환사채의 경우, 조정가액 적용일이 6월 26일이었으나 비영업일이었던 관계로 당일(6월 28일)을 적용일로 기재하였습니다.\n"
     ]
    }
   ],
   "source": [
    "# 병렬 데이터 생성 - 편향되지 않은 데이터셋 생성\n",
    "# 영어->한국어, 한국어->영어\n",
    "\n",
    "# train.csv 생성\n",
    "with open('./llm_data/ai_hub_disclosure_translation/train.csv', 'w', encoding='utf-8', newline='') as f_out:\n",
    "    writer = csv.writer(f_out)\n",
    "    writer.writerow(['src', 'tgt', 'src_lang', 'tgt_lang'])\n",
    "\n",
    "    print(train_en[0])\n",
    "    print(train_ko[0])\n",
    "    for en, ko in zip(train_en, train_ko):\n",
    "        en, ko = en.strip(), ko.strip()\n",
    "        if not en or not ko:\n",
    "            continue\n",
    "\n",
    "        # 영어 -> 한국어\n",
    "        writer.writerow([en, ko, 'en', 'ko'])\n",
    "        # 한국어 -> 영어\n",
    "        writer.writerow([ko, en, 'ko', 'en'])\n",
    "\n",
    "# valid.csv 생성\n",
    "with open('./llm_data/ai_hub_disclosure_translation/valid.csv', 'w', encoding='utf-8', newline='') as f_out:\n",
    "    writer = csv.writer(f_out)\n",
    "    writer.writerow(['src', 'tgt', 'src_lang', 'tgt_lang'])\n",
    "\n",
    "    for en, ko in zip(valid_en, valid_ko):\n",
    "        en, ko = en.strip(), ko.strip()\n",
    "        if not en or not ko:\n",
    "            continue\n",
    "        \n",
    "        # 영어 -> 한국어\n",
    "        writer.writerow([en, ko, 'en', 'ko'])\n",
    "        # 한국어 -> 영어\n",
    "        writer.writerow([ko, en, 'ko', 'en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420188a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 전처리\n",
    "from datasets import load_dataset # Hugging Face의 데이터셋 관리 라이브러리(학습용 데이터 로딩에 사용)\n",
    "# M2M100 모델과 토크나이저, 학습 관련 유틸리티 제공\n",
    "from transformers import M2M100Tokenizer, M2M100ForConditionalGeneration, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model # LoRA 설정을 위한 라이브러리(모델 파라미터 효율적 파인튜닝)\n",
    "\n",
    "# 1. tokenizer 로드, Hugging Face M2M100-418M 모델의 토크나이저 로드\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "# 2. 전처리 함수 (동적 tgt_lang 설정)\n",
    "def preprocess_function(examples):\n",
    "    # 데이터셋에서 src(원문), tgt(번역문), tgt_lang(목표 언어 코드) 가져옴\n",
    "    inputs = examples[\"src\"]\n",
    "    targets = examples[\"tgt\"]\n",
    "    tgt_langs = examples[\"tgt_lang\"]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, # src(원문)을 토큰화\n",
    "        max_length=128,  # 최대 길이 128\n",
    "        truncation=True, # 최대 길이 초과시 잘라냄\n",
    "        padding=\"max_length\" # 길이가 부족하면 padding 처리\n",
    "    )\n",
    "\n",
    "    labels_list = []\n",
    "    for text, lang in zip(targets, tgt_langs):\n",
    "        # 각 문장마디 목표 언어(tgt_lang)\n",
    "        if lang in tokenizer.lang_code_to_id:\n",
    "            tokenizer.tgt_lang = lang\n",
    "        else:\n",
    "            tokenizer.tgt_lang = \"en\"  # 기본값\n",
    "        \n",
    "        # 타겟 문장 토큰화\n",
    "        with tokenizer.as_target_tokenizer(): # 번역 대상 문장을 토큰화할때 사용하는 모드\n",
    "            labels = tokenizer(\n",
    "                text, # tgt(번역문)\n",
    "                max_length=128, \n",
    "                truncation=True, \n",
    "                padding=\"max_length\"\n",
    "            )\n",
    "        \n",
    "        # labels[\"input_ids\"]를 추출해서 학습용 정답(label)로 저장\n",
    "        labels_list.append(labels[\"input_ids\"])\n",
    "\n",
    "    # 입력(src)와 정답(tgt)을 모두 포함한 딕셔너리 반환, Trainer가 이 반환값을 받아서 학습에 사용\n",
    "    # {\n",
    "    #     \"input_ids\": [...],        # 원문 토큰 시퀀스\n",
    "    #     \"attention_mask\": [...],   # 패딩 여부 표시\n",
    "    #     \"labels\": [...]            # 번역문 토큰 시퀀스\n",
    "    # }\n",
    "    model_inputs[\"labels\"] = labels_list\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fd609d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 900 examples [00:00, 14405.99 examples/s]\n",
      "Generating validation split: 100 examples [00:00, 13920.23 examples/s]\n",
      "Map:   0%|          | 0/900 [00:00<?, ? examples/s]/Users/martin/AI/deep-learning/env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 900/900 [00:01<00:00, 858.93 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 750.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 불러오기\n",
    "dataset = load_dataset( # Hugging Face datasets 라이브러리를 사용해 CSV 파일을 로드\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        \"train\": \"./llm_data/ai_hub_disclosure_translation/train.csv\",\n",
    "        \"validation\": \"./llm_data/ai_hub_disclosure_translation/valid.csv\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 토크나이즈 적용\n",
    "# - 결과: 각 샘플이 {\"input_ids\": ..., \"attention_mask\": ..., \"labels\": ...} \n",
    "tokenized_dataset = dataset.map( # map() 함수로 앞서 정의한 preprocess_function을 데이터셋 전체에 적용\n",
    "    preprocess_function, \n",
    "    batched=True # 여러 샘플을 한번에 처리하여 속도 향상\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817f345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "\n",
    "# pretrained model M2M100_418M 로드, 베이스 모델로 사용\n",
    "base_model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "# LoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    r=8,              # 랭크 크기(저차원 행렬 크기), 작을수록 가볍고 빠르지만 표현력이 줄어듬\n",
    "    lora_alpha=32,    # 스케일링 계수, 학습된 LoRA 행렬을 원래 모델에 얼마나 반영할지 결정하는 스케일\n",
    "    lora_dropout=0.1, # 드롭아웃\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]  # Attention 모듈에 적용, Query/Value 저차원 행렬만 학습\n",
    ")\n",
    "\n",
    "# LoRA 모델 생성, PEFT(Param-Efficient Fine-Tuning) 모델 생성\n",
    "model = get_peft_model(base_model, lora_config) # 전체 모델 파라미터는 그대로 두고 LoRA 모듈만 학습 대상이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4780be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llm_models/results_lora_ai_hub_disclosure\",    # 학습 결과(모델, 체크포인트) 저장 경로\n",
    "    eval_strategy=\"epoch\",          # 구버전, 매 epoch마다 평가\n",
    "    learning_rate=2e-4,             # 학습률 2e-5 - 5e-5\n",
    "    per_device_train_batch_size=16, # 학습 배치 크기\n",
    "    per_device_eval_batch_size=16,  # 평가 배치 크기\n",
    "    num_train_epochs=3,             # 학습 epoch 수\n",
    "    weight_decay=0.01,              # 가중치 감쇠(정규화)\n",
    "    save_total_limit=2,             # 체크포인트 최대 저장 개수\n",
    "    logging_dir=\"./llm_models/results_lora_logs_ai_hub_disclosure\",           # 로그 저장 경로\n",
    "    logging_steps=100,              # 100 step마다 로그 기록\n",
    ")\n",
    "\n",
    "# Trainer 정의\n",
    "trainer = Trainer(\n",
    "    model=model,        # LoRA 적용된 모델\n",
    "    args=training_args, # 학습 설정\n",
    "    train_dataset=tokenized_dataset[\"train\"],       # 학습 데이터셋\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],   # 평가 데이터셋\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca31c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 37/171 42:10 < 2:41:29, 0.01 it/s, Epoch 0.63/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 실행\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3218a337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN→KO: 그것은 문자 그대로 삶의 기초입니다.\n",
      "KO→EN: It is literally the basis of life.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 영어 → 한국어\n",
    "text = \"It is literally the basis of life.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)   # 입력도 GPU로 이동\n",
    "forced_bos_token_id = tokenizer.lang_code_to_id[\"ko\"]\n",
    "outputs = model.generate(**inputs, forced_bos_token_id=forced_bos_token_id)\n",
    "print(\"EN→KO:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "# 한국어 → 영어\n",
    "text = \"말 그대로 삶의 기초입니다.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)   # 입력도 GPU로 이동\n",
    "forced_bos_token_id = tokenizer.lang_code_to_id[\"en\"]\n",
    "outputs = model.generate(**inputs, forced_bos_token_id=forced_bos_token_id)\n",
    "print(\"KO→EN:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40cb8db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./llm_models/translation_model_ai_hub_disclosure/tokenizer_config.json',\n",
       " './llm_models/translation_model_ai_hub_disclosure/special_tokens_map.json',\n",
       " 'llm_models/translation_model_ai_hub_disclosure/vocab.json',\n",
       " 'llm_models/translation_model_ai_hub_disclosure/sentencepiece.bpe.model',\n",
       " './llm_models/translation_model_ai_hub_disclosure/added_tokens.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LoRA 적용된 모델 저장\n",
    "model.save_pretrained(\"./llm_models/translation_model_ai_hub_disclosure\")\n",
    "tokenizer.save_pretrained(\"./llm_models/translation_model_ai_hub_disclosure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f98cc413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import M2M100Tokenizer, M2M100ForConditionalGeneration\n",
    "from peft import PeftModel\n",
    "\n",
    "# 원본 M2M100 모델 로드\n",
    "base_model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "# LoRA 어댑터 붙여서 불러오기\n",
    "model = PeftModel.from_pretrained(base_model, \"./llm_models/translation_model_ai_hub_disclosure\")\n",
    "\n",
    "# 토크나이저도 불러오기\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"./llm_models/translation_model_ai_hub_disclosure\")\n",
    "\n",
    "# 디바이스 맞추기\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48403b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN→KO:\n",
      "The central bank decided to keep interest rates unchanged to stabilize market expectations. → 중앙은행은 시장 기대를 안정화하기 위해 금리를 변함없이 유지하기로 결정했다.\n",
      "Major banks reported a decline in quarterly profits due to rising credit risks. → 주요 은행들은 신용 위험 증가로 인해 분기 수익이 줄어들었다고 보고했다.\n",
      "The government introduced new fiscal policies to stimulate domestic consumption. → 정부는 국내 소비를 촉진하기 위해 새로운 세금 정책을 도입했습니다.\n",
      "Stock markets rebounded after positive corporate earnings announcements. → 주식회사는 긍정적 인 기업 수익 발표 후 다시 묶여있다.\n",
      "Financial regulators tightened disclosure requirements for listed companies. → 금융 규제 기관은 등록된 회사에 대한 공개 요구 사항을 강화했습니다.\n",
      "Foreign investment surged following the signing of a new trade agreement. → 외국인 투자는 새로운 무역협정에 서명한 후에 상승했습니다.\n",
      "The insurance industry anticipates growth amid increasing demand for health coverage. → 보험업계는 건강보험에 대한 수요가 증가함에 따라 성장할 것으로 예상된다.\n",
      "The national currency depreciated against the dollar due to external market pressures. → 국가 통화는 외부 시장의 압박으로 인해 달러에 대한 가치가 낮아졌습니다.\n",
      "Analysts forecast moderate growth in the housing finance sector. → 분석가들은 주택 금융 분야의 적당한 성장률을 예측합니다.\n",
      "The merger of two leading banks is expected to reshape the financial industry. → 두 개의 주요 은행의 합병은 금융 산업을 재구성 할 것으로 예상됩니다.\n",
      "\n",
      "KO→EN:\n",
      "중앙은행은 시장 안정을 위해 기준 금리를 동결했다. → The central bank has frozen the standard interest rate for market stability.\n",
      "주요 은행들은 신용 위험 증가로 인해 분기 실적이 감소했다고 발표했다. → The major banks have announced that the quarterly performance has decreased due to the increase in credit risk.\n",
      "정부는 내수 소비를 촉진하기 위한 새로운 재정 정책을 도입했다. → The government has introduced a new financial policy to promote domestic water consumption.\n",
      "기업 실적 호조 발표 이후 주식시장이 반등했다. → After the announcement of the company’s performance, the stock market has declined.\n",
      "금융 당국은 상장 기업의 공시 요건을 강화했다. → The financial authorities have strengthened the publication requirements of the listed companies.\n",
      "새로운 무역 협정 체결 이후 해외 투자가 급증했다. → After the signing of a new trade agreement, foreign investments have increased rapidly.\n",
      "보험 산업은 건강 보장 수요 증가로 성장을 예상하고 있다. → The insurance industry is expected to grow with increased health insurance demand.\n",
      "외부 시장 압력으로 인해 원화가 달러 대비 약세를 보였다. → Due to external market pressure, the currency was weakened against the dollar.\n",
      "전문가들은 주택 금융 부문에서 완만한 성장을 전망하고 있다. → Experts expect full growth in the housing finance sector.\n",
      "두 주요 은행의 합병은 금융 산업 구도를 재편할 것으로 예상된다. → The merger of the two major banks is expected to reorganize the financial industry.\n"
     ]
    }
   ],
   "source": [
    "# Glossary 분리\n",
    "glossary_ko = {\n",
    "    \"이자율\": \"금리\",\n",
    "    \"세금 자극\": \"세제 혜택\",\n",
    "    \"부패 위험\": \"부도 위험\",\n",
    "    \"자본 예비\": \"자본 준비금\",\n",
    "    \"자본 보유량\": \"자본 준비금\",\n",
    "    \"공급망 장애\": \"공급망 혼란\",\n",
    "    \"산업의 풍경\": \"산업 구도\",\n",
    "    \"노동-생명 경계\": \"일과 삶의 경계\",\n",
    "    \"금리을\": \"금리를\",\n",
    "    \"혼란를\": \"혼란을\",\n",
    "    \"구도을\": \"구도를\",\n",
    "    \"좁아졌다\": \"흐려졌다\"\n",
    "}\n",
    "\n",
    "glossary_en = {\n",
    "    \"capital earnings\": \"capital reserves\",\n",
    "    \"consumer trust\": \"consumer confidence\",\n",
    "    \"inter-national\": \"international\",\n",
    "    \"supply chain confusion\": \"supply chain disruptions\",\n",
    "    \"unemployment risks\": \"default risks\"\n",
    "}\n",
    "\n",
    "def postprocess_translation(text: str, glossary: dict) -> str:\n",
    "    # 1. Glossary 치환\n",
    "    for wrong, correct in glossary.items():\n",
    "        text = text.replace(wrong, correct)\n",
    "\n",
    "    # 2. 조사 중복 교정\n",
    "    text = text.replace(\"을을\", \"을\")\n",
    "    text = text.replace(\"를를\", \"를\")\n",
    "    text = text.replace(\"을를\", \"를\")\n",
    "    text = text.replace(\"를을\", \"을\")\n",
    "\n",
    "    # 3. 금융 보고서 톤 교정\n",
    "    # text = text.replace(\"떨어졌다\", \"하락했다\")\n",
    "    # text = text.replace(\"올랐다\", \"상승했다\")\n",
    "    # text = text.replace(\"줄였다\", \"축소했다\")\n",
    "    # text = text.replace(\"늘어났다\", \"확대됐다\")\n",
    "    # text = text.replace(\"~할 것입니다\", \"~할 것으로 예상된다\")\n",
    "    # text = text.replace(\"~될 것입니다\", \"~될 것으로 예상된다\")\n",
    "\n",
    "    # 4. 띄어쓰기/표현 보정\n",
    "    # text = text.replace(\"했 습니다\", \"했습니다\")\n",
    "    # text = text.replace(\"했 다\", \"했다\")\n",
    "    # text = text.replace(\"것 입니다\", \"것입니다\")\n",
    "    # text = text.replace(\"재구성 할\", \"재구성할\")\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# 영어 → 한국어\n",
    "text = \"It is literally the basis of life.\"\n",
    "texts_en = [\n",
    "    \"The company discloses its consolidated financial statements for Q3 2025.\",\n",
    "    \"The board of directors has approved the resolution for entering a new business sector.\",\n",
    "    \"The dividend payment plan for 2025 has been finalized at 500 KRW per share.\",\n",
    "    \"According to the audit report, the internal accounting control system is operating appropriately.\",\n",
    "    \"The largest shareholder’s ownership stake increased from 35% to 40%.\",\n",
    "    \"As of December 31, 2025, the company reported total assets of 1 trillion KRW.\",\n",
    "    \"The company decided to expand investment in its overseas subsidiaries.\",\n",
    "    \"Sales revenue for the first half of 2025 increased by 15% compared to the same period last year.\",\n",
    "    \"The company raised 50 billion KRW through the issuance of new bonds.\",\n",
    "    \"The external auditor’s opinion was expressed as 'unqualified.'\"\n",
    "]\n",
    "inputs = tokenizer(texts_en, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "forced_bos_token_id = tokenizer.lang_code_to_id[\"ko\"]\n",
    "# outputs = model.generate(**inputs, forced_bos_token_id=forced_bos_token_id, num_beams=5, max_length=128)\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    forced_bos_token_id=forced_bos_token_id,\n",
    "    num_beams=5,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "# print(\"EN→KO:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(\"EN→KO:\")\n",
    "for i, output in enumerate(outputs):\n",
    "    decoded = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    processed = postprocess_translation(decoded, glossary_ko) # 후처리 적용\n",
    "    print(f\"{texts_en[i]} → {processed}\")\n",
    "    # print(f\"{texts[i]} → {tokenizer.decode(output, skip_special_tokens=True)}\")\n",
    "\n",
    "# 한국어 → 영어\n",
    "text = \"말 그대로 삶의 기초입니다.\"\n",
    "texts_ko = [\n",
    "    \"회사는 2025년 3분기 연결재무제표를 공시합니다.\",\n",
    "    \"당사는 신규 사업 진출을 위해 이사회 결의를 완료했습니다.\",\n",
    "    \"2025년 배당금 지급 계획은 주당 500원으로 확정되었습니다.\",\n",
    "    \"감사보고서에 따르면 내부회계관리제도는 적정하게 운영되고 있습니다.\",\n",
    "    \"최대주주가 보유한 지분율은 35%에서 40%로 증가했습니다.\",\n",
    "    \"회사는 2025년 12월 31일 기준 자산총액을 1조 원으로 보고했습니다.\",\n",
    "    \"당사는 해외 자회사에 대한 투자 확대를 결정했습니다.\",\n",
    "    \"2025년 상반기 매출액은 전년 동기 대비 15% 증가했습니다.\",\n",
    "    \"회사는 신규 채권 발행을 통해 500억 원을 조달했습니다.\",\n",
    "    \"외부감사인의 의견은 ‘적정’으로 표시되었습니다.\"\n",
    "]\n",
    "inputs = tokenizer(texts_ko, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "forced_bos_token_id = tokenizer.lang_code_to_id[\"en\"]\n",
    "# outputs = model.generate(**inputs, forced_bos_token_id=forced_bos_token_id, num_beams=5, max_length=128)\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    forced_bos_token_id=forced_bos_token_id,\n",
    "    num_beams=5,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "# print(\"KO→EN:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(\"\\nKO→EN:\")\n",
    "for i, output in enumerate(outputs):\n",
    "    decoded = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    processed = postprocess_translation(decoded, glossary_en) # 후처리 적용\n",
    "    print(f\"{texts_ko[i]} → {processed}\")\n",
    "\n",
    "    # print(f\"{texts_ko[i]} → {tokenizer.decode(output, skip_special_tokens=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c8d4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN→KO:\n",
      "The central bank decided to keep interest rates unchanged to stabilize market expectations. → 중앙은행은 시장 기대를 안정화하기 위해 이자율을 변함없이 유지하기로 결정했다.\n",
      "Major banks reported a decline in quarterly profits due to rising credit risks. → 주요 은행은 신용 위험 증가로 인해 분기 이익이 떨어지는 것으로 보고되었습니다.\n",
      "The government introduced new fiscal policies to stimulate domestic consumption. → 정부는 국내 소비를 자극하기 위해 새로운 세금 정책을 도입했습니다.\n",
      "Stock markets rebounded after positive corporate earnings announcements. → 주식 시장은 긍정적 인 기업 수익 발표 후 회복되었습니다.\n",
      "Financial regulators tightened disclosure requirements for listed companies. → 금융 규제 기관은 등록된 회사에 대한 공개 요구 사항을 강화했습니다.\n",
      "Foreign investment surged following the signing of a new trade agreement. → 외국인 투자는 새로운 무역 협정 서명 후 상승했다.\n",
      "The insurance industry anticipates growth amid increasing demand for health coverage. → 보험 산업은 건강 보험에 대한 수요가 증가함에 따라 성장을 예상하고 있습니다.\n",
      "The national currency depreciated against the dollar due to external market pressures. → 국가 통화는 외부 시장 압박으로 인해 달러에 비해 가치가 떨어졌습니다.\n",
      "Analysts forecast moderate growth in the housing finance sector. → 분석가들은 주택 금융 분야에서 적당한 성장을 예측합니다.\n",
      "The merger of two leading banks is expected to reshape the financial industry. → 두 개의 주요 은행의 합병은 금융 산업을 재구성 할 것으로 예상됩니다.\n",
      "\n",
      "KO→EN:\n",
      "중앙은행은 시장 안정을 위해 기준 금리를 동결했다. → The central bank has frozen the standard interest rate for the stability of the market.\n",
      "주요 은행들은 신용 위험 증가로 인해 분기 실적이 감소했다고 발표했다. → The major banks announced that the increase in credit risk led to a decrease in quarterly performance.\n",
      "정부는 내수 소비를 촉진하기 위한 새로운 재정 정책을 도입했다. → The government has introduced a new financial policy to promote domestic water consumption.\n",
      "기업 실적 호조 발표 이후 주식시장이 반등했다. → After the company’s real estate announcement, the stock market has reversed.\n",
      "금융 당국은 상장 기업의 공시 요건을 강화했다. → Financial authorities have strengthened the publication requirements of the listed companies.\n",
      "새로운 무역 협정 체결 이후 해외 투자가 급증했다. → After the signing of a new trade agreement, foreign investments have increased.\n",
      "보험 산업은 건강 보장 수요 증가로 성장을 예상하고 있다. → The insurance industry is expecting growth with increased health insurance demand.\n",
      "외부 시장 압력으로 인해 원화가 달러 대비 약세를 보였다. → Due to external market pressure, the currency showed weakness against the dollar.\n",
      "전문가들은 주택 금융 부문에서 완만한 성장을 전망하고 있다. → Experts are expecting full growth in the housing finance sector.\n",
      "두 주요 은행의 합병은 금융 산업 구도를 재편할 것으로 예상된다. → The merger of the two major banks is expected to reorganize the financial industry.\n"
     ]
    }
   ],
   "source": [
    "# 베이스 모델 테스트\n",
    "import torch\n",
    "\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 영어 → 한국어\n",
    "text = \"It is literally the basis of life.\"\n",
    "texts = [\n",
    "    \"The company discloses its consolidated financial statements for Q3 2025.\",\n",
    "    \"The board of directors has approved the resolution for entering a new business sector.\",\n",
    "    \"The dividend payment plan for 2025 has been finalized at 500 KRW per share.\",\n",
    "    \"According to the audit report, the internal accounting control system is operating appropriately.\",\n",
    "    \"The largest shareholder’s ownership stake increased from 35% to 40%.\",\n",
    "    \"As of December 31, 2025, the company reported total assets of 1 trillion KRW.\",\n",
    "    \"The company decided to expand investment in its overseas subsidiaries.\",\n",
    "    \"Sales revenue for the first half of 2025 increased by 15% compared to the same period last year.\",\n",
    "    \"The company raised 50 billion KRW through the issuance of new bonds.\",\n",
    "    \"The external auditor’s opinion was expressed as 'unqualified.'\"\n",
    "]\n",
    "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "forced_bos_token_id = tokenizer.lang_code_to_id[\"ko\"]\n",
    "# outputs = model.generate(**inputs, forced_bos_token_id=forced_bos_token_id, num_beams=5, max_length=128)\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    forced_bos_token_id=forced_bos_token_id,\n",
    "    num_beams=5,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "# print(\"EN→KO:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(\"EN→KO:\")\n",
    "for i, output in enumerate(outputs):\n",
    "    print(f\"{texts[i]} → {tokenizer.decode(output, skip_special_tokens=True)}\")\n",
    "\n",
    "\n",
    "# 한국어 → 영어\n",
    "text = \"말 그대로 삶의 기초입니다.\"\n",
    "texts_ko = [\n",
    "    \"회사는 2025년 3분기 연결재무제표를 공시합니다.\",\n",
    "    \"당사는 신규 사업 진출을 위해 이사회 결의를 완료했습니다.\",\n",
    "    \"2025년 배당금 지급 계획은 주당 500원으로 확정되었습니다.\",\n",
    "    \"감사보고서에 따르면 내부회계관리제도는 적정하게 운영되고 있습니다.\",\n",
    "    \"최대주주가 보유한 지분율은 35%에서 40%로 증가했습니다.\",\n",
    "    \"회사는 2025년 12월 31일 기준 자산총액을 1조 원으로 보고했습니다.\",\n",
    "    \"당사는 해외 자회사에 대한 투자 확대를 결정했습니다.\",\n",
    "    \"2025년 상반기 매출액은 전년 동기 대비 15% 증가했습니다.\",\n",
    "    \"회사는 신규 채권 발행을 통해 500억 원을 조달했습니다.\",\n",
    "    \"외부감사인의 의견은 ‘적정’으로 표시되었습니다.\"\n",
    "]\n",
    "inputs = tokenizer(texts_ko, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "forced_bos_token_id = tokenizer.lang_code_to_id[\"en\"]\n",
    "# outputs = model.generate(**inputs, forced_bos_token_id=forced_bos_token_id, num_beams=5, max_length=128)\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    forced_bos_token_id=forced_bos_token_id,\n",
    "    num_beams=5,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "# print(\"KO→EN:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(\"\\nKO→EN:\")\n",
    "for i, output in enumerate(outputs):\n",
    "    print(f\"{texts_ko[i]} → {tokenizer.decode(output, skip_special_tokens=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b185fe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN→KO chrF Score:\n",
      "chrF2 = 59.34\n",
      "\n",
      "KO→EN chrF Score:\n",
      "chrF2 = 69.97\n"
     ]
    }
   ],
   "source": [
    "# sacrebleu.corpus_chrf는 chrF 점수를 계산하는 함수로, 번역된 문장(hypotheses)과 정답 문장(references) 간의 문자 단위 F-score를 측정\n",
    "# BLEU 보다 문장 길이나 형태 변화에 덜 민감해서 번역 품질 평가에 자주 쓰인다\n",
    "import sacrebleu\n",
    "\n",
    "# LoRA 파인 튜닝 정수\n",
    "# - EN→KO chrF Score:\n",
    "# - chrF2 = 59.34\n",
    "# - KO→EN chrF Score:\n",
    "# - chrF2 = 69.97\n",
    "\n",
    "# Base 모델 점수\n",
    "# - EN→KO chrF Score:\n",
    "# - chrF2 = 59.74\n",
    "# - KO→EN chrF Score:\n",
    "# - chrF2 = 70.77\n",
    "\n",
    "# 영어 → 한국어 평가\n",
    "references_ko = [ # 영어 문장의 정답 한국어 번역\n",
    "    \"중앙은행은 인플레이션을 억제하기 위해 금리를 인상하기로 결정했다.\",\n",
    "    \"외국인 투자자들은 한국 국채에 강한 관심을 보이고 있다.\",\n",
    "    \"회사는 수출 증가로 인해 분기별 수익이 크게 증가했다고 보고했다.\",\n",
    "    \"신용 리스크 관리는 금융 안정성을 유지하는 데 필수적이다.\",\n",
    "    \"새로운 규제 발표 이후 주식 시장은 높은 변동성을 경험했다.\",\n",
    "    \"환율 변동은 다국적 기업에 큰 영향을 미친다.\",\n",
    "    \"은행은 소매 고객을 위한 새로운 디지털 플랫폼을 도입했다.\",\n",
    "    \"유동성 부족은 금융 부문에서 시스템 리스크로 이어질 수 있다.\",\n",
    "    \"두 은행의 합병은 경쟁력을 향상시킬 것으로 예상된다.\",\n",
    "    \"글로벌 금융 기관들은 미국의 통화 정책 영향을 면밀히 모니터링하고 있다.\"\n",
    "]\n",
    "\n",
    "hypotheses_ko = [ # 모델이 생성한 한국어 번역\n",
    "    \"중앙은행은 인플레이션을 통제하기 위해 이자율을 올리기로 결정했다.\",\n",
    "    \"외국인 투자자들은 한국 정부의 부채에 강한 관심을 보이고 있습니다.\",\n",
    "    \"회사는 더 높은 수출으로 인해 분기 수익이 상당히 증가했습니다.\",\n",
    "    \"신용 위험 관리는 금융 안정성을 유지하는 데 필수적입니다.\",\n",
    "    \"주식 시장은 새로운 규정 발표 후 높은 변동을 경험했습니다.\",\n",
    "    \"교환율 변동은 다국적 기업에 큰 영향을 미칩니다.\",\n",
    "    \"은행은 소매 고객을위한 새로운 디지털 플랫폼을 도입했습니다.\",\n",
    "    \"유동성 결핍은 금융 부문에서 체계적인 위험을 초래할 수 있습니다.\",\n",
    "    \"두 은행의 합병은 경쟁력을 향상시킬 것으로 예상된다.\",\n",
    "    \"글로벌 금융 기관은 미국의 통화 정책의 영향을 철저히 모니터링하고 있습니다.\"\n",
    "]\n",
    "\n",
    "hypotheses_ko_lora= [\n",
    "    \"중앙은행은 인플레이션을 통제하기 위해 이자율을 올리기로 결정했다.\",\n",
    "    \"외국인 투자자들은 한국 정부의 부채에 강한 관심을 보이고 있다.\",\n",
    "    \"회사는 더 높은 수출으로 인해 분기 수익이 상당히 증가했습니다.\",\n",
    "    \"신용 위험 관리는 금융 안정성을 유지하는 데 필수적입니다.\",\n",
    "    \"주식 시장은 새로운 규정 발표 후 높은 변동을 경험했습니다.\",\n",
    "    \"교환율 변동은 다국적 기업에 큰 영향을 미칩니다.\",\n",
    "    \"은행은 소매 고객을위한 새로운 디지털 플랫폼을 도입했습니다.\",\n",
    "    \"유동성 결핍은 금융 부문에서 체계적인 위험을 초래할 수 있습니다.\",\n",
    "    \"두 은행의 합병은 경쟁력을 향상시킬 것으로 예상된다.\",\n",
    "    \"세계 금융 기관은 미국의 통화 정책의 영향을 철저히 모니터링하고 있습니다.\"\n",
    "]\n",
    "\n",
    "print(\"EN→KO chrF Score:\")\n",
    "# chrF 점수를 계산\n",
    "# chrf_ko = sacrebleu.corpus_chrf(hypotheses_ko, [references_ko])\n",
    "chrf_ko = sacrebleu.corpus_chrf(hypotheses_ko_lora, [references_ko])\n",
    "print(chrf_ko)\n",
    "\n",
    "\n",
    "# 한국어 → 영어 평가\n",
    "references_en = [\n",
    "    \"The central bank decided to raise interest rates to control inflation.\",\n",
    "    \"Foreign investors are showing strong interest in Korean government bonds.\",\n",
    "    \"The company reported a significant increase in quarterly earnings due to higher exports.\",\n",
    "    \"Credit risk management is essential for maintaining financial stability.\",\n",
    "    \"The stock market experienced high volatility after the announcement of new regulations.\",\n",
    "    \"Exchange rate fluctuations have a major impact on multinational corporations.\",\n",
    "    \"The bank introduced a new digital platform for retail customers.\",\n",
    "    \"Liquidity shortages can lead to systemic risks in the financial sector.\",\n",
    "    \"The merger between the two banks is expected to improve competitiveness.\",\n",
    "    \"Global financial institutions are closely monitoring the impact of U.S. monetary policy.\"\n",
    "]\n",
    "\n",
    "hypotheses_en = [\n",
    "    \"The central bank has decided to raise interest rates to suppress inflation.\",\n",
    "    \"Foreign investors are very interested in the Korean national debt.\",\n",
    "    \"The company that a significant increase in quarterly revenue due to increased exports.\",\n",
    "    \"Credit risk management is essential toining financial stability.\",\n",
    "    \"Since the announcement of new regulations, the stock market has experienced high volatility.\",\n",
    "    \"Currency rate variations have a great impact on multinational enterprises.\",\n",
    "    \"The bank has introduced a new digital platform for retail customers.\",\n",
    "    \"Lack of liquidity can lead to system risk in the financial sector.\",\n",
    "    \"The fusion of the two banks is expected to boost competitiveness.\",\n",
    "    \"Global financial institutions are closely monitoring the influence of U.S. currency policy.\"\n",
    "]\n",
    "\n",
    "hypotheses_en_lora= [\n",
    "    \"The central bank has decided to raise interest rates to suppress inflation.\",\n",
    "    \"Foreign investors are very interested in the Korean national debt.\",\n",
    "    \"The company that the quarterly revenue was significantly increased due to increased exports.\",\n",
    "    \"Credit risk management is essential to maintain financial stability.\",\n",
    "    \"After the announcement of new regulations, the stock market has experienced high volatility.\",\n",
    "    \"The change in exchange rates has a significant impact on multinational companies.\",\n",
    "    \"The bank has introduced a new digital platform for retail customers.\",\n",
    "    \"Lack of liquidity can lead to system risk in the financial sector.\",\n",
    "    \"The fusion of the two banks is expected to boost competitiveness.\",\n",
    "    \"Global financial institutions are closely monitoring the influence of U.S. currency policy.\"\n",
    "]\n",
    "\n",
    "print(\"\\nKO→EN chrF Score:\")\n",
    "# chrf_en = sacrebleu.corpus_chrf(hypotheses_en, [references_en])\n",
    "chrf_en = sacrebleu.corpus_chrf(hypotheses_en_lora, [references_en])\n",
    "print(chrf_en)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
