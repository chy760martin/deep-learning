# app_19_deep_learning_model_hybrid_mnist.py
# Streamlit ì•± - Hybrid ëª¨ë¸ MNIST ì†ê¸€ì”¨ ìˆ«ì ì´ë¯¸ì§€ ë¶„ë¥˜
# '0~9' ìˆ«ì ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìœ„í•œ CNN + RNN í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì‚¬ìš©

import streamlit as st
import torch
from torchvision import models, datasets, transforms
from torch.utils.data import DataLoader
from sklearn.metrics import confusion_matrix, classification_report
from model_utils import HybridModel_CNN_RNN
import os, json, cv2 # ì–¼êµ´ ê²€ì¶œìš©
from streamlit_drawable_canvas import st_canvas
import seaborn as sns
import matplotlib.pyplot as plt
from PIL import Image, ImageOps, ImageEnhance
import numpy as np
import pandas as pd

# ë””ë°”ì´ìŠ¤ ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ ë¡œë”©
@st.cache_resource # - @st.cache_resource: ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë”©í•˜ê³  ìºì‹œí•˜ì—¬ ì•± ì†ë„ í–¥ìƒ
def load_model():
    num_classes = 10 # MNISTëŠ” 10ê°œ ìˆ«ì í´ë˜ìŠ¤ (0~9)
    model = HybridModel_CNN_RNN(in_channels=1, rnn_hidden=128, num_classes=num_classes, dropout_rate=0.3).to(DEVICE) # ëª¨ë¸ ê°ì²´ ìƒì„±

    model_path = os.path.join("models", "model_hybrid_mnist.pt") # - í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    if not os.path.exists(model_path):
        st.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        st.stop()

    model.load_state_dict(torch.load(model_path, map_location=DEVICE)) # - í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    model.eval() # - ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜
    return model

model = load_model() # ëª¨ë¸ ë¡œë“œ

# MNIST í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë”©
transform = transforms.ToTensor()
test_dataset = datasets.MNIST(root='../data/MNIST_data', train=False, transform=transform, download=True)

# ë¼ë²¨ ë§µ ë¡œë”© - labels_map.json íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ì™€ ê°•ì•„ì§€ ì´ë¦„ ë§¤í•‘
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
labels_path = os.path.join(BASE_DIR, 'labels_map.json') # ì˜ˆ: í´ë˜ìŠ¤ ì¸ë±ìŠ¤ â†’ ë§ˆìŠ¤í¬ ì‘ìš©/ë¯¸ì‘ìš© ì´ë¦„

# if not os.path.exists(labels_path): # labels_map.json íŒŒì¼ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
#     st.error(f"labels_map.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {labels_path}")
#     st.stop() # - íŒŒì¼ì´ ì—†ìœ¼ë©´ ì•± ì¤‘ì§€

# with open(labels_path, 'r') as f: # - labels_map.json íŒŒì¼ ì—´ê¸°
#     labels_map = {int(k):v for k, v in json.load(f).items()} # - JSON íŒŒì¼ì—ì„œ ë”•ì…”ë„ˆë¦¬ë¡œ ë¡œë“œ, í‚¤ë¥¼ intë¡œ ë³€í™˜

# Streamlit UI
st.title('CNN MNIST ìˆ«ì ë¶„ë¥˜ê¸° ì›¹ì•±')
st.write("í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ë¬´ì‘ìœ„ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ê±°ë‚˜, ì§ì ‘ ì†ê¸€ì”¨ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ë³´ì„¸ìš”!")

# íƒ­ êµ¬ì„±
# tab1, tab2, tab3 = st.tabs(['í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡', 'ì´ë¯¸ì§€ ì—…ë¡œë“œ', 'ì§ì ‘ ê·¸ë¦¬ê¸°'])
mode = st.selectbox("ëª¨ë“œ ì„ íƒ", ["í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡", "ì´ë¯¸ì§€ ì—…ë¡œë“œ", "ì§ì ‘ ê·¸ë¦¬ê¸°"])


# í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ íƒ­
if mode == "í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡":
    # ë¬´ì‘ìœ„ ì´ë¯¸ì§€ ì„ íƒ
    sample_idx = st.slider('ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ì„ íƒ', 0, len(test_dataset)-1, 0)
    image, label = test_dataset[sample_idx]

    # ëª¨ë¸ ì¶”ë¡ 
    with torch.no_grad(): # ë¯¸ë¶„ ì—°ì‚°í•˜ì§€ ì•ŠìŒ
        # input_tensor = image.view(-1, 28 * 28).to(DEVICE) # MLP ëª¨ë¸ í˜•íƒœ
        # input_tensor = image.view(-1, 1, 28, 28).to(DEVICE) # CNN ëª¨ë¸ í˜•íƒœ
        input_tensor = image.unsqueeze(0).to(DEVICE) # - image.unsqueeze(0)ëŠ” ì°¨ì› ìƒì„±
        output = model(input_tensor)
        pred = torch.argmax(output, dim=1).item()
        
    # ì‹œê°í™”
    st.image(image.squeeze().numpy(), caption=f'ì‹¤ì œ ë¼ë²¨: {label}, ì˜ˆì¸¡: {pred}', width=150, channels='GRAY')

    # Confusion Matrix ë²„íŠ¼
    if st.button('ì „ì²´ Confusion Matrix ë³´ê¸°'):
        all_preds = []
        all_labels = []
        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

        with torch.no_grad():
            for imgs, labels in test_loader:
                x = imgs.to(DEVICE) # ì´ë¯¸ [batch, 1, 28, 28] í˜•íƒœë¥¼ ê°–ì¶”ê³  ìˆìŒ
                y = labels.to(DEVICE) # ì •ë‹µë°ì´í„°

                outputs = model(x) # ëª¨ë¸ ì˜ˆì¸¡
                _, preds = torch.max(outputs, 1) # ëª¨ë¸ ì˜ˆì¸¡ ê°’ ì¶”ì¶œ

                all_preds.extend(preds.cpu().numpy()) # GPU í…ì„œë¥¼ CPUë¡œ ì˜®ê¸°ê³  ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜
                all_labels.extend(y.cpu().numpy())
        
        # confusion matrix ê³„ì‚° (normalize='true'ë¡œ ë¹„ìœ¨ ê¸°ë°˜)
        cm = confusion_matrix(all_labels, all_preds, normalize='true')

        # ì‹œê°í™”
        st.text('Confusion Matrix:')
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', ax=ax)
        ax.set_xlabel('Predicted Labels')
        ax.set_ylabel('True Labels')
        ax.set_title('Normalized Confusion Matrix')
        st.pyplot(fig)

        st.text('Classification Report:')
        st.text(classification_report(all_labels, all_preds, digits=4))

# ì´ë¯¸ì§€ ì—…ë¡œë“œ íƒ­
elif mode == "ì´ë¯¸ì§€ ì—…ë¡œë“œ":
    uploaded_file = st.file_uploader('ì†ê¸€ì”¨ ìˆ«ì ì´ë¯¸ì§€ ì—…ë¡œë“œ (PNG/JPG)', type=['png', 'jpg', 'jpeg'])
    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert('L') # í‘ë°± ë³€í™˜
        image = ImageOps.invert(image) # MNIST ìŠ¤íƒ€ì¼ ë°˜ì „
        image = image.resize( (28, 28) ) # MNIST í¬ê¸°ë¡œ ì¡°ì •

        st.image(image, caption='ì—…ë¡œë“œ ì´ë¯¸ì§€', width=150)

        transform = transforms.Compose([
            transforms.ToTensor(), # 0~255 ì´ë¯¸ì§€ ê°’ì„ 0~1 ì‚¬ì´ê°’ì„ ë³€í™˜
            transforms.Normalize((0.1307,), (0.3081,)) # ì •ê·œí™”
        ])
        # input_tensor = transform(image).view(-1, 28 * 28).to(DEVICE)
        # input_tensor = transform(image).view(-1, 1, 28, 28).to(DEVICE) # CNN ëª¨ë¸ í˜•íƒœ
        input_tensor = transform(image).unsqueeze(0).to(DEVICE) # [1, 1, 28, 28] image.unsqueeze(0)ëŠ” ì°¨ì› ìƒì„±

        with torch.no_grad(): # ë¯¸ë¶„ ì—°ì‚°í•˜ì§€ ì•ŠìŒ
            output = model(input_tensor) # ëª¨ë¸ ì˜ˆì¸¡
            pred = torch.argmax(output, dim=1).item() # ëª¨ë¸ ì˜ˆì¸¡ê°’ ì¶”ì¶œ
        
        st.success(f'ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼: {pred}')


# ì§ì ‘ ê·¸ë¦¬ê¸° íƒ­
elif mode == "ì§ì ‘ ê·¸ë¦¬ê¸°":
    st.write("ğŸ–Œï¸ ì•„ë˜ ìº”ë²„ìŠ¤ì— ìˆ«ìë¥¼ ì§ì ‘ ê·¸ë ¤ë³´ì„¸ìš”")

    canvas_result = st_canvas(
        fill_color="white",
        stroke_width=10,
        stroke_color="black",
        background_color="white",
        height=280,
        width=280,
        drawing_mode="freedraw",
        key="canvas_test",
        update_streamlit=True
    )

    if canvas_result.image_data is not None:
        image_data = canvas_result.image_data

        def center_image(img):
            img = np.array(img)
            coords = np.column_stack(np.where(img > 0))
            if coords.size == 0:
                return Image.fromarray(img)
            y_min, x_min = coords.min(axis=0)
            y_max, x_max = coords.max(axis=0)
            cropped = img[y_min:y_max+1, x_min:x_max+1]
            canvas = np.zeros((28, 28), dtype=np.uint8)
            h, w = cropped.shape
            y_offset = (28 - h) // 2
            x_offset = (28 - w) // 2
            canvas[y_offset:y_offset+h, x_offset:x_offset+w] = cropped
            return Image.fromarray(canvas)

        if np.std(image_data) < 1:
            st.warning("ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¬ë¯¸í•˜ê±°ë‚˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìˆ«ìë¥¼ êµµê²Œ ê·¸ë ¤ì£¼ì„¸ìš”.")
        else:
            image = Image.fromarray((image_data[:, :, :3]).astype('uint8')).convert('L')
            image = ImageOps.invert(image)
            image = image.resize((28, 28))
            image = center_image(image)

            st.image(image, caption='ê·¸ë¦° ìˆ«ì', width=150)

            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((0.1307,), (0.3081,))
            ])
            # input_tensor = transform(image).view(-1, 28 * 28)
            # input_tensor = transform(image).view(-1, 1, 28, 28).to(DEVICE) # CNN ëª¨ë¸ í˜•íƒœ
            input_tensor = transform(image).unsqueeze(0).to(DEVICE) # [1, 1, 28, 28]

            # ëª¨ë¸ ì¶”ë¡  (ëª¨ë¸ì€ ë¯¸ë¦¬ ë¡œë”©ë˜ì–´ ìˆì–´ì•¼ í•¨)
            with torch.no_grad():
                # outputì€ ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥ í…ì„œ, ë³´í†µ shapeì€ [1, 10](ìˆ«ì 0~9ì— ëŒ€í•œ ë¡œì§“ ê°’)
                output = model(input_tensor)
                # pred = torch.argmax(output, dim=1).item()
                # softmax()ë¥¼ í†µí•´ ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥ ë¡œ ë³€í™˜, squeeze()ëŠ” ë°°ì¹˜ ì°¨ì›ì„ ì œê±°í•´ 1D ë°°ì—´ë¡œ ë§Œë“ ë‹¤, numpy()ëŠ” ë„˜íŒŒì´ ë°ì´í„°ë¡œ ë§Œë“ ë‹¤.
                # .squeeze()ëŠ” ë¶ˆí•„ìš”í•œ ì°¨ì›ì„ ì œê±° [1, 10] -> [10]ìœ¼ë¡œ ë°”ê¿”ì„œ 1D ë°°ì—´ë¡œ ë§Œë“ ë‹¤.
                probabilities = torch.nn.functional.softmax(output, dim=1).squeeze().cpu().numpy()
                pred = int(np.argmax(probabilities))

            st.success(f'ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼: {pred}')
            st.markdown(f"### âœï¸ ëª¨ë¸ì´ ì¸ì‹í•œ ìˆ«ì: `{pred}`")

            # ì˜ˆì¸¡ í™•ë¥  ë§‰ëŒ€ê·¸ë˜í”„
            fig, ax = plt.subplots()
            ax.bar(range(10), probabilities, color='skyblue')
            ax.set_xticks(range(10))
            ax.set_xlabel('Num Class')
            ax.set_ylabel('Prediction')
            ax.set_title('Model Prediction')

            st.pyplot(fig)

st.markdown("---")
st.caption("Powered by CNN + RNN Hybrid Learning")