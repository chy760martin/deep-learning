{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb79a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning(전이학습)\n",
    "# Transfer Learning(전이학습)이란 아주 큰 데이터셋, 즉 21,841 부류에 대해서 총 1419만7122장의 이미지로 구성되어 있는\n",
    "# ImageNet 데이터를 사용해서 학습된 모델의 가중치를 가져와서, 우리가 해결하려는 문제에 맞게 보정해서 사용하는 것을 의미함\n",
    "# 이때 큰 데이터셋을 사용해서 훈련된 모델을 사전학습모델(pre-trained model)이라고 함\n",
    "# ImageNet 데이터의 이미지 크기는 평균적으로 469x387 이며, 이러한 2만개 이상의 부류 가운데 1000 부류만 뽑아서 데이터를 구성하고\n",
    "# 정확도를 높이는 대회가 바로 ImageNet Challenge 이다\n",
    "\n",
    "# 전이학습 필요성 \n",
    "# ImageNet(풍부한 데이터) -> 사전학습모델(pre-trained model) -> 전이학습(Transfer Learning) -> 새롭게 학습되는 모델(일반적으로 파인튜닝으로 사용됨) <- 부족한 사용자 데이터\n",
    "\n",
    "# 사전 학습 모델 구조(pre-trained model)\n",
    "# 입력 -> 사전 학습된 특징 추출기(pre-trained feature extractor) -> 사전 학습된 분류기(pre-trained classifier) -> 출력\n",
    "\n",
    "# 사전 학습된 특징 추출기(pre-trained feature extractor)\n",
    "# - 특징 추출기(feature extractor)는 컨볼루션층과 풀링층의 조합으로 구성되어 있으며, ImageNet 데이터에 대해 이미 학습되어 있음\n",
    "# - conv->conv->pooling->, 특징 추출기는 출력 데이터를 bottleneck 또는 feature vector 등으로 지칭함\n",
    "\n",
    "# 사전 학습된 분류기(pre-trained classifier)\n",
    "# - 분류기(classifier)는 완전 연결층으로 구성되며 추출된 특징을 입력으로 받아 최종적으로 주어진 이미지에 대한 클래스(정답)을 카테고리 형태로 분류하는 역할 수행\n",
    "# - Linear->Linear->Linear(Softmax)->, 오버피팅을 줄이기 위해 출력층 이전의 Linear layer 사이에는 Dropout, BatchNormalization layer 등을 추가 할 수 있음\n",
    "\n",
    "# 파인 튜닝(Fine Tuning)\n",
    "# - 사전 학습 모델의 가중치를 미세하게 조정하는 기법이며, 새롭게 분류하려는 데이터의 종류와 전체 개수를 미리 분석한 후에, \n",
    "#   그것을 바탕으로 사전 학습 모델 가중치 일부만을 재학습 시키거나 또는 모든 가중치를 처음부터 다시 학습시킬 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e8502f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version :  2.2.2 , device :  cpu\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# pre-trained model(사전학습모델) 다운로드\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models # 다양한 사전 학습 모델을 포함한 모듈\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('pytorch version : ', torch.__version__, ', device : ', DEVICE)\n",
    "\n",
    "# 사전 학습 모델 vgg16(), 사전 학습된 가중치 weights=models.VGG16_Weights.DEFAULT\n",
    "pretrained_model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "\n",
    "print(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96515c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning Model\n",
    "class TransferLearningModel(nn.Module):\n",
    "    def __init__(self, pretrained_model, feature_extractor):\n",
    "        super().__init__()\n",
    "\n",
    "        if(feature_extractor):\n",
    "            for param in pretrained_model.parameters():\n",
    "                param.requires_grad = False # 특정 파라미터의 기울기 계산을 중단시키는 설정, 가중치/바이어스 학습과정에서 업데이트 되지 않음\n",
    "        \n",
    "        # 학습데이터에 맞게 새로운 분류기를 만들어 준 후에, 기존 사전학습모델 classifier 부분을 새로운 classifier 로 반드시 바꾸어야 함\n",
    "        pretrained_model.classifier = nn.Sequential(\n",
    "            nn.Linear(pretrained_model.classifier[0].in_features, 128),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "        self.model = pretrained_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78cfb2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = True # True : feature_extractor, False : Fine Tuning\n",
    "\n",
    "# model 객체 생성\n",
    "model = TransferLearningModel(pretrained_model, feature_extractor).to(DEVICE)\n",
    "# loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
