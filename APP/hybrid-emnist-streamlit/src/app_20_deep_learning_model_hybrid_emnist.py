# app_20_deep_learning_model_hybrid_emnist.py
# Streamlit ì•± - Hybrid ëª¨ë¸ EMNIST ì†ê¸€ì”¨ ìˆ«ì + ì•ŒíŒŒë²³ ì´ë¯¸ì§€ ë¶„ë¥˜
# '0~9' ìˆ«ì + ì•ŒíŒŒë²³ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìœ„í•œ CNN + RNN í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì‚¬ìš©

# app_emnist_handwriting_recognizer.py

import streamlit as st
import torch
from torchvision import transforms
from streamlit_drawable_canvas import st_canvas
from PIL import Image, ImageOps, ImageEnhance
import numpy as np
import json, os
from model_utils import HybridModel_CNN_RNN
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
matplotlib.rcParams['font.family'] = 'Malgun Gothic'  # Windowsìš© í•œê¸€ í°íŠ¸
matplotlib.rcParams['axes.unicode_minus'] = False     # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# ë””ë°”ì´ìŠ¤ ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ ë¡œë”©
@st.cache_resource
def load_model():
    model = HybridModel_CNN_RNN(in_channels=1, rnn_hidden=128, num_classes=47).to(DEVICE)
    model.load_state_dict(torch.load("./models/model_hybrid_emnist.pt", map_location=DEVICE))
    model.eval()
    return model

model = load_model()

# ë¼ë²¨ ë§µ ë¡œë”©
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
labels_path = os.path.join(BASE_DIR, 'labels_map.json') # ì˜ˆ: í´ë˜ìŠ¤ ì¸ë±ìŠ¤ â†’ ë§ˆìŠ¤í¬ ì‘ìš©/ë¯¸ì‘ìš© ì´ë¦„
with open(labels_path, "r") as f:
    labels_map = {int(k): v for k, v in json.load(f).items()}

# Streamlit UI
st.title("âœï¸ ì†ê¸€ì”¨ ë¬¸ì ì¸ì‹ê¸° (EMNIST ê¸°ë°˜)")
st.write("ì•„ë˜ ìº”ë²„ìŠ¤ì— ìˆ«ìë‚˜ ì•ŒíŒŒë²³ì„ ì§ì ‘ ê·¸ë ¤ë³´ì„¸ìš”. ëª¨ë¸ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸ì‹í•©ë‹ˆë‹¤.")

# ìº”ë²„ìŠ¤ ì„¤ì •
canvas_result = st_canvas(
    fill_color="white",
    stroke_width=15,
    stroke_color="black",
    background_color="white",
    height=280,
    width=280,
    drawing_mode="freedraw",
    key="canvas"
)

def center_image(img):
    img = np.array(img)
    coords = np.column_stack(np.where(img > 0))
    if coords.size == 0:
        return Image.fromarray(img)
    y_min, x_min = coords.min(axis=0)
    y_max, x_max = coords.max(axis=0)
    cropped = img[y_min:y_max+1, x_min:x_max+1]
    canvas = np.zeros((28, 28), dtype=np.uint8)
    h, w = cropped.shape
    y_offset = (28 - h) // 2
    x_offset = (28 - w) // 2
    canvas[y_offset:y_offset+h, x_offset:x_offset+w] = cropped
    return Image.fromarray(canvas)

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(image_data):
    image = Image.fromarray((image_data[:, :, :3]).astype('uint8')).convert('L')
    image = ImageOps.invert(image)
    image = image.resize((28, 28))
    image = center_image(image)     # ì¤‘ì‹¬ ì •ë ¬
    image = ImageEnhance.Contrast(image).enhance(2.0)  # ëŒ€ë¹„ ê°•í™”

    # ì¤‘ì‹¬ ì •ë ¬
    img_np = np.array(image)
    coords = np.column_stack(np.where(img_np > 0))
    if coords.size == 0:
        return None
    y_min, x_min = coords.min(axis=0)
    y_max, x_max = coords.max(axis=0)
    cropped = img_np[y_min:y_max+1, x_min:x_max+1]
    canvas = np.zeros((28, 28), dtype=np.uint8)
    h, w = cropped.shape
    y_offset = (28 - h) // 2
    x_offset = (28 - w) // 2
    canvas[y_offset:y_offset+h, x_offset:x_offset+w] = cropped
    return Image.fromarray(canvas)

# ì˜ˆì¸¡ ìˆ˜í–‰
if canvas_result.image_data is not None:
    image = preprocess_image(canvas_result.image_data)
    if image is None:
        st.warning("ì´ë¯¸ì§€ê°€ ë¹„ì–´ ìˆê±°ë‚˜ ë„ˆë¬´ íë¦½ë‹ˆë‹¤. ë‹¤ì‹œ ê·¸ë ¤ì£¼ì„¸ìš”.")
    else:
        st.image(image, caption="ì…ë ¥ ì´ë¯¸ì§€", width=150)

        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        input_tensor = transform(image).unsqueeze(0).to(DEVICE)

        with torch.no_grad():
            output = model(input_tensor)
            probabilities = torch.nn.functional.softmax(output, dim=1).squeeze().cpu().numpy()
            pred = int(np.argmax(probabilities))
            pred_label = labels_map.get(pred, "Unknown")

        st.success(f"ğŸ§  ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼: `{pred_label}` (í´ë˜ìŠ¤ ì¸ë±ìŠ¤: {pred})")

        # ğŸ”¢ Top-3 ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
        topk = torch.topk(torch.tensor(probabilities), k=3)
        top_indices = topk.indices.numpy()
        top_probs = topk.values.numpy()

        st.markdown("### ğŸ” Top-3 ì˜ˆì¸¡ ê²°ê³¼")
        for i in range(3):
            label = labels_map.get(int(top_indices[i]), "Unknown")
            prob = top_probs[i]
            st.write(f"Top-{i+1}: `{label}` ({prob:.2%})")

        # ğŸ“‹ ì˜ˆì¸¡ ê²°ê³¼ ë³µì‚¬/ë‹¤ìš´ë¡œë“œ
        st.markdown("### ğŸ“¥ ì˜ˆì¸¡ ê²°ê³¼ ë³µì‚¬ ë° ì €ì¥")
        st.text_input("ì˜ˆì¸¡ëœ ë¬¸ì", value=pred_label, disabled=True)
        st.download_button("ê²°ê³¼ ì €ì¥í•˜ê¸°", data=pred_label, file_name="prediction.txt", mime="text/plain")

        # í™•ë¥  ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(10, 4))
        sns.barplot(x=[labels_map[i] for i in range(len(probabilities))], y=probabilities, ax=ax, palette="Blues_d")
        ax.set_title("í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ í™•ë¥ ")
        ax.set_ylabel("Probability")
        ax.set_xlabel("Class")
        plt.xticks(rotation=90)
        st.pyplot(fig)

uploaded_file = st.file_uploader("ì†ê¸€ì”¨ ì´ë¯¸ì§€ ì—…ë¡œë“œ (PNG/JPG)", type=["png", "jpg", "jpeg"])
if uploaded_file:
    image = preprocess_image(Image.open(uploaded_file))
    st.image(image, caption="ì—…ë¡œë“œ ì´ë¯¸ì§€", width=150)

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    input_tensor = transform(image).unsqueeze(0).to(DEVICE)

    with torch.no_grad():
        output = model(input_tensor)
        pred = torch.argmax(output, dim=1).item()
        pred_label = labels_map.get(pred, "Unknown")

    st.success(f"ğŸ§  ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼: `{pred_label}` (í´ë˜ìŠ¤ ì¸ë±ìŠ¤: {pred})")
    st.code(pred_label, language="text")  # ë³µì‚¬ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì¶œë ¥
    st.download_button("ê²°ê³¼ ë³µì‚¬/ì €ì¥", pred_label, file_name="prediction.txt")