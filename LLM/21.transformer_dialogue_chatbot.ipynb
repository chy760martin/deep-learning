{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e468aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer 모델 구축 - Transformer 대화형 챗봇(Dialogue Chatbot) 모델\n",
    "# 학습 목표 - 실무에서 사용되는 파이프라인 이해 및 적용\n",
    "# - 1. 데이터셋 로드 및 데이터 분리\n",
    "# - AI Hub 대화데이터: 한국어 SNS 멀티턴 대화 데이터\n",
    "# - 데이터 분리: train, validation\n",
    "# - 2. 토크나이저, 데이터셋, 전처리 적용\n",
    "# - 전처리 함수: 질문 + 문맥 토큰화 + 정답 스팬(offsets 위치 정보: offset_mapping 구조 생성)매핑\n",
    "# - 데이터셋 적용, batched=True\n",
    "# - 3. collate_fn 정의 및 DataLoader 생성\n",
    "# - collate_fn: 데이터로더 batch 데이터->텐서->스택 쌓아 리턴\n",
    "# - DataLoader 생성\n",
    "# - 4. 모델 정의\n",
    "# - Feature Extraction + LoRA Fine-tuning 조합\n",
    "# - 최적화 설정: optimizer, GradScaler, autocast\n",
    "# - Early Stopping 클래스 정의\n",
    "# - 최적 모델 가중치 저장\n",
    "# - 5. 학습/검증 루프\n",
    "# - 딕셔너리 형태 학습데이터를 그대로 모델에 전달하는 코드로 정리, 코드가 깔끔하고 범용적으로 사용한다\n",
    "# - Early Stopping 객체 사용하여 적용\n",
    "# - 6. 전체 평가 파이프라인\n",
    "# - F1/EM 평가\n",
    "# - 7. 추론 단일 테스트\n",
    "# - 8. 추론 다중 테스트\n",
    "# - 9. 문장 추론: Fast API 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4539cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2e21008a9e463a9c66aba656e1ad6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dff490d5aee4dd09fc69fef2d5dc1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68986b74818a4794b7459ab084ed58ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/165 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193453d088c3442c910ecc8bf73efdcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/20 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d76db0b4544c4991cb00a6649b1d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1aad3dc1a2400281407625aad71ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330, 10)\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 로드 \n",
    "# - AI Hub 대화데이터: 한국어 SNS 멀티턴 대화 데이터\n",
    "# - 데이터 분리: train, validation\n",
    "from datasets import load_dataset\n",
    "import glob, random\n",
    "\n",
    "train_files = glob.glob('llm_data/ai_hub_dialogue_session2/train/*.json')\n",
    "valid_files = glob.glob('llm_data/ai_hub_dialogue_session2/validation/*.json')\n",
    "\n",
    "# 10%만 샘플링\n",
    "sample_train = random.sample(train_files, int(len(train_files) * 0.005))\n",
    "sample_valid = random.sample(valid_files, int(len(valid_files) * 0.005))\n",
    "\n",
    "dataset = load_dataset(\n",
    "    'json',\n",
    "    data_files={\n",
    "        'train': sample_train,\n",
    "        'validation': sample_valid\n",
    "    },\n",
    "    field='sessionInfo'\n",
    ")\n",
    "print(dataset['train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd4d975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde4c8eeddaf4520a1164a24b8ccf378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/330 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a59d25306cd45f990db95caa9b6ccb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': '안녕하세요! 요즘에는 여행을 못 다니지만, 가끔 국내여행을 가곤 해요. 힐링이 되는 시간이에요.', 'response': '여행은 정말 좋은 시간인 것 같아요. 제가 알려드릴만한 국내여행지가 있나요?'}\n",
      "(4833, 2)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리 및 대화 쌍 만들기\n",
    "# - train/validation/test 분리\n",
    "# - utterance 쌍(이전대화, 현재대화) 추출\n",
    "\n",
    "# 대화 파싱 함수: map(batched=True)로 여러 쌍을 한번에 반환 할 수 있다\n",
    "def extract_pairs(batch):\n",
    "    contexts = []\n",
    "    responses = []\n",
    "    for example in batch['dialog']:\n",
    "        for i in range(1, len(example)):\n",
    "            contexts.append(example[i-1]['utterance']) # 이전 대화\n",
    "            responses.append(example[i]['utterance']) # 현재 대화\n",
    "    return {\n",
    "        'context': contexts,\n",
    "        'response': responses\n",
    "    }\n",
    "\n",
    "# utterance 쌍 추출, map 사용: 리스트 컬럼 생성\n",
    "train_pairs = dataset['train'].map(\n",
    "    extract_pairs, \n",
    "    remove_columns=dataset['train'].column_names,\n",
    "    batched=True\n",
    ")\n",
    "valid_pairs = dataset['validation'].map(\n",
    "    extract_pairs, \n",
    "    remove_columns=dataset['validation'].column_names,\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "# flatten으로 리스트 풀기\n",
    "train_pairs = train_pairs.flatten()\n",
    "valid_pairs = valid_pairs.flatten()\n",
    "\n",
    "# validation -> validation/test 분리\n",
    "split_dataset = valid_pairs.train_test_split(test_size=0.5, seed=42)\n",
    "valid_pairs = split_dataset['train']\n",
    "test_pairs = split_dataset['test']\n",
    "\n",
    "print(train_pairs[0])\n",
    "print(train_pairs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42335820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "d:\\AI\\Pytorch\\deep-learning\\.venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "학습 데이터 개수: 4833\n",
      "검증 데이터 개수: 298\n",
      "배치 크기: 8\n",
      "학습 로더 길이: 605\n",
      "검증 로더 길이: 38\n"
     ]
    }
   ],
   "source": [
    "# Dataset, DataLoader 생성\n",
    "# - Hugging Face Dataset -> PyTorch Dataset 클래스로 감싸기\n",
    "# - DataLoader 생성\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 토크나이저 준비: MT5 모델\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/mt5-small')\n",
    "\n",
    "class DialogueDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, tokenizer, max_length=128): # 파라미터 초기 셋팅\n",
    "        self.dataset=hf_dataset\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_length=max_length\n",
    "    \n",
    "    def __len__(self): # dataset 길이 리턴\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        context = item['context']\n",
    "        response = item['response']\n",
    "\n",
    "        # 토크나이즈\n",
    "        inputs = self.tokenizer(\n",
    "            context,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        labels = self.tokenizer(\n",
    "            response,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0), # 불필요한 squeeze(0) 앞 배치 차원만 제거\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'labels': labels['input_ids'].squeeze(0)\n",
    "        }\n",
    "\n",
    "# Dataset 생성\n",
    "train_dataset = DialogueDataset(train_pairs, tokenizer)\n",
    "valid_dataset = DialogueDataset(valid_pairs, tokenizer)\n",
    "test_dataset = DialogueDataset(test_pairs, tokenizer)\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=8\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# 데이터 확인\n",
    "batch = next(iter(train_loader))\n",
    "print(batch['input_ids'].shape) # torch.Size([32, 128])\n",
    "print(batch['attention_mask'].shape) # torch.Size([32, 128])\n",
    "print(batch['labels'].shape) # torch.Size([32, 128])\n",
    "\n",
    "print(\"학습 데이터 개수:\", len(train_dataset))\n",
    "print(\"검증 데이터 개수:\", len(valid_dataset))\n",
    "print(\"배치 크기:\", train_loader.batch_size)\n",
    "print(\"학습 로더 길이:\", len(train_loader))\n",
    "print(\"검증 로더 길이:\", len(valid_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b7b67e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.8.0+cu129, Device: cuda\n",
      "PeftModelForSeq2SeqLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MT5ForConditionalGeneration(\n",
      "      (shared): Embedding(250112, 512)\n",
      "      (encoder): MT5Stack(\n",
      "        (embed_tokens): Embedding(250112, 512)\n",
      "        (block): ModuleList(\n",
      "          (0): MT5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): MT5LayerSelfAttention(\n",
      "                (SelfAttention): MT5Attention(\n",
      "                  (q): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "                  (v): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "                  (relative_attention_bias): Embedding(32, 6)\n",
      "                )\n",
      "                (layer_norm): MT5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): MT5LayerFF(\n",
      "                (DenseReluDense): MT5DenseGatedActDense(\n",
      "                  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): NewGELUActivation()\n",
      "                )\n",
      "                (layer_norm): MT5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1-7): 7 x MT5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): MT5LayerSelfAttention(\n",
      "                (SelfAttention): MT5Attention(\n",
      "                  (q): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "                  (v): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "                )\n",
      "                (layer_norm): MT5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): MT5LayerFF(\n",
      "                (DenseReluDense): MT5DenseGatedActDense(\n",
      "                  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): NewGELUActivation()\n",
      "                )\n",
      "                (layer_norm): MT5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_layer_norm): MT5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (decoder): MT5Stack(\n",
      "        (embed_tokens): Embedding(250112, 512)\n",
      "        (block): ModuleList(\n",
      "          (0): MT5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): MT5LayerSelfAttention(\n",
      "                (SelfAttention): MT5Attention(\n",
      "                  (q): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "                  (v): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "                  (relative_attention_bias): Embedding(32, 6)\n",
      "                )\n",
      "                (layer_norm): MT5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): MT5LayerCrossAttention(\n",
      "                (EncDecAttention): MT5Attention(\n",
      "                  (q): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "                  (v): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "                )\n",
      "                (layer_norm): MT5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (2): MT5LayerFF(\n",
      "                (DenseReluDense): MT5DenseGatedActDense(\n",
      "                  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): NewGELUActivation()\n",
      "                )\n",
      "                (layer_norm): MT5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1-7): 7 x MT5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): MT5LayerSelfAttention(\n",
      "                (SelfAttention): MT5Attention(\n",
      "                  (q): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "                  (v): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "                )\n",
      "                (layer_norm): MT5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): MT5LayerCrossAttention(\n",
      "                (EncDecAttention): MT5Attention(\n",
      "                  (q): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "                  (v): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=512, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "                )\n",
      "                (layer_norm): MT5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (2): MT5LayerFF(\n",
      "                (DenseReluDense): MT5DenseGatedActDense(\n",
      "                  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "                  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): NewGELUActivation()\n",
      "                )\n",
      "                (layer_norm): MT5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_layer_norm): MT5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "# - 모델 본체 동결 처리: Feature Extraction\n",
    "# - LoRA 파인튜닝 적용\n",
    "# - Early Stopping 적용\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.amp import GradScaler, autocast\n",
    "import os\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('google/mt5-small') # MT5 모델 불러온다\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'PyTorch Version: {torch.__version__}, Device: {device}')\n",
    "\n",
    "# 모델 전체를 GPU/CPU 디바이스 메모리로 이동\n",
    "model = model.to(device)\n",
    "\n",
    "# 모델 본체 동결 처리: Feature Extraction\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "# # LoRA 대상 모듈 자동 추출\n",
    "# target_modules = []\n",
    "# for name, module in model.named_modules():\n",
    "#     if any(x in name for x in [\"SelfAttention.q\", \"SelfAttention.k\", \"SelfAttention.v\", \"SelfAttention.o\"]):\n",
    "#         target_modules.append(name)\n",
    "\n",
    "# print(\"LoRA target modules:\", target_modules)\n",
    "\n",
    "# LoRA 적용: LoRA 모듈만 학습되도록 설정(경량 파인튜닝)\n",
    "lora_config = LoraConfig(\n",
    "    r=8, # 작은 rank(r=8)로 효율적인 파인튜닝 가능\n",
    "    lora_alpha=32, # LoRA scaling factor\n",
    "    # target_modules=['q', 'v'], # Attention 모듈의 Query/Value 부분에 LoRA 레이어 추가\n",
    "    target_modules=['q', 'v'], # Attention 모듈의 Query/Value 부분에 LoRA 레이어 추가\n",
    "    lora_dropout=0.1, # 드롭아웃\n",
    "    bias='none',\n",
    "    task_type='SEQ_2_SEQ_LM' # 대화 응답 생성은 Seq2Seq LM\n",
    ")\n",
    "# LoRA 모델 생성\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# Automatic Mixed Precision(AMP) 학습을 위한 GradScaler 준비\n",
    "# Automatic Mixed Precision(AMP)은 모델 파라미터는 FP32로 유지하면서 연산(곱셈·덧셈 등)만 FP16으로 자동 전환하여, \n",
    "# 정밀도 손실 없이 메모리와 연산 효율을 극대화하는 기술\n",
    "scaler = GradScaler()\n",
    "num_epochs = 5\n",
    "\n",
    "# Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.0, path='./llm_models/21_transformer_dialogue_chatbot/best_model.pt'):\n",
    "        self.patience=patience\n",
    "        self.min_delta=min_delta\n",
    "        self.best_loss=None\n",
    "        self.counter=0\n",
    "        self.early_stop=False\n",
    "        self.path=path\n",
    "    \n",
    "    def __call__(self, valid_loss, model):\n",
    "        # 최조 손실값에 해당하는 모델 가중치 저장\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss=valid_loss\n",
    "            self.save_checkpoint(model)\n",
    "        \n",
    "        # 성능 개선 -> 최적 모델 갱신\n",
    "        elif valid_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss=valid_loss\n",
    "            self.counter=0\n",
    "            self.save_checkpoint(model)\n",
    "        \n",
    "        # 개선 없음\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop=True\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        # 디렉토리만 생성\n",
    "        folder = os.path.dirname(self.path)\n",
    "        if folder !='' and not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        # 모델 가중치 저장\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        print(f' Best model saved at {self.path}')\n",
    "\n",
    "# Early Stopping 객체 생성\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.001)\n",
    "\n",
    "# 모델 확인\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a68a5035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|██████████| 605/605 [25:51<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 36.5985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Valid]: 100%|██████████| 38/38 [00:29<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Valid Loss: 20.4426\n",
      " Best model saved at ./llm_models/21_transformer_dialogue_chatbot/best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]: 100%|██████████| 605/605 [25:48<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 15.8730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Valid]: 100%|██████████| 38/38 [00:29<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Valid Loss: 9.2546\n",
      " Best model saved at ./llm_models/21_transformer_dialogue_chatbot/best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Train]: 100%|██████████| 605/605 [25:49<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 9.8985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Valid]: 100%|██████████| 38/38 [00:29<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Valid Loss: 7.2316\n",
      " Best model saved at ./llm_models/21_transformer_dialogue_chatbot/best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Train]: 100%|██████████| 605/605 [25:50<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 8.0731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Valid]: 100%|██████████| 38/38 [00:29<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Valid Loss: 6.1560\n",
      " Best model saved at ./llm_models/21_transformer_dialogue_chatbot/best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Train]: 100%|██████████| 605/605 [25:50<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 6.9918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Valid]: 100%|██████████| 38/38 [00:29<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Valid Loss: 5.3459\n",
      " Best model saved at ./llm_models/21_transformer_dialogue_chatbot/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    model.train() # 학습 모드 지정\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Train Loop\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch+1} [Train]'):\n",
    "        batch = { k: v.to(device) for k, v in batch.items() } # 딕셔너리 형태로 생성, 학습데이터 GPU 지정\n",
    "        optimizer.zero_grad() # 오차역전파 코드, 미분 전 가중치/바이어스 파라미터 초기화\n",
    "\n",
    "        # AMP(Automatic Mixed Precision) GPU에서 연산 속도와 메모리 효율 향상\n",
    "        # with autocast(device_type='cuda', dtype=torch.float16):\n",
    "        #     outputs = model(**batch) # 딕셔너리 형태 학습데이터를 그대로 모델에 전달, 코드가 깔끔하고 범용적으로 사용한다\n",
    "        #     loss = outputs.loss # 손실값\n",
    "        # scaler.scale(loss).backward() # 미분 연산\n",
    "        # scaler.step(optimizer) # 미분 연산 후 가중치/바이어스 파라미터 업데이트\n",
    "        # scaler.update()\n",
    "\n",
    "        with autocast(device_type='cuda', enabled=False):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() # 손실 누적\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval() # 검증/추론 모드 지정\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader, desc=f'Epoch {epoch+1} [Valid]'):\n",
    "            batch = { k: v.to(device) for k, v in batch.items() }\n",
    "\n",
    "            # AMP(Automatic Mixed Precision) GPU에서 연산 속도와 메모리 효율 향상\n",
    "            # with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            #     outputs = model(**batch) # 검증 모델 예측\n",
    "            #     loss = outputs.loss # 검증 손실값\n",
    "\n",
    "            with autocast(device_type='cuda', enabled=False):\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "\n",
    "            total_val_loss += loss.item() # 검증 손실값 누적    \n",
    "    avg_val_loss = total_val_loss / len(valid_loader)\n",
    "    print(f'Epoch {epoch+1}, Valid Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # Early Stopping 체크\n",
    "    early_stopping(valid_loss=avg_val_loss, model=model)\n",
    "    if early_stopping.early_stop:\n",
    "        print('Early stopping triggered.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fad4dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': '안녕하세요! 요즘에는 여행을 못 다니지만, 가끔 국내여행을 가곤 해요. 힐링이 되는 시간이에요.', 'response': '여행은 정말 좋은 시간인 것 같아요. 제가 알려드릴만한 국내여행지가 있나요?'}\n",
      "{'context': '안녕? 나궁금한점이 생겨서 물어보러왔어. ', 'response': '오렌지 나눠주고 오신다더니 2주만에 오셨군요.  지난번 국립제주박물관에 대한 답변에는 만족하십니까? '}\n"
     ]
    }
   ],
   "source": [
    "print(train_pairs[0])\n",
    "print(valid_pairs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
