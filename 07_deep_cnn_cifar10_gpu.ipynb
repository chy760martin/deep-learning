{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep CNN(Convolutional Neural Network) - CIFAR10 Dataset\n",
    "# airplane(0),automobile(1),bird(2),cat(3),deer(4),dog(5),frog(6),horse(7),ship(8),truck(9)\n",
    "# CIFAR10 데이터에서 가각의 이미지는 32x32 크기의 작은 컬러 이미지\n",
    "# 32 x 32 x 3 형상(shape)을 가지는 아주 작은 컬러 데이터\n",
    "\n",
    "# 딥러닝 Deep CNN 아키텍처\n",
    "# [<Feature Extractor>\n",
    "# conv1>relu>conv2>relu>pooling>dropout -> conv3>relu>conv4>relu>pooling>dropout ->\n",
    "# conv5>relu>pooling>dropout -> conv6>relu>pooling>dropout -> conv7>relu>pooling>dropout]\n",
    "\n",
    "# [ <Fully-Connected>\n",
    "# Flatten]\n",
    "\n",
    "# [<Classification>\n",
    "# fc1>relu>Dropout -> fc2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decedca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) import, GPU 설정\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('pytorch version : ', torch.__version__, ', device : ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38674761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) CIFAR10 Dataset 다운로드\n",
    "\n",
    "# CIFAR10 Dataset 데이터 증강(augmentation) 및 정규화 설정\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 테스트 데이터셋은 데이터 증강(augmentation) 없이 정규화만 수행\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) )\n",
    "])\n",
    "\n",
    "# train\n",
    "train_dataset = datasets.CIFAR10(root='./data/CIFAR10_data',\n",
    "                               train=True,\n",
    "                               transform=transform_train,\n",
    "                               download=True)\n",
    "# test\n",
    "test_dataset = datasets.CIFAR10(root='./data/CIFAR10_data',\n",
    "                               train=False,\n",
    "                               transform=transform_test,\n",
    "                               download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a9ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 Dataset 확인\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) CIFAR10 Dataset 데이터 분리 - train 85% : validation 15%\n",
    "train_dataset_size = int(len(train_dataset) * 0.85) # train 85%\n",
    "# validation_dataset_size = int(len(train_dataset) * 0.15) # validation 15%\n",
    "validation_dataset_size = len(train_dataset) - train_dataset_size # validation 15%\n",
    "train_dataset, validation_dataset = random_split(dataset=train_dataset,\n",
    "                                                 lengths=[train_dataset_size, validation_dataset_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 Dataset 데이터 분리 확인\n",
    "print(len(train_dataset), len(validation_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) batch, dataloader 생성\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# train\n",
    "train_dataset_loader = DataLoader(dataset=train_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True)\n",
    "\n",
    "# validation\n",
    "validation_dataset_loader = DataLoader(dataset=validation_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=False)\n",
    "\n",
    "# test\n",
    "test_dataset_loader = DataLoader(dataset=test_dataset,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5244c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) CIFAR10 Dataset 1개 배치 데이터 확인\n",
    "images, labels = next(iter(train_dataset_loader))\n",
    "\n",
    "# labels map 생성\n",
    "labels_map = { v:k for k, v in train_dataset.dataset.class_to_idx.items() }\n",
    "print(labels_map)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "cols, rows = 4, 4\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(images), size=(1,)).item()\n",
    "    img, label = images[sample_idx], labels[sample_idx].item()\n",
    "    img = img * 0.5 + 0.5 # 복원\n",
    "    \n",
    "    plt.subplot(cols, rows, i)\n",
    "    plt.imshow(torch.permute(img, (1,2,0)))\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eab1ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 딥러닝 Deep CNN 아키텍처\n",
    "\n",
    "# <Feature Extractor>\n",
    "# conv1>relu>conv2>relu>pooling>dropout -> conv3>relu>conv4>relu>pooling>dropout ->\n",
    "# conv5>relu>pooling>dropout -> conv6>relu>pooling>dropout -> conv7>relu>pooling>dropout\n",
    "\n",
    "# <Fully-Connected>\n",
    "# Flatten \n",
    "\n",
    "# <Classification>\n",
    "# fc1>relu>Dropout -> fc2\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # conv1, conv2\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        # conv3, conv4\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # conv5\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        # conv6\n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        # conv7\n",
    "        self.conv7 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "                \n",
    "        # pooling\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # fc1, fc2\n",
    "        self.fc1 = nn.Linear(1 * 1 * 256, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        # dropout\n",
    "        self.dropout25 = nn.Dropout(p=0.25)\n",
    "        self.dropout50 = nn.Dropout(p=0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 패딩이 적용되었기 때문에 컨볼루션층을 통과한 데이터는 크기는 변하지 않고 필터 개수와 동일하게 출력채널 개수만 변함\n",
    "        # 맥스풀링층을 통과한 데이터는 1/2로 바뀌지만 채널 개수는 변하지 않음\n",
    "\n",
    "        # conv1, conv2 data shape = (H, W, C) = (32, 32, 3)\n",
    "        x = self.conv1(x) # (32, 32, 3)\n",
    "        x = torch.relu(x) # (32, 32, 32)\n",
    "        x = self.conv2(x) # (32, 32, 32)\n",
    "        x = torch.relu(x) # (32, 32, 32)\n",
    "        x = self.pooling(x) # (32, 32, 32)\n",
    "        x = self.dropout25(x) # (16, 16, 32)\n",
    "\n",
    "        # conv3, conv4\n",
    "        x = self.conv3(x) # (16, 16, 32)\n",
    "        x = torch.relu(x) # (16, 16, 64)\n",
    "        x = self.conv4(x) # (16, 16, 64)\n",
    "        x = torch.relu(x) # (16, 16, 64)\n",
    "        x = self.pooling(x) # (16, 16, 64)\n",
    "        x = self.dropout25(x) # (8, 8, 64)\n",
    "\n",
    "        # conv5\n",
    "        x = self.conv5(x) # (8, 8, 64)\n",
    "        x = torch.relu(x) # (8, 8, 128)\n",
    "        x = self.pooling(x) # (8, 8, 128)\n",
    "        x = self.dropout25(x) # (4, 4, 128)\n",
    "\n",
    "        # conv6\n",
    "        x = self.conv6(x) # (4, 4, 128)\n",
    "        x = torch.relu(x) # (4, 4, 128)\n",
    "        x = self.pooling(x) # (4, 4, 128)\n",
    "        x = self.dropout25(x) # (2, 2, 128)\n",
    "\n",
    "        # conv7\n",
    "        x = self.conv7(x) # (2, 2, 128)\n",
    "        x = torch.relu(x) # (2, 2, 256)\n",
    "        x = self.pooling(x) # (2, 2, 256)\n",
    "        x = self.dropout25(x) # (1, 1, 256)\n",
    "\n",
    "        # (높이,너비,채널)3차원 텐서이므로 완전연결층(Fully-Connected)과 연결을 위해 view() 명령어를 이용해서 3차원 텐서를 1차원 vector로 만들어 주는 역할\n",
    "        # view(-1, 벡터크기) 이용해서 배치차원은 유지되고 3차원 텐서는 1차원 벡터로 변환됨\n",
    "        x = x.view(-1, 1 * 1 * 256)\n",
    "\n",
    "        # Linear\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout50(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ce4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Model 객체 생성\n",
    "model = CNNModel().to(DEVICE)\n",
    "\n",
    "# loss function\n",
    "loss_function = nn.CrossEntropyLoss() # Softmax() 함수 포함되어 있음\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Model 정보\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a10568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Model train 함수\n",
    "def model_train(dataloader, model, loss_function, optimizer):\n",
    "    model.train() # 확습모드\n",
    "\n",
    "    train_loss_sum = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    total_train_batch = len(dataloader)\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        # 처음 크기는 (batch_size, 1, 28, 28) -> (batch_size, 784) 1차원 벡터로 변환\n",
    "        x_train = images.to(DEVICE)\n",
    "        y_train = labels.to(DEVICE)\n",
    "\n",
    "        # 모델 예측값 게산\n",
    "        outputs = model(x_train)\n",
    "\n",
    "        # 손실함수값 계산\n",
    "        loss = loss_function(outputs, y_train)\n",
    "\n",
    "        # 오차역전파\n",
    "        optimizer.zero_grad() # 미분 연산 초기화\n",
    "        loss.backward() # 미분 연산\n",
    "        optimizer.step() # 미분 연산 후 가중치 바이어스 파라미터 업데이트\n",
    "\n",
    "        train_loss_sum += loss.item()\n",
    "        train_total += y_train.size(0)\n",
    "        train_correct += (torch.argmax(outputs, 1) == y_train).sum().item()\n",
    "    train_avg_loss = train_loss_sum / total_train_batch # 평균 오차 계산\n",
    "    train_avg_accuracy = 100 * train_correct / train_total # 평균 정확도 계산\n",
    "\n",
    "    return train_avg_loss, train_avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28e3f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Model evaluate 함수\n",
    "def model_evaluate(dataloader, model, loss_function, optimizer):\n",
    "    model.eval() # 추론모드\n",
    "\n",
    "    with torch.no_grad(): # 미분 연산 하지 않음\n",
    "        val_loss_sum = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        total_val_batch = len(dataloader)\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            # 처음 크기는 (batch_size, 1, 28, 28) -> (batch_size, 784) 1차원 벡터로 변환\n",
    "            x_val = images.to(DEVICE)\n",
    "            y_val = labels.to(DEVICE)\n",
    "\n",
    "            # 모델 예측값 게산\n",
    "            outputs = model(x_val)\n",
    "\n",
    "            # 손실함수값 계산\n",
    "            loss = loss_function(outputs, y_val)\n",
    "\n",
    "            # 오차역전파\n",
    "            # optimizer.zero_grad() # 미분 연산 초기화\n",
    "            # loss.backward() # 미분 연산\n",
    "            # optimizer.step() # 미분 연산 후 가중치 바이어스 파라미터 업데이트\n",
    "\n",
    "            val_loss_sum += loss.item()\n",
    "            val_total += y_val.size(0)\n",
    "            val_correct += (torch.argmax(outputs, 1) == y_val).sum().item()\n",
    "        val_avg_loss = val_loss_sum / total_val_batch # 평균 오차 계산\n",
    "        val_avg_accuracy = 100 * val_correct / val_total # 평균 정확도 계산\n",
    "\n",
    "        return val_avg_loss, val_avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41646968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Model test 함수\n",
    "def model_test(dataloader, model):\n",
    "    model.eval() # 추론모드\n",
    "\n",
    "    with torch.no_grad(): # 미분 연산 하지 않음\n",
    "        test_loss_sum = 0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        total_test_batch = len(dataloader)\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            # 처음 크기는 (batch_size, 1, 28, 28) -> (batch_size, 784) 1차원 벡터로 변환\n",
    "            x_test = images.to(DEVICE)\n",
    "            y_test = labels.to(DEVICE)\n",
    "\n",
    "            # 모델 예측값 게산\n",
    "            outputs = model(x_test)\n",
    "\n",
    "            # 손실함수값 계산\n",
    "            loss = loss_function(outputs, y_test)\n",
    "\n",
    "            # 오차역전파\n",
    "            # optimizer.zero_grad() # 미분 연산 초기화\n",
    "            # loss.backward() # 미분 연산\n",
    "            # optimizer.step() # 미분 연산 후 가중치 바이어스 파라미터 업데이트\n",
    "\n",
    "            test_loss_sum += loss.item()\n",
    "            test_total += y_test.size(0)\n",
    "            test_correct += (torch.argmax(outputs, 1) == y_test).sum().item()\n",
    "        test_avg_loss = test_loss_sum / total_test_batch\n",
    "        test_avg_accuracy = 100 * test_correct / test_total\n",
    "\n",
    "        print('accuracy = ', test_avg_accuracy, ', loss = ', test_avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Model 학습 \n",
    "train_loss_list = []\n",
    "train_accuracy_list = []\n",
    "\n",
    "val_loss_list = []\n",
    "val_accuracy_list = []\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # train\n",
    "    train_avg_loss, train_avg_accuracy = model_train(dataloader=train_dataset_loader,\n",
    "                                                     model=model,\n",
    "                                                     loss_function=loss_function,\n",
    "                                                     optimizer=optimizer)\n",
    "    train_loss_list.append(train_avg_loss)\n",
    "    train_accuracy_list.append(train_avg_accuracy)\n",
    "\n",
    "    # evaluate\n",
    "    val_avg_loss, val_avg_accuracy = model_evaluate(dataloader=validation_dataset_loader,\n",
    "                                                     model=model,\n",
    "                                                     loss_function=loss_function,\n",
    "                                                     optimizer=optimizer)\n",
    "    val_loss_list.append(val_avg_loss)\n",
    "    val_accuracy_list.append(val_avg_accuracy)\n",
    "\n",
    "    # print\n",
    "    print(\n",
    "        'epoch : ', '%02d' % (epoch + 1),\n",
    "        'train loss = ', '{:4f}'.format(train_avg_loss), ', train acc = ', '{:4f}'.format(train_avg_accuracy),\n",
    "        'val loss = ', '{:4f}'.format(val_avg_loss), ', val acc = ', '{:4f}'.format(val_avg_accuracy)\n",
    "    )\n",
    "\n",
    "# time\n",
    "end_time = datetime.now()\n",
    "print('elapsed time => ', end_time -start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0645fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Test Dataset 정확도, 오차 테스트\n",
    "model_test(dataloader=test_dataset_loader,\n",
    "            model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c81a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 시각화 - 손실함수\n",
    "plt.title('Loss Trend')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(train_loss_list, label='train loss')\n",
    "plt.plot(val_loss_list, label='validation loss')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# 시각화 - 정확도\n",
    "plt.title('Accuracy Trend')\n",
    "plt.xlabel('accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(train_accuracy_list, label='train accuracy')\n",
    "plt.plot(val_accuracy_list, label='validation accuracy')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d6511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) Save the model checkpoint\n",
    "torch.save(model.state_dict(), '.\\\\models\\\\model_deep_cnn_cifar10.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15) 테스트 - 모델 추론 및 예측값 추출\n",
    "model = CNNModel().to(DEVICE)\n",
    "model.load_state_dict(torch.load('.\\\\models\\\\model_deep_cnn_cifar10.ckpt'))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# test dataloader\n",
    "test_image_loader = DataLoader(dataset=test_dataset,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               shuffle=False)\n",
    "# test dataset 1개 배치 추출\n",
    "test_images, test_labels = next(iter(test_image_loader))\n",
    "\n",
    "# 학습/정답 데이터\n",
    "x_test = test_images.to(DEVICE)\n",
    "y_test = test_labels.to(DEVICE)\n",
    "\n",
    "# 모델 추론\n",
    "outputs = model(x_test)\n",
    "\n",
    "# 모델 예측값 추출\n",
    "_, preds = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16) 시각화 - 추론 및 정답 비교\n",
    "\n",
    "# labels map 생성 - train_dataset 에서 정답 label map을 생성\n",
    "labels_map = { v : k for k, v in train_dataset.dataset.class_to_idx.items() }\n",
    "print(labels_map)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 7))\n",
    "\n",
    "cols, rows = 4, 4\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "\n",
    "    # torch.randint()를 통한 1개의 index 추출\n",
    "    sample_idx = torch.randint(len(x_test), size=(1,)).item()\n",
    "    \n",
    "    # test dataloder에서 image, label, pred 값을 추출하여 시각화 비교\n",
    "    img, label, pred = test_images[sample_idx], test_labels[sample_idx].item(), preds[sample_idx].item()\n",
    "    img = img * 0.5 + 0.5 # 복원\n",
    "\n",
    "    plt.title('label:' + labels_map[label] + '\\npred:' + labels_map[pred])\n",
    "    plt.imshow(torch.permute(img, (1, 2, 0))) # 본래 이미지 shape (3, 224, 224) -> 시각화 하기 위해서 (224, 224, 3) 변환\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
