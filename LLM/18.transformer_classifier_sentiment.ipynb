{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094ec65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer 모델 구축 - Transformer Sentiment Classifier 감정 분류 모델\n",
    "# 학습 목표 - 실무에서 사용되는 파이프라인 이해 및 적용\n",
    "# - 1. 데이터 로드 & 확인: 결측치 제거(None, \"\")\n",
    "# - 2. 토크나이저 적용: Hugging Face DistilBertTokenizer 베이스 모델 사용\n",
    "# - 3. 데이터셋 -> DataLoader 변환: DistilBertTokenizer 베이스 모델 토크나이저에서 DataLoader 로 바로 변환, Custom Dataset 필요 없음\n",
    "# - 4. 모델정의 & GPU설정 & 전이학습 & 본체 동결(Feature Extraction) + LoRA Fine-tuning 조합 & EarlyStopping 클래스 정의\n",
    "# - 전이 학습: DistilBertForSequenceClassification 베이스 모델(distilbert-base-uncased), num_labels=2 긍정/부정 2개 클래스\n",
    "# - 본체 동결: model.distilbert.parameters()는 사전학습된 본체(embedding + transformer 블록)의 모든 파라미터를 의미, 따라서 학습은 classifier 레이어(pre_classifier, classifier)만 진행된다\n",
    "# - LoRA: Attention의 q_lin, v_lin 레이어에서 LoRA가 768차원 → 8차원 축소 → 768차원 복원 과정을 거쳐 업데이트를 추가하는 구조\n",
    "# - EarlyStopping: - 과적합 방지 + 최적 모델 확보 + 자원 절약 + EarlyStopping 발동 시점에서 최적 모델 가중치를 자동 저장\n",
    "# - 5. 최적화 설정 & 학습 루프 & 검증 루프 EarlyStopping 클래스 적용\n",
    "# - 최적화 설정: autocast(속도 향상) GradScaler(안정적 학습) 적용\n",
    "\n",
    "# DistilBert 구조 특징 \n",
    "# - BERT 계열 모델은 Transformer의 Encoder 부분만 사용한다\n",
    "# - 입력 문장을 임베딩 -> 여러층의 Transformer Encoder 블록 -> [CLS]토큰 벡터 추출 -> 분류기(Classifier)\n",
    "\n",
    "# DistilBertForSequenceClassification 내부 흐름\n",
    "# 입력(DataLoader 배치): \n",
    "# - input_ids:(batch_size,seq_len)->(32,128)\n",
    "# - attention_mask: (32,128)\n",
    "# - labels:(32)\n",
    "# DistilBertForSequenceClassification(\n",
    "#   (distilbert): DistilBertModel(\n",
    "#     (embeddings): Embeddings(\n",
    "#       (word_embeddings): Embedding(30522, 768, padding_idx=0) : (32,128) -> (32,128,768) (batch_size,seq_len,hidden_dim)\n",
    "#       (position_embeddings): Embedding(512, 768) : (32,128) -> (32,128,768) (batch_size,seq_len,hidden_dim)\n",
    "#       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) : (32,128,768) (batch_size,seq_len,hidden_dim) 유지\n",
    "#       (dropout): Dropout(p=0.1, inplace=False) : (32,128,768) (batch_size,seq_len,hidden_dim) 유지\n",
    "#     )\n",
    "#     (transformer): Transformer(\n",
    "#       (layer): ModuleList(\n",
    "#         (0-5): 6 x TransformerBlock( : (32,128,768) (batch_size,seq_len,hidden_dim) 유지\n",
    "#           (attention): DistilBertSdpaAttention(\n",
    "#             (dropout): Dropout(p=0.1, inplace=False)\n",
    "#             (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
    "#             (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
    "#             (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
    "#             (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
    "#           )\n",
    "#           (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) : (32,128,768) (batch_size,seq_len,hidden_dim) 유지\n",
    "#           (ffn): FFN( : (32,128,768) (batch_size,seq_len,hidden_dim)\n",
    "#             (dropout): Dropout(p=0.1, inplace=False)\n",
    "#             (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
    "#             (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
    "#             (activation): GELUActivation()\n",
    "#           )\n",
    "#           (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) : (32,128,768) (batch_size,seq_len,hidden_dim) 유지\n",
    "#         )\n",
    "#       )\n",
    "#     ) : Transformer 출력(output_layer_norm 이후) (32,128,768) (batch_size,seq_len,hidden_dim) shape을 가지며\n",
    "#         내부 forward()에서 hidden_states[:, 0, :] 선택([CSL] 벡터를 추출) -> (32,768) (batch_size,hidden_dim) 변경 한다\n",
    "#   ) \n",
    "#   (pre_classifier): Linear(in_features=768, out_features=768, bias=True) : (32,768) -> (32,768) (batch_size,hidden_dim)\n",
    "#   (classifier): Linear(in_features=768, out_features=2, bias=True) : (32,768)@(768,2) -> (32,2) 입력 벡터와 가중치 행렬의 내적 계산\n",
    "#   (dropout): Dropout(p=0.2, inplace=False) : (32,768) (batch_size,hidden_dim) 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c229bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 본체 동결(Feature Extraction) + LoRA Fine-tuning 조합\n",
    "# - 원래 q_lin / v_lin은 Linear(768 → 768) 구조: LoRA는 이 weight를 그대로 두고, 추가로 저차원 랭크 행렬을 학습\n",
    "# - Attention의 q_lin, v_lin 레이어에서 LoRA가 768차원 → 8차원 축소 → 768차원 복원 과정을 거쳐 업데이트를 추가하는 구조\n",
    "\n",
    "# trainable params: 739,586 || all params: 67,694,596 || trainable%: 1.0925\n",
    "# PeftModelForSequenceClassification(\n",
    "#   (base_model): LoraModel(\n",
    "#     (model): DistilBertForSequenceClassification(\n",
    "#       (distilbert): DistilBertModel(\n",
    "#         (embeddings): Embeddings(\n",
    "#           (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
    "#           (position_embeddings): Embedding(512, 768)\n",
    "#           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "#           (dropout): Dropout(p=0.1, inplace=False)\n",
    "#         )\n",
    "#         (transformer): Transformer(\n",
    "#           (layer): ModuleList(\n",
    "#             (0-5): 6 x TransformerBlock(\n",
    "#               (attention): DistilBertSdpaAttention(\n",
    "#                 (dropout): Dropout(p=0.1, inplace=False)\n",
    "#                 (q_lin): lora.Linear(\n",
    "#                   (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
    "#                   (lora_dropout): ModuleDict(\n",
    "#                     (default): Dropout(p=0.1, inplace=False)\n",
    "#                   )\n",
    "#                   (lora_A): ModuleDict(\n",
    "#                     (default): Linear(in_features=768, out_features=8, bias=False)\n",
    "#                   )\n",
    "#                   (lora_B): ModuleDict(\n",
    "#                     (default): Linear(in_features=8, out_features=768, bias=False)\n",
    "#                   )\n",
    "#                   (lora_embedding_A): ParameterDict()\n",
    "#                   (lora_embedding_B): ParameterDict()\n",
    "#                   (lora_magnitude_vector): ModuleDict()\n",
    "#                 )\n",
    "#                 (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
    "#                 (v_lin): lora.Linear(\n",
    "#                   (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
    "#                   (lora_dropout): ModuleDict(\n",
    "#                     (default): Dropout(p=0.1, inplace=False)\n",
    "#                   )\n",
    "#                   (lora_A): ModuleDict(\n",
    "#                     (default): Linear(in_features=768, out_features=8, bias=False)\n",
    "#                   )\n",
    "#                   (lora_B): ModuleDict(\n",
    "#                     (default): Linear(in_features=8, out_features=768, bias=False)\n",
    "#                   )\n",
    "#                   (lora_embedding_A): ParameterDict()\n",
    "#                   (lora_embedding_B): ParameterDict()\n",
    "#                   (lora_magnitude_vector): ModuleDict()\n",
    "#                 )\n",
    "#                 (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
    "#               )\n",
    "#               (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "#               (ffn): FFN(\n",
    "#                 (dropout): Dropout(p=0.1, inplace=False)\n",
    "#                 (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
    "#                 (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
    "#                 (activation): GELUActivation()\n",
    "#               )\n",
    "#               (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "#             )\n",
    "#           )\n",
    "#         )\n",
    "#       )\n",
    "#       (pre_classifier): ModulesToSaveWrapper(\n",
    "#         (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
    "#         (modules_to_save): ModuleDict(\n",
    "#           (default): Linear(in_features=768, out_features=768, bias=True)\n",
    "#         )\n",
    "#       )\n",
    "#       (classifier): ModulesToSaveWrapper(\n",
    "#         (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
    "#         (modules_to_save): ModuleDict(\n",
    "#           (default): Linear(in_features=768, out_features=2, bias=True)\n",
    "#         )\n",
    "#       )\n",
    "#       (dropout): Dropout(p=0.2, inplace=False)\n",
    "#     )\n",
    "#   )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "909c366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'document', 'label'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'document', 'label'],\n",
      "    num_rows: 5000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드 & 확인\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Hugging Face datasets 라이브러리 함수(CSV,JSON.. 데이터 로드)\n",
    "dataset = load_dataset( # DatasetDict 형태로 반환\n",
    "    'csv', # csv 포멧 지정\n",
    "    data_files={ # train/test 데이터 각각 지정\n",
    "        'train': \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\",\n",
    "        'test': \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\"\n",
    "    },\n",
    "    delimiter='\\t' # 구분자, 현재 데이터에서는 탭으로 구분\n",
    ")\n",
    "\n",
    "# 결측치 제거\n",
    "all_clean_train = dataset[\"train\"].filter(lambda x: x[\"document\"] is not None and x[\"document\"].strip() != \"\")\n",
    "all_clean_test = dataset[\"test\"].filter(lambda x: x[\"document\"] is not None and x[\"document\"].strip() != \"\")\n",
    "\n",
    "# 데이터 축소\n",
    "clean_train = all_clean_train.select(range(10000))\n",
    "clean_test = all_clean_test.select(range(5000))\n",
    "\n",
    "print(clean_train)\n",
    "print(clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959e7d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 9976970, 'label': 0, 'input_ids': [101, 1463, 30006, 1457, 30008, 29996, 30019, 30025, 1012, 1012, 100, 100, 1459, 30011, 30020, 29997, 30011, 29994, 30019, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'id': 6270596, 'label': 1, 'input_ids': [101, 100, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 적용\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenizer_function(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"document\"],   # 문자열 리스트만 들어옴\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128 # 시퀀스 길이, 연산량 절반 이상 감소\n",
    "    )\n",
    "\n",
    "tokenized_train = clean_train.map(\n",
    "    tokenizer_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"document\"]\n",
    ")\n",
    "\n",
    "tokenized_test = clean_test.map(\n",
    "    tokenizer_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"document\"]\n",
    ")\n",
    "\n",
    "print(tokenized_train[0])\n",
    "print(tokenized_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7af3042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "torch.Size([32, 128]) torch.Size([32, 128]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 -> DataLoader 변환\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# collate_fn 함수 : Hugging Face Dataset에서 꺼낸 샘플은 파이썬 dict 형태, collate_fn() 각 샘플을 모아 PyTorch 텐서로 변환\n",
    "def collate_fn(batch): # batch 샘플 리스트 : [{'input_ids':[...],'attention_mask':[...],'label':[...]}, {...}, ...]\n",
    "    input_ids = torch.tensor([ item['input_ids'] for item in batch ]) # 토큰화된 문장\n",
    "    attention_mask = torch.tensor([ item['attention_mask'] for item in batch ]) # 패딩 여부\n",
    "    labels = torch.tensor([ item['label'] for item in batch ]) # 감성 분류 라벨(0=부정/1=긍정)\n",
    "\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
    "\n",
    "# train: 학습용 데이터, 배치크기 16, epoch 마다 데이터 순서 섞음\n",
    "train_loader = DataLoader(tokenized_train, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "# valid: 검증용 데이터, 학습 데이터에서 10%를 검증용으로 분리 Hugging Face에서 제공하는 train_test_split() 메서드\n",
    "valid_loader = DataLoader(tokenized_train.train_test_split(test_size=0.1)['test'], batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "# test: 테스트 데이터, 성능 최종 평가용\n",
    "test_loader = DataLoader(tokenized_test, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# train_loader 데이터 확인\n",
    "for batch in train_loader:\n",
    "    print(batch.keys())\n",
    "    print(batch['input_ids'].shape, batch['attention_mask'].shape, batch['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07545c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 739,586 || all params: 67,694,596 || trainable%: 1.0925\n",
      "PeftModelForSequenceClassification(\n",
      "  (base_model): LoraModel(\n",
      "    (model): DistilBertForSequenceClassification(\n",
      "      (distilbert): DistilBertModel(\n",
      "        (embeddings): Embeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (transformer): Transformer(\n",
      "          (layer): ModuleList(\n",
      "            (0-5): 6 x TransformerBlock(\n",
      "              (attention): DistilBertSdpaAttention(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (q_lin): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (v_lin): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (activation): GELUActivation()\n",
      "              )\n",
      "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pre_classifier): ModulesToSaveWrapper(\n",
      "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (classifier): ModulesToSaveWrapper(\n",
      "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "# - Feature Extraction + LoRA Fine-tuning 조합\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from torch.amp import autocast # 최신 API\n",
    "from torch.amp import GradScaler\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import os\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# DistilBertForSequenceClassification 베이스 모델(distilbert-base-uncased), num_labels=2 긍정/부정 2개 클래스\n",
    "model = DistilBertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2).to(device)\n",
    "\n",
    "# DistilBERT 본체 동결(Feature Extraction, Parameter Freezing, Weight Freezing)\n",
    "# - model.distilbert.parameters()는 사전학습된 본체(embedding + transformer 블록)의 모든 파라미터를 의미 한다\n",
    "# - requires_grad = False로 설정하면 역전파 시 이 파라미터들은 업데이트되지 않는다\n",
    "# - 따라서 학습은 classifier 레이어(pre_classifier, classifier)만 진행된다\n",
    "for param in model.distilbert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# LoRA config & warp\n",
    "# - trainable params: 739,586 || all params: 67,694,596 || trainable%: 1.0925, 학습 가능한 파라미터 수: 739,586(전체의 1.0925%)\n",
    "# - Attention의 q_lin, v_lin 레이어에서 LoRA가 768차원 → 8차원 축소 → 768차원 복원 과정을 거쳐 업데이트를 추가하는 구조\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=['q_lin', 'v_lin'], # DistilBERT attention\n",
    "    bias='none',\n",
    "    task_type='SEQ_CLS'\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 모델 확인\n",
    "model.print_trainable_parameters() # LoRA 적용 확인용\n",
    "print(model)\n",
    "\n",
    "# 최적화 설정\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# 반복횟수\n",
    "num_epochs = 3\n",
    "\n",
    "# EarlyStopping 클래스 정의\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.0, path='./llm_models/18_transformer_classifier_sentiment/best_model.pt'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.path = path\n",
    "    \n",
    "    def __call__(self, valid_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = valid_loss\n",
    "            self.save_checkpoint(model)\n",
    "        # 성능 개선 -> 최적 모델 갱신\n",
    "        elif valid_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = valid_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        # 개선 없음\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        # 디렉토리만 생성\n",
    "        folder = os.path.dirname(self.path)\n",
    "        if folder !=\"\" and not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            \n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        print(f'Best model saved at {self.path}')\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7d7c3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|██████████| 313/313 [01:54<00:00,  2.73it/s]\n",
      "1 [Valid]: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at ./llm_models/18_transformer_classifier_sentiment/best_model.pt\n",
      "Epoch 1 | Tran Loss: 0.6763 | Train Acc: 0.5619 | Valid Loss: 0.6614 | Valid Acc: 0.5890 | EarlyStopping: CONTINUE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]: 100%|██████████| 313/313 [02:02<00:00,  2.56it/s]\n",
      "2 [Valid]: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at ./llm_models/18_transformer_classifier_sentiment/best_model.pt\n",
      "Epoch 2 | Tran Loss: 0.6570 | Train Acc: 0.5929 | Valid Loss: 0.6498 | Valid Acc: 0.6010 | EarlyStopping: CONTINUE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Train]: 100%|██████████| 313/313 [02:02<00:00,  2.56it/s]\n",
      "3 [Valid]: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at ./llm_models/18_transformer_classifier_sentiment/best_model.pt\n",
      "Epoch 3 | Tran Loss: 0.6502 | Train Acc: 0.6081 | Valid Loss: 0.6452 | Valid Acc: 0.6250 | EarlyStopping: CONTINUE\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프: autocast(속도 향상) 적용, GradScaler(안정적 학습) 적용\n",
    "# autocast 적용: 연산을 FP16(half precision)과 FP32(full precision)중 적절히 선택해서 실행\n",
    "# - 속도 향상: 대부분의 연산을 FP16으로 처리해 GPU 연산 속도를 높인다\n",
    "# - 안정성 유지: 손실이 큰 연산(예시:소프트맥스,레이어정규화)은 FP32로 자동 변환해 정확도를 보장한다\n",
    "# GradScaler 적용: FP16 학습에서는 작은 값이 underflow(0으로 사라짐)될 위험이 있다\n",
    "# - 안정적 학습 보장: GradScaler는 손실(loss)를 크게 스케일링해서 역전파 시 그래디언트가 사라지지 않도록 한다\n",
    "# - 이후 업데이트 단계에서 다시 원래 크기로 되돌려 안정적인 학습을 보장한다. 즉 FP16 학습에서 발생할 수 있는 수치 불안정 문제를 해결하는 역할\n",
    "from tqdm import tqdm # 시각화(진행바)\n",
    "\n",
    "# DistilBert 구조 특징 \n",
    "# - BERT 계열 모델은 Transformer의 Encoder 부분만 사용한다\n",
    "# - 입력 문장을 임베딩 -> 여러층의 Transformer Encoder 블록 -> [CLS]토큰 벡터 추출 -> 분류기(Classifier)\n",
    "# DistilBertForSequenceClassification 내부 흐름\n",
    "# 1. 입력: (batch_size,seq_len)\n",
    "# 2. Encoder(DistilBERT 본체) \n",
    "# - Embedding: (batch_size,seq_len,hidden_dim) \n",
    "# - Transformer Block(6개): (batch_size,seq_len,hidden_dim)\n",
    "# 3. [CLS] 토큰 추출: (batch_size,hidden_dim)\n",
    "# 4. Classifier 레이어: (batch_size,num_labels)\n",
    "# 5. 출력: logits, loss\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # train\n",
    "    model.train() # 학습 모드 지정\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1} [Train]'):        \n",
    "        optimizer.zero_grad() # 오차역전파 코드, 미분 전 가중치/바이어스 파라미터 초기화\n",
    "        # 학습데이터 GPU 지정\n",
    "        input_ids = batch['input_ids'].to(device) # [32, 128]\n",
    "        attention_mask = batch['attention_mask'].to(device) # [32, 128]\n",
    "        labels = batch['labels'].to(device) # [32]\n",
    "\n",
    "        # 모델 forward(autocast 영역) 내부 shape 변환\n",
    "        # - 임베딩 레이어: (32,128) -> (32,128,768) \n",
    "        # - Transformer 블록: (32,128,768) -> (32,128,768)\n",
    "        # - CLS 토큰 추출: (32,768) \n",
    "        # - Classifier 레이어: (32,768) -> (32,2) \n",
    "        # - outputs.logits.shape: (32,2) \n",
    "        # - outputs.loss: scalar\n",
    "        with autocast('cuda'):\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits # (32,2)        \n",
    "        # 오차역전차\n",
    "        scaler.scale(loss).backward() # 미분 연산\n",
    "        scaler.step(optimizer) # 미분 연산 후 가중치/바이어스 파라미터 업데이트\n",
    "        scaler.update()        \n",
    "        # 손실 누적\n",
    "        total_loss += loss.item()\n",
    "        # Accuracy 계산\n",
    "        preds = logits.argmax(dim=-1) # 예측 클래스 (32,)\n",
    "        correct += (preds == labels).sum().item() # 맞춘 개수\n",
    "        total += labels.size(0)    \n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # validation\n",
    "    model.eval() # 검증/추론 모드\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # 검증/추론 모드에서는 미분 연산 처리 하지 않음\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader, desc=f'{epoch + 1} [Valid]'):\n",
    "            # 검증 데이터 GPU에 할당\n",
    "            input_ids = batch['input_ids'].to(device) # (32,128) (batch_size,seq_len), 토큰화된 문장 ID(각 문장을 토큰 단위로 숫자로 변환한 것)\n",
    "            attention_mask = batch['attention_mask'].to(device) # (32,128) (batch_size,seq_len), 패딩 토큰을 무시하기 위한 마스크 1=실제 토큰 0=패딩\n",
    "            labels = batch['labels'].to(device) # (32,) (batch_size,), 각 문장의 정답 라벨(긍정=1,부정=0 클래스)\n",
    "\n",
    "            with autocast('cuda'):\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits            \n",
    "            # 손실 누적\n",
    "            total_loss += loss.item()\n",
    "            # Accuracy 계산\n",
    "            # logits (32,2) (batch_size,num_labels), logits.argmax(dim=-1) (32,) 32개 각 샘플중 2개의 점수중 더 큰쪽의 인덱스(0또는1) 선택\n",
    "            preds = logits.argmax(dim=-1) # (32,)\n",
    "            # (preds == labels) 예측/정답을 비교해 True/False 벡터 생성\n",
    "            # ->.sum() True=1/False=0 계산해 맞춘 개수 합산(PyTorch 텐서)\n",
    "            # ->.item() 파이썬 숫자로 변환(파이썬 숫자 int/float)\n",
    "            correct += (preds == labels).sum().item() # (맞춘 개수 누적)\n",
    "            total += labels.size(0) # (32,)\n",
    "        # 손실 계산\n",
    "        # - 예시) 전체 검증데이터가 320개, 1배치가 32 -> 10번 배치 반복을 한다\n",
    "        # - 계산) total_loss 손실 누적 합산값 / 10(10번 배치), 즉 손실을 배치 개수로 나누어 배치 평균 손실을 구한다\n",
    "        valid_loss = total_loss / len(valid_loader)\n",
    "        valid_acc = correct / total # 정확도 계산\n",
    "\n",
    "        # Early Stopping 객체 호출\n",
    "        early_stopping(valid_loss, model)\n",
    "        status = 'STOP' if early_stopping.early_stop else 'CONTINUE' # # Early Stopping status 상태값\n",
    "\n",
    "        print(f'Epoch {epoch + 1} | Tran Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}'\n",
    "              f' | Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f} | EarlyStopping: {status}')\n",
    "        \n",
    "        # Early Stopping 체크\n",
    "        if early_stopping.early_stop: # early_stop=True 학습 종료\n",
    "            print('Early stopping triggered')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e98212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DistilBertForSequenceClassification(\n",
       "      (distilbert): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x TransformerBlock(\n",
       "              (attention): DistilBertSdpaAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pre_classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적 모델 로드\n",
    "\n",
    "# torch.load() 파일에서 파라미터(가중치) 딕셔너리를 불러옴\n",
    "# model.load_state_dict() 불러온 파리미터를 모델 구조에 맞게 적용\n",
    "model.load_state_dict(torch.load('./llm_models/18_transformer_classifier_sentiment/best_model.pt'))\n",
    "\n",
    "# 모델을 실행할 디바이스(GPU or CPU)에 올린다\n",
    "model.to(device)\n",
    "\n",
    "# 검증/추론 모드 전환 \n",
    "# - model.eval() 검증/추촌 모드 에서는 Dropout 등이 비활성화되어 일관된 추론 결과를 보장한다, \n",
    "# - model.train() 학습 모드 에서는 Dropout, BatchNorm 등이 활성화되어 파라미터 업데이트를 준비 한다\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7681a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3 [Test]: 100%|██████████| 157/157 [00:23<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.62      0.63      0.62      2478\n",
      "    positive       0.63      0.61      0.62      2522\n",
      "\n",
      "    accuracy                           0.62      5000\n",
      "   macro avg       0.62      0.62      0.62      5000\n",
      "weighted avg       0.62      0.62      0.62      5000\n",
      "\n",
      "[[1562  916]\n",
      " [ 973 1549]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 평가\n",
    "\n",
    "# 사이킷런 평가 지표 함수 라이브러리 호출\n",
    "# - classification_report 정확도/정밀도/재현율/F1-socre 확인\n",
    "# - confusion_matrix 오분류 패턴 분석\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 전체 예측값, 실제 라벨을 저장 리스트 초기화\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "# 검증/추론시에는 역전파(gradient 계산)가 필요 없으므로 메모리/연산 절약\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=f'{epoch + 1} [Test]'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # AMP(Automatic Mixed Precision) GPU에서 연산 속도와 메모리 효율 향상\n",
    "        with autocast('cuda'):\n",
    "            # 모델 예측\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "        \n",
    "        # 각 샘플에서 가장 큰 점수의 인덱스(0=Negative, 1=Positive) 선택\n",
    "        preds = logits.argmax(dim=-1).cpu().numpy() # PyTorch Tensor -> numpy 변환\n",
    "        labels = labels.cpu().numpy() # PyTorch Tensor -> numpy 변환\n",
    "\n",
    "        all_preds.extend(preds) \n",
    "        all_labels.extend(labels)\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=['Negative', 'positive']))\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da6a4883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix를 Heatmap 그래프로 시각화, 테스트 데이터 평가 데이터를 활용\n",
    "import matplotlib.pyplot as plt # 그래프 그리기 기본 라이브러리\n",
    "import seaborn as sns # 시각화 스타일을 더 깔끔하게 만들어주는 라이브러리\n",
    "import numpy as np # Confunsion Matrix 데이터를 배열 형태로 관리\n",
    "\n",
    "# Confusion Matrix 데이터, 2x2 행렬 구조 실제 라벨과 예측 라벨의 매칭 결과\n",
    "# cm = np.array([ [1562, 916],\n",
    "#                [973, 1549] ])\n",
    "cm = np.array(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "# 클래스 이름\n",
    "labels = ['Negative', 'Positive']\n",
    "\n",
    "# Heatmap 시각화\n",
    "plt.figure(figsize=(6, 5))\n",
    "# cm 데이터, annot=True 각 셀에 숫자 표시, fmt='d' 정수 형태로 출력, cmap='Blues' 파란색 계열 색상 맵 선택, xticklabels/yticklabels 축 라벨에 클래스 이름 푝시\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
