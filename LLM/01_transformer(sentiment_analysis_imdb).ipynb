{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0286209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis(긍정/부정) 분류 모델: IMDB 리뷰 데이터셋 적용\n",
    "# IMDB 데이터셋 : 영어 영화 리뷰(긍정/부정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14887fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI\\Pytorch\\deep-learning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 1. 라이브러리 설치 및 임포트\n",
    "import torch\n",
    "# from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification # 경량 모델\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fbf7889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier\\'s plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it\\'s the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...', 'label': 1}\n",
      "{'text': \"<br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\", 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "# 2. 데이터셋 로드\n",
    "dataset = load_dataset('imdb') # 데이터셋 불러오기(IMDB 리뷰)\n",
    "\n",
    "# 데이터 크기 줄이기(학습용 2000개, 테스트용 500개만 사용)\n",
    "small_train = dataset['train'].shuffle(seed=42).select(range(2000))\n",
    "small_test = dataset['test'].shuffle(seed=42).select(range(500))\n",
    "print(small_train[0])\n",
    "print(small_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13656578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 토큰화\n",
    "\n",
    "# BERT의 사전학습된 토크나이저 모델 로드, \n",
    "# bert-base-uncased는 영어 BERT 모델로, 모든 단어를 소문자(uncased)롤 변환\n",
    "# - 토크나이저는 문장을 단어 → 토큰 → 숫자 ID로 바꿔주는 역할을 합니다. 예: \"I love movies\" → [101, 1045, 2293, 3185, 102]\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 경량 모델 DistilBERT 토크나이저 준비\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased') # 경량 모델\n",
    "\n",
    "def tokenize(batch):\n",
    "    # batch['text'] 데이터셋에서 텍스트 분분을 가져온다\n",
    "    # padding='max_length' 모든 문장을 동일한 길이로 맞추가 위해 패딩(padding)을 추가(짧은 문장은 [PAD] 토큰으로 채움)\n",
    "    # truncation=True 너무 긴 문장은 잘라내기(truncate)를 해서 모델 입력 크기에 맞춘다\n",
    "    # 각 문장이 토큰 ID, attention mask 등으로 변환된 딕셔너리 형태로 반환\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=128) # 경량 모델\n",
    "\n",
    "# dataset.map() 데이터셋 모든 샘플에 tokenize 함수를 적용\n",
    "# batched=True 여러 샘플을 한번에 묶어서 처리 -> 속도 향상\n",
    "# 결과적으로 원래 텍스트 데이터셋에 토큰화된 입력값(input_ids, attention_mask)이 추가\n",
    "# dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "small_train = small_train.map(tokenize, batched=True) # 경량 모델\n",
    "small_test = small_test.map(tokenize, batched=True)\n",
    "\n",
    "# 라벨 컬럼 이름 변경(Trainer는 'labels'를 기대함)\n",
    "small_train = small_train.rename_column('label', 'labels')\n",
    "small_test = small_test.rename_column('label', 'labels')\n",
    "\n",
    "# 불필요한 컬럼 제거\n",
    "small_train = small_train.remove_columns(['text'])\n",
    "small_test = small_test.remove_columns(['text'])\n",
    "\n",
    "# PyTorch 텐서 포맷 지정\n",
    "small_train.set_format('torch')\n",
    "small_test.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58bcb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 불러오기\n",
    "\n",
    "# HuggingFace transformers 라이브러리에서 제공하는 BERT 기반 텍스트 분류 모델 클래스\n",
    "# 기존 BERT 모델 위에 분류용 헤드(classification head)가 추가된 구조\n",
    "# - BERT 본체: 입력 문장을 토큰 단위로 인코딩 -> 문맥적 벡터 표현 생성\n",
    "# - Classification Head: [CLS] 토큰의 벡터를 받아 Dense Layer + Softmax로 분류 결과 출력\n",
    "\n",
    "# from_pretrained(\"bert-base-uncased\") 사전학습된 bert-base-uncased 모델 로드, uncased -> 모든 영어 단어를 소문자로 변환해서 처리\n",
    "# 이미 대규모 코퍼스(위키백과, BookCorpus 등)로 학습된 모델을 가져오기 때문에, 처음부터 학습하지 않고도 좋은 성능을 낼 수 있다\n",
    "# num_labels=2 분류할 클래스 개수를 지정 -> 여기서는 2개 클래스 예시) 긍정(Positive)/부정(Negative), 뉴스 카테고리 분류 num_labels=4(정치,경제,스포츠,기술)\n",
    "\n",
    "# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2) # 경량 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11eb1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 학습 파라미터 설정\n",
    "trainer_args = TrainingArguments(\n",
    "    output_dir='./results_sentiment_analysis_imdb', # 학습된 모델과 체크포인트(중간 저장 파일)를 저장할 디렉토리 경로, 학습 도중과 완료 후 모델 가중치가 이 폴더에 저장\n",
    "    eval_strategy='epoch', # 매 epoch(한번 전체 데이터셋을 학습)마다 평가를 수행\n",
    "    per_device_train_batch_size=16, # 배치 사이즈 16\n",
    "    num_train_epochs=1, # 학습 반복 3회, 전체 데이터셋을 3회 학습\n",
    "    logging_dir='./logs', # 학습 과정의 로그를 저장\n",
    "    fp16=True # 혼합 정밀도 -> 속도 향상\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c054181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Trainer 구성\n",
    "\n",
    "# Trainer 객체 생성, Hugging Face에서 제공하는 고수준 학습 관리 클래스, 모델 학습/평가/저장 자동 처리\n",
    "# PyTorch의 DataLoader, 학습 루프, 옵티마이저 등을 직접 작성하지 않아도 됨\n",
    "trainer = Trainer(\n",
    "    model=model, # 학습 모델 지정(BertForSequenceClassification), BERT + 분류 헤드 구조가 학습 대상\n",
    "    args=trainer_args, # 학습 파라미터 전달\n",
    "    train_dataset=small_train, # 학습 데이터셋 지정, 토큰화된 입력(input_ids, attention_mask)과 라벨(label)이 포함\n",
    "    eval_dataset=small_test, # 평가 데이터셋 지정, 학습 중간이나 학습 후 성능을 측정할때 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c4af56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.399264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=0.490640625, metrics={'train_runtime': 56.2516, 'train_samples_per_second': 35.555, 'train_steps_per_second': 2.222, 'total_flos': 66233699328000.0, 'train_loss': 0.490640625, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. 학습 실행\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f40739ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39926397800445557, 'eval_runtime': 2.8774, 'eval_samples_per_second': 173.767, 'eval_steps_per_second': 21.895, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# 8. 모델 평가\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a2dca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과: tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "문장: I really loved this movie, it was fantastic!\n",
      "예측: 긍정\n",
      "\n",
      "문장: The film was boring and too long.\n",
      "예측: 부정\n",
      "\n",
      "문장: An average movie, not too bad but not great either.\n",
      "예측: 부정\n",
      "\n",
      "문장: The acting was brilliant and kept me engaged.\n",
      "예측: 긍정\n",
      "\n",
      "문장: I fell asleep halfway through, it was so dull.\n",
      "예측: 부정\n",
      "\n",
      "문장: The storyline was unique and very exciting.\n",
      "예측: 긍정\n",
      "\n",
      "문장: The dialogue felt forced and unnatural.\n",
      "예측: 부정\n",
      "\n",
      "문장: I enjoyed every moment, truly a masterpiece!\n",
      "예측: 긍정\n",
      "\n",
      "문장: The special effects were cheap and disappointing.\n",
      "예측: 부정\n",
      "\n",
      "문장: It was okay, but I wouldn’t watch it again.\n",
      "예측: 부정\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. 추론 테스트\n",
    "test_sentences = [\n",
    "    \"I really loved this movie, it was fantastic!\",\n",
    "    \"The film was boring and too long.\",\n",
    "    \"An average movie, not too bad but not great either.\",\n",
    "    \"The acting was brilliant and kept me engaged.\",\n",
    "    \"I fell asleep halfway through, it was so dull.\",\n",
    "    \"The storyline was unique and very exciting.\",\n",
    "    \"The dialogue felt forced and unnatural.\",\n",
    "    \"I enjoyed every moment, truly a masterpiece!\",\n",
    "    \"The special effects were cheap and disappointing.\",\n",
    "    \"It was okay, but I wouldn’t watch it again.\"\n",
    "]\n",
    "\n",
    "# test_sentences = [\n",
    "#     \"이 영화 정말 재미있었어요!\",\n",
    "#     \"스토리가 지루하고 너무 길었어요.\",\n",
    "#     \"그럭저럭 볼만했지만 특별한 건 없었어요.\",\n",
    "#     \"배우들의 연기가 훌륭해서 몰입할 수 있었습니다.\",\n",
    "#     \"중간에 잠들 정도로 지루했어요.\",\n",
    "#     \"전개가 신선하고 흥미로웠습니다.\",\n",
    "#     \"대사가 어색하고 자연스럽지 않았습니다.\",\n",
    "#     \"처음부터 끝까지 즐겁게 볼 수 있었어요!\",\n",
    "#     \"특수효과가 싸구려 같아서 실망했어요.\",\n",
    "#     \"괜찮았지만 다시 보고 싶지는 않네요.\"\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 토큰화\n",
    "inputs = tokenizer(\n",
    "    test_sentences, # 추론 테스트 문장\n",
    "    padding=True, # 문장 길이를 맞추기 위해 패딩 추가\n",
    "    truncation=True, # 너무 긴 문장은 잘라냄\n",
    "    max_length=128, # 최대 토큰 길이 제한\n",
    "    return_tensors='pt' # PyTorch 텐서로 반환\n",
    ").to(device) # 입력 텐서를 GPU/CPU로 이동\n",
    "\n",
    "# 모델 예측\n",
    "\n",
    "# **inputs -> 파이썬 언패킹 문법을 사용해 딕셔너리의 키-값을 함수 인자로 전달\n",
    "# 내부적으로 호출 -> model(input_ids=..., attention_mask=...)\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# outputs.logits 각 클래스(긍정/부정)에 대한 점수, 예시) [[-1.3135,  1.1777],[ 1.1172, -1.1963],[ 0.2496, -0.2385]]\n",
    "# 가장 높은 점수를 가진 클래스 선택 -> 결과 [1,0,0] (0=부정, 1=긍정), 예시) [1, 0, 0]\n",
    "predictions = torch.argmax(outputs.logits, dim=1)\n",
    "print('예측 결과:', predictions)\n",
    "\n",
    "# test_sentences -> 추론에 테스트 할 문장\n",
    "# predictions -> 모델이 예측한 결과(0 또는 1 값이 들어 있는 텐서)\n",
    "# zip(test_sentences, predictions) -> 두 리스트/텐서를 묶어서 문장과 예측값을 한쌍으로 반복할 수 있게 만든다\n",
    "for sentence, pred in zip(test_sentences, predictions):\n",
    "    label = '긍정' if pred.item() == 1 else '부정'\n",
    "    print(f'문장: {sentence}\\n예측: {label}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
