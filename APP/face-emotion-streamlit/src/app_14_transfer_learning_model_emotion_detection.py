# app_14_transfer_learning_model_emotion_detection.py
# Streamlit ì•± - Kaggle Face Emotion Detection Classification
# {0: 'angry', 1: 'disgusted', 2: 'fearful', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprised'}

import streamlit as st
import torch
from torchvision import models, transforms
import cv2 # ì–¼êµ´ ê²€ì¶œìš©
from PIL import Image # ì´ë¯¸ì§€ í¬ë©§ìš©
import numpy as np
from model_utils import TransferLearningModel  # í˜„ìš©ë‹˜ì´ ë§Œë“  í´ë˜ìŠ¤
import os, json
import pandas as pd

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ ë¡œë”©
@st.cache_resource # - @st.cache_resource: ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë”©í•˜ê³  ìºì‹œí•˜ì—¬ ì•± ì†ë„ í–¥ìƒ
def load_model():
    # base_model = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT) # - vit_b_16: Vision Transformer ì‚¬ì „í•™ìŠµ ëª¨ë¸
    base_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT) # ResNet ëª¨ë¸ì„ ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ë¡œ ë¶ˆëŸ¬ì˜´.
    num_classes=7
    model = TransferLearningModel(base_model, feature_extractor=True, num_classes=num_classes).to(device) # - feature_extractor=True: íŠ¹ì§• ì¶”ì¶œê¸°ë¡œ ì‚¬ìš©, num_classes=2: ë§ˆìŠ¤í¬ ì°©ìš© ì—¬ë¶€ 2 í´ë˜ìŠ¤

    model_path = os.path.join("models", "model_transfer_learning_emotion_detection.pt") # - í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    if not os.path.exists(model_path):
        st.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        st.stop()

    model.load_state_dict(torch.load(model_path, map_location=device)) # - í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    model.eval() # - ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜
    return model

model = load_model()
# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ - OpenCVë¥¼ ì´ìš©í•´ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ìë™ìœ¼ë¡œ ê²€ì¶œí•˜ê³ , ê·¸ ì–¼êµ´ ì˜ì—­ë§Œ ì˜ë¼ì„œ ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
# 1) ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ëŠ”ë‹¤ (OpenCV Haar Cascade), 2) ì–¼êµ´ì´ ìˆìœ¼ë©´ cropí•´ì„œ ì „ì²˜ë¦¬, 3) ì–¼êµ´ì´ ì—†ìœ¼ë©´ ì „ì²´ ì´ë¯¸ì§€ë¥¼ ì „ì²˜ë¦¬
def detect_and_preprocess(image):
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') # OpenCVì—ì„œ ì œê³µí•˜ëŠ” Haar Cascade ì–¼êµ´ ê²€ì¶œê¸°ë¥¼ ë¶ˆëŸ¬ì˜´.
    img_cv = np.array(image) # ë„˜íŒŒì´ ë³€í™˜í•˜ì—¬ OpenCVê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•¨.
    gray = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY) # ì–¼êµ´ ê²€ì¶œì€ í‘ë°± ì´ë¯¸ì§€ì—ì„œ ë” ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ ì‘ë™í•˜ë¯€ë¡œ, RGB ì´ë¯¸ì§€ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    faces = face_cascade.detectMultiScale(gray, 1.1, 4) # ì–¼êµ´ ê²€ì¶œ, 1.1(ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 10%ì”© ì¤„ì—¬ê°€ë©° íƒìƒ‰), 4(ìµœì†Œ 4ê°œì˜ ì´ì›ƒ ì‚¬ê°í˜•ì´ ìˆì–´ì•¼ ì–¼êµ´ë¡œ íŒë‹¨)

    if len(faces) == 0:
        return preprocess_image(image) # ì–¼êµ´ì´ í•˜ë‚˜ë„ ê²€ì¶œë˜ì§€ ì•Šìœ¼ë©´, ì „ì²´ ì´ë¯¸ì§€ë¥¼ ê·¸ëŒ€ë¡œ ì „ì²˜ë¦¬í•´ì„œ ë°˜í™˜(fallback: ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©)

    x, y, w, h = faces[0] # ì²« ë²ˆì§¸ë¡œ ê²€ì¶œëœ ì–¼êµ´ì˜ ì¢Œí‘œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (ì—¬ëŸ¬ ì–¼êµ´ì´ ìˆì„ ê²½ìš° ì²« ë²ˆì§¸ë§Œ ì‚¬ìš©)
    face_img = img_cv[y:y+h, x:x+w] # ì–¼êµ´ ì˜ì—­ë§Œ ì˜ë¼ëƒ…ë‹ˆë‹¤ (crop)
    face_pil = Image.fromarray(face_img) # NumPy ë°°ì—´ì„ ë‹¤ì‹œ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜, preprocess_image()ëŠ” PIL ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê¸° ë•Œë¬¸ì„.
    return preprocess_image(face_pil)

def preprocess_image(image):
    transform = transforms.Compose([
        transforms.Resize((224, 224)), # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 224Ã—224ë¡œ ì¡°ì • (ViT ì…ë ¥ í¬ê¸°)
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    return transform(image).unsqueeze(0).to(device) # - unsqueeze(0): ë°°ì¹˜ ì°¨ì› ì¶”ê°€ â†’ [1, 3, 224, 224], ë°°ì¹˜ ì°¨ì› ì¶”ê°€ ë° ë””ë°”ì´ìŠ¤ë¡œ ì´ë™

# Grad-CAM í•¨ìˆ˜ - ëª¨ë¸, ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ, ì˜ˆì¸¡ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¥¼ ë°›ì•„ heatmapì„ ìƒì„±
# ë¹¨ê°„ìƒ‰ ì˜ì—­ - ëª¨ë¸ì´ ê°€ì¥ ì£¼ëª©í•œ ë¶€ë¶„ì…ë‹ˆë‹¤. ì´ ì˜ì—­ì´ ì˜ˆì¸¡ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì³¤ìœ¼ë©°, ëª¨ë¸ì´ ì´ ë¶€ë¶„ì„ í†µí•´ í´ë˜ìŠ¤ë¥¼ ê²°ì •í–ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ë…¸ë€ìƒ‰ê³¼ ë…¹ìƒ‰ ì˜ì—­ - ì´ ë¶€ë¶„ë„ ì˜ˆì¸¡ì— ê¸°ì—¬í–ˆì§€ë§Œ, ë¹¨ê°„ìƒ‰ ì˜ì—­ë³´ë‹¤ëŠ” ëœ ì¤‘ìš”í•˜ê²Œ ì‘ìš©í–ˆìŠµë‹ˆë‹¤.
# íŒŒë€ìƒ‰ ì˜ì—­ - ëª¨ë¸ì´ ìƒëŒ€ì ìœ¼ë¡œ ëœ ì£¼ëª©í•˜ê±°ë‚˜ ê±°ì˜ ì£¼ëª©í•˜ì§€ ì•Šì€ ë¶€ë¶„ì…ë‹ˆë‹¤.
# ResNet ëª¨ë¸, ì „ì²˜ë¦¬ëœ ì…ë ¥ ì´ë¯¸ì§€(shape:[1,3,224,224]), Grad-CAMì„ ì ìš©í•  ëŒ€ìƒ ë ˆì´ì–´(ë³´í†µ ë§ˆì§€ë§‰ convolution block), ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ì¸ë±ìŠ¤(0~7)
def grad_cam(model, image_tensor, target_layer, predicted_class):
    gradients = []
    activations = []
    
    def forward_hook(module, input, output): # ìˆœì „íŒŒ ì‹œ í™œì„±í™”ê°’(feature map)ì„ ì €ì¥
        activations.append(output)
    
    def backward_hook(module, grad_input, grad_output): # ì—­ì „íŒŒ ì‹œ gradientë¥¼ ì €ì¥
        gradients.append(grad_output[0])
    
    # Hook ë“±ë¡, ì§€ì •í•œ target_layerì— hookì„ ì—°ê²°í•˜ì—¬ forward/backward ì‹œì ì— ë°ì´í„°ë¥¼ ìˆ˜ì§‘
    target_layer.register_forward_hook(forward_hook)
    target_layer.register_backward_hook(backward_hook)

    # ìˆœì „íŒŒ ë° ì—­ì „íŒŒ
    model.zero_grad() # ë¯¸ë¶„ ì´ˆê¸°í™”
    output = model(image_tensor) # ëª¨ë¸ ì˜ˆì¸¡

    # output[0] ë°°ì¹˜ì—ì„œ ì²«ë²ˆì§¸ ì´ë¯¸ì§€ ì˜ˆì¸¡ ê²°ê³¼, predicted_class: ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ (ì˜ˆ: 3 â†’ happy)
    # ë”°ë¼ì„œ output[0, predicted_class]ëŠ”: 
    # ëª¨ë¸ì´ í•´ë‹¹ ì´ë¯¸ì§€ì— ëŒ€í•´ ì˜ˆì¸¡í•œ í´ë˜ìŠ¤ì˜ ì ìˆ˜ë§Œ í•˜ë‚˜ ì„ íƒí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
    # ì˜ˆì‹œ: output[0, 3] = 3.1 â†’ ëª¨ë¸ì´ "happy" í´ë˜ìŠ¤ì— ëŒ€í•´ 3.1ì´ë¼ëŠ” ì ìˆ˜ë¥¼ ì¤¬ë‹¤ëŠ” ëœ»
    class_score = output[0, predicted_class]
    class_score.backward() # ë¯¸ë¶„ ì—°ì‚°, ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì—¬ ì—­ì „íŒŒ í•œë‹¤.

    # Grad-CAM ê³„ì‚°
    grads = gradients[0].cpu().detach().numpy()[0] # í…ì„œ -> ë„˜íŒŒì´ ë³€ê²½
    acts = activations[0].cpu().detach().numpy()[0]
    weights = np.mean(grads, axis=(1, 2)) # ê° ì±„ë„ì˜ ì¤‘ìš”ë„ (gradientì˜ í‰ê· ê°’)
    # ìµœì¢…ì ìœ¼ë¡œ ê° ìœ„ì¹˜ì˜ ì¤‘ìš”ë„ë¥¼ ëˆ„ì í•  ê³µê°„
    cam = np.zeros(acts.shape[1:], dtype=np.float32) # acts.shape: [C, H, W] â†’ ì±„ë„ ìˆ˜, ë†’ì´, ë„ˆë¹„, acts.shape[1:]: [H, W] â†’ ê° ì±„ë„ì˜ ê³µê°„ í¬ê¸°

    for i, w in enumerate(weights): # ê° ì±„ë„ì˜ feature mapì— í•´ë‹¹ ì±„ë„ì˜ ì¤‘ìš”ë„(weight)ë¥¼ ê³±í•´ì„œ ëˆ„ì 
        cam += w * acts[i]
    
    cam = np.maximum(cam, 0) # ìŒìˆ˜ ì œê±°(ìŒìˆ˜ëŠ” ì¤‘ìš”í•˜ì§€ ì•Šë‹¤ê³  ê°„ì£¼í•œë‹¤.)
    cam = cv2.resize(cam, (224, 224)) # heatmapì„ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì™€ ë§ì¶¤
    # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
    cam = cam - np.min(cam) # ê°€ì¥ ë‚®ì€ ê°’ ì œê±°
    cam = cam / np.max(cam) # ê°€ì¥ ë†’ì€ ê°’ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§

    return cam


# ì˜ˆì¸¡ í•¨ìˆ˜
def predict(image_tensor):
    with torch.no_grad(): # - ì¶”ë¡  ì‹œì—ëŠ” ê¸°ìš¸ê¸° ê³„ì‚° ë¶ˆí•„ìš”
        outputs = model(image_tensor) # - ëª¨ë¸ì— ì´ë¯¸ì§€ í…ì„œ ì…ë ¥
        probabilities = torch.nn.functional.softmax(outputs, dim=1) # - ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¡œ í™•ë¥  ê³„ì‚°
        predicted = torch.argmax(probabilities, dim=1).item() # - ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ í´ë˜ìŠ¤ ì„ íƒ
        probabilities = probabilities.cpu().numpy()[0] # - í™•ë¥ ì„ CPUë¡œ ì˜®ê¸°ê³  numpy ë°°ì—´ë¡œ ë³€í™˜
    return predicted, probabilities # - ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ë°˜í™˜ (0~3), ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë°°ì—´ ë°˜í™˜

# ë¼ë²¨ ë§µ ë¡œë”© - labels_map.json íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ì™€ ê°•ì•„ì§€ ì´ë¦„ ë§¤í•‘
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
labels_path = os.path.join(BASE_DIR, 'labels_map.json') # ì˜ˆ: í´ë˜ìŠ¤ ì¸ë±ìŠ¤ â†’ ë§ˆìŠ¤í¬ ì‘ìš©/ë¯¸ì‘ìš© ì´ë¦„

if not os.path.exists(labels_path): # labels_map.json íŒŒì¼ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
    st.error(f"labels_map.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {labels_path}")
    st.stop() # - íŒŒì¼ì´ ì—†ìœ¼ë©´ ì•± ì¤‘ì§€

with open(labels_path, 'r') as f: # - labels_map.json íŒŒì¼ ì—´ê¸°
    labels_map = {int(k):v for k, v in json.load(f).items()} # - JSON íŒŒì¼ì—ì„œ ë”•ì…”ë„ˆë¦¬ë¡œ ë¡œë“œ, í‚¤ë¥¼ intë¡œ ë³€í™˜

# Streamlit UI
st.title("ì–¼êµ´ ê°ì • ë¶„ë¥˜ê¸°") # - ì•± ì œëª©
st.write("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ì–¼êµ´ ê°ì •ë¥¼ ì˜ˆì¸¡í•´ì¤ë‹ˆë‹¤!") # - ì•± ì„¤ëª…

# ë‹¨ì¼ ì´ë¯¸ì§€ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png" ]) # - íŒŒì¼ ì—…ë¡œë”
if uploaded_file is not None: # - íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆì„ ë•Œ
    image = Image.open(uploaded_file).convert("RGB") # - ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜
    # st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)
    st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", width='stretch') # - use_container_width=True: ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ê²Œ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •

    try:
        # image_tensor = preprocess_image(image) # - ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        image_tensor = detect_and_preprocess(image) # - ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        prediction, probabilities = predict(image_tensor) # - ì˜ˆì¸¡ ìˆ˜í–‰
        label = labels_map[prediction]

        st.success(f'ì˜ˆì¸¡ ê²°ê³¼: **{label}**')
        st.subheader("ì˜ˆì¸¡ í™•ë¥ ")
        st.bar_chart( {labels_map[i]: prob for i, prob in enumerate(probabilities)} )

        # Grad-CAM ì‹œê°í™” ì¶”ê°€
        target_layer = model.model.layer4[-1] # TransferLearningModel í´ë˜ìŠ¤ ë‚´ë¶€ì˜ ResNet18 ë§ˆì§€ë§‰ Residual Block ì§€ì •
        # ëª¨ë¸ê³¼ ì—ì¸¡ëœ í´ë˜ìŠ¤ì— ëŒ€í•´ Grad-CAM heatmapì„ ìƒì„±
        cam = grad_cam(model=model.model, image_tensor=image_tensor, target_layer=target_layer, predicted_class=prediction)

        # ì›ë³¸ ì´ë¯¸ì§€ì™€ heatmap overlay
        img_np = np.array(image.resize( (224, 224) )) / 255.0
        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET) # COLORMAP_JETì€ ë¹¨ê°•(ë†’ì€ ì¤‘ìš”ë„), íŒŒë‘(ë‚®ì€ ì¤‘ìš”ë„)ìœ¼ë¡œ í‘œí˜„ë¨
        heatmap = np.float32(heatmap) / 255
        overlay = heatmap + img_np
        overlay = overlay / np.max(overlay)
        
        st.subheader('Grad-CAM ì‹œê°í™”')
        st.image(img_np, caption='ì›ë³¸ ì´ë¯¸ì§€', use_container_width=True)
        st.image(overlay, caption='Grad-CAM Overlay', use_container_width=True)

    except Exception as e:
        st.error(f"ì˜ˆì¸¡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ì›¹ìº  ì…ë ¥
camera_image = st.camera_input("ğŸ“· ì›¹ìº ìœ¼ë¡œ ì‚¬ì§„ ì´¬ì˜")

if camera_image is not None:
    image = Image.open(camera_image).convert("RGB")
    st.image(image, caption="ì´¬ì˜ëœ ì´ë¯¸ì§€", width='stretch')

    try:
        # image_tensor = preprocess_image(image)
        image_tensor = detect_and_preprocess(image) # - ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        prediction, probabilities = predict(image_tensor)
        label = labels_map[prediction]

        st.success(f'ì˜ˆì¸¡ ê²°ê³¼: **{label}**')

        st.subheader("ì˜ˆì¸¡ í™•ë¥ ")
        st.bar_chart({labels_map[i]: prob for i, prob in enumerate(probabilities)})

        # Grad-CAM ì‹œê°í™” ì¶”ê°€
        target_layer = model.model.layer4[-1] # ResNet18ì˜ ë§ˆì§€ë§‰ Residual Block
        cam = grad_cam(model=model.model, image_tensor=image_tensor, target_layer=target_layer, predicted_class=prediction)

        # ì›ë³¸ ì´ë¯¸ì§€ì™€ heatmap overlay
        img_np = np.array(image.resize( (224, 224) )) / 255.0
        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
        heatmap = np.float32(heatmap) / 255
        overlay = heatmap + img_np
        overlay = overlay / np.max(overlay)

        st.subheader('Grad-CAM ì‹œê°í™”')
        st.image(img_np, caption='ì›ë³¸ ì´ë¯¸ì§€', use_container_width=True)
        st.image(overlay, caption='Grad-CAM Overlay', use_container_width=True)

    except Exception as e:
        st.error(f"ì›¹ìº  ì˜ˆì¸¡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ë‹¤ì¤‘ ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì˜µì…˜)
uploaded_files = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—¬ëŸ¬ ì¥ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

if uploaded_files:
    results = []  # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    st.write(f"{len(uploaded_files)}ê°œì˜ ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    for uploaded_file in uploaded_files:
        image = Image.open(uploaded_file).convert("RGB")
        st.image(image, caption=uploaded_file.name, width='stretch')

        try:
            # image_tensor = preprocess_image(image)
            image_tensor = detect_and_preprocess(image) # - ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            prediction, probabilities = predict(image_tensor)
            label = labels_map[prediction]
            
            st.success(f'ì˜ˆì¸¡ ê²°ê³¼: **{label}**')
            # ê²°ê³¼ ì €ì¥
            results.append({
                "íŒŒì¼ëª…": uploaded_file.name,
                "ì˜ˆì¸¡ í´ë˜ìŠ¤": label,
                "í™•ë¥ ": f"{probabilities[prediction]:.4f}"
            })
            st.bar_chart({labels_map[i]: prob for i, prob in enumerate(probabilities)})

            # Grad-CAM ì‹œê°í™” ì¶”ê°€
            target_layer = model.model.layer4[-1] # ResNet18ì˜ ë§ˆì§€ë§‰ Residual Block
            cam = grad_cam(model=model.model, image_tensor=image_tensor, target_layer=target_layer, predicted_class=prediction)

            # ì›ë³¸ ì´ë¯¸ì§€ì™€ heatmap overlay
            img_np = np.array(image.resize( (224, 224) )) / 255.0
            heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
            heatmap = np.float32(heatmap) / 255
            overlay = heatmap + img_np
            overlay = overlay / np.max(overlay)

            st.subheader('Grad-CAM ì‹œê°í™”')
            st.image(img_np, caption='ì›ë³¸ ì´ë¯¸ì§€', use_container_width=True)
            st.image(overlay, caption='Grad-CAM Overlay', use_container_width=True)

        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    if results:
        import pandas as pd
        df = pd.DataFrame(results)
        st.subheader("ğŸ“„ ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½")
        st.dataframe(df)

        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button(
            label="ğŸ“¥ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name="prediction_results.csv",
            mime="text/csv"
        )

st.markdown("---")
st.caption("Powered by ResNet + Transfer Learning")