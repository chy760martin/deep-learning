{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1]) torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# MLP DeepLearning\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# tensor, 입력데이터가 12이하라면 정답이 0이고 14이상이면 정답이 1이라는 것을 알 수 있음\n",
    "x_train = torch.Tensor( [2,4,6,8,10,12,14,16,18,20] ).view(10,1) # reshape\n",
    "y_train = torch.Tensor( [0,0,0,0,0,0,1,1,1,1] ).view(10,1) \\\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepLearning Model\n",
    "# 입력층 -> 은닉층 -> 출력층\n",
    "class DeepLearningModel(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.deeplearning_stack = nn.Sequential(\n",
    "            nn.Linear(1, 8), # 1개의 입력데이터에 대해서 8개의 출력을 내놓는 은닉층\n",
    "            nn.Linear(8, 1), # 8개의 입력데이터에 대해서 1개의 출력을 내놓는 출력층\n",
    "            nn.Sigmoid() # 활성화함수 0~1 사이값 리턴\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.deeplearning_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8eef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning_stack Parameter containing:\n",
      "tensor([[-0.3074],\n",
      "        [ 0.9485],\n",
      "        [-0.0775],\n",
      "        [ 0.6588],\n",
      "        [ 0.3084],\n",
      "        [-0.1917],\n",
      "        [ 0.3418],\n",
      "        [ 0.2948]], requires_grad=True)\n",
      "deeplearning_stack Parameter containing:\n",
      "tensor([-0.3860, -0.4853, -0.4499, -0.6149, -0.8236,  0.3415, -0.6960,  0.2016],\n",
      "       requires_grad=True)\n",
      "deeplearning_stack Parameter containing:\n",
      "tensor([[ 0.0957,  0.0421,  0.0544,  0.0475,  0.0445,  0.0834, -0.2072,  0.1896]],\n",
      "       requires_grad=True)\n",
      "deeplearning_stack Parameter containing:\n",
      "tensor([0.0597], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Model 객체 생성\n",
    "model = DeepLearningModel()\n",
    "\n",
    "# Model 파라미터(가중치, 바이어스) 값 확인\n",
    "for name, child in model.named_children():\n",
    "    for param in child.parameters():\n",
    "        print(name, param)\n",
    "\n",
    "# 입력층-출력층 가중치 8개(1x8)\n",
    "# deeplearning_stack Parameter containing:\n",
    "# tensor([[-0.9416],\n",
    "#         [-0.0063],\n",
    "#         [ 0.4107],\n",
    "#         [ 0.6724],\n",
    "#         [-0.0693],\n",
    "#         [-0.0932],\n",
    "#         [-0.5608],\n",
    "#         [-0.3111]], requires_grad=True)\n",
    "# 은닉층 바이어스 8개\n",
    "# deeplearning_stack Parameter containing:\n",
    "# tensor([-0.7501,  0.1256, -0.3569,  0.3050,  0.8730,  0.7295,  0.6094, -0.3402],\n",
    "#        requires_grad=True)\n",
    "\n",
    "# 은닉층-출력층 가중치 8개(8x1)\n",
    "# deeplearning_stack Parameter containing:\n",
    "# tensor([[ 0.0211,  0.2055,  0.3179,  0.0011, -0.2181,  0.2186, -0.0436,  0.3099]],\n",
    "#        requires_grad=True)\n",
    "# 출력층 바이어스 1개\n",
    "# deeplearning_stack Parameter containing:\n",
    "# tensor([-0.1547], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2211c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss_function = nn.BCELoss() # loss function 이지 분류이므로 Binary CrossEntropy(BCELoss())\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1) # 확율적경사하강법 SGD(가장 기본)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15c80d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 , loss =  0.18116353452205658\n",
      "epoch =  100 , loss =  0.1663568913936615\n",
      "epoch =  200 , loss =  0.15462958812713623\n",
      "epoch =  300 , loss =  0.1450420618057251\n",
      "epoch =  400 , loss =  0.13701122999191284\n",
      "epoch =  500 , loss =  0.13015416264533997\n",
      "epoch =  600 , loss =  0.12420759350061417\n",
      "epoch =  700 , loss =  0.11898478120565414\n",
      "epoch =  800 , loss =  0.11434732377529144\n",
      "epoch =  900 , loss =  0.11019174009561539\n",
      "epoch =  1000 , loss =  0.10643782466650009\n",
      "epoch =  1100 , loss =  0.1030232161283493\n",
      "epoch =  1200 , loss =  0.09989811480045319\n",
      "epoch =  1300 , loss =  0.0970214381814003\n",
      "epoch =  1400 , loss =  0.09436104446649551\n",
      "epoch =  1500 , loss =  0.09188933670520782\n",
      "epoch =  1600 , loss =  0.08958306908607483\n",
      "epoch =  1700 , loss =  0.08742395788431168\n",
      "epoch =  1800 , loss =  0.08539468795061111\n",
      "epoch =  1900 , loss =  0.08348260819911957\n",
      "epoch =  2000 , loss =  0.08167480677366257\n",
      "epoch =  2100 , loss =  0.07996023446321487\n",
      "epoch =  2200 , loss =  0.07833444327116013\n",
      "epoch =  2300 , loss =  0.07678163796663284\n",
      "epoch =  2400 , loss =  0.07524868845939636\n",
      "epoch =  2500 , loss =  0.07379970699548721\n",
      "epoch =  2600 , loss =  0.08298464864492416\n",
      "epoch =  2700 , loss =  0.03632510453462601\n",
      "epoch =  2800 , loss =  0.03733351454138756\n",
      "epoch =  2900 , loss =  0.032895125448703766\n",
      "epoch =  3000 , loss =  0.034492164850234985\n",
      "epoch =  3100 , loss =  0.03005560301244259\n",
      "epoch =  3200 , loss =  0.03411341458559036\n",
      "epoch =  3300 , loss =  0.029561281204223633\n",
      "epoch =  3400 , loss =  0.026111703366041183\n",
      "epoch =  3500 , loss =  0.032135944813489914\n",
      "epoch =  3600 , loss =  0.027880672365427017\n",
      "epoch =  3700 , loss =  0.02466316893696785\n",
      "epoch =  3800 , loss =  0.02207968942821026\n",
      "epoch =  3900 , loss =  0.08406475931406021\n",
      "epoch =  4000 , loss =  0.026333829388022423\n",
      "epoch =  4100 , loss =  0.023295164108276367\n",
      "epoch =  4200 , loss =  0.02085486426949501\n",
      "epoch =  4300 , loss =  0.018850097432732582\n",
      "epoch =  4400 , loss =  0.017173485830426216\n",
      "epoch =  4500 , loss =  0.015750939026474953\n",
      "epoch =  4600 , loss =  0.014529342763125896\n",
      "epoch =  4700 , loss =  0.013469763100147247\n",
      "epoch =  4800 , loss =  0.012542190961539745\n",
      "epoch =  4900 , loss =  0.011723771691322327\n",
      "epoch =  5000 , loss =  0.010997239500284195\n"
     ]
    }
   ],
   "source": [
    "# Model 학습\n",
    "nums_epoch = 5000\n",
    "\n",
    "for epoch in range(nums_epoch + 1):\n",
    "    # 예측값 계산\n",
    "    outputs = model(x_train)\n",
    "\n",
    "    # 손실함수값 계산\n",
    "    loss = loss_function(outputs, y_train)\n",
    "\n",
    "    # 오차역전파\n",
    "    optimizer.zero_grad() # 미분 초기화\n",
    "    loss.backward() # 미분 연산\n",
    "    optimizer.step() # 미분 연산 후 가중치, 바이어스 파라미터 업데이트\n",
    "\n",
    "    if epoch %100 == 0:\n",
    "        print('epoch = ', epoch, ', loss = ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c91e1a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5112e-16],\n",
      "        [3.3654e-13],\n",
      "        [1.4206e-12],\n",
      "        [3.4077e-03],\n",
      "        [5.2052e-01],\n",
      "        [1.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "# Model 테스트\n",
    "model.eval() # 추론 모드 전환\n",
    "\n",
    "test_data = torch.Tensor( [0.5, 3.0, 3.5, 11.0, 13.0, 31.0] ).view(6, 1)\n",
    "\n",
    "# 모델 예측\n",
    "pred = model(test_data)\n",
    "\n",
    "# 예측값 0.5 이상 True -> 1.0 변환, 0.5 이하 False -> 0.0 변환\n",
    "logical_value = (pred > 0.5).float()\n",
    "\n",
    "print(pred)\n",
    "print(logical_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
