{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765acad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer 요약 모델 & 파인 튜닝\n",
    "# - Hugging Face 라이브러리 적용\n",
    "# - AI HUB 요약문 및 레포트 뉴스(news) 데이터셋 적용\n",
    "# - 입력된 문장을 요약 모델을 통한 문장 요약\n",
    "# 1. 학습 목표\n",
    "# - 구조 최적화 및 파이프라인 단순화\n",
    "# - AI HUB 요약문 및 레포트 뉴스(news) 데이터셋 전처리\n",
    "# - 병렬 문장쌍 데이터셋 변환 전처리\n",
    "# - 토크나이징 및 토크나이징 전처리\n",
    "# - 베이스 모델 로드\n",
    "# - LoRA(Low-Rank Adaptation) 설정, 특정 레이어에 작은 저차원 행렬(랭크 r)을 삽입해서 학습\n",
    "# - LoRA(Low-Rank Adaptation) 모델, 메모리 효율성/빠른 학습/도메인 적용, base 모델에 여러 LoRA 모듈을 붙였다 떼었다 할 수 있음\n",
    "# - 학습 args 설정\n",
    "# - Trainer 정의\n",
    "# - Trainer 실행\n",
    "# - LoRA 적용된 모델 저장, LoRA모델/토크나이저\n",
    "# - LoRA 적용된 모델 불러오기, 베이스모델/LoRA모델/토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bf0361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0 cpu\n",
      "CUDA 사용 가능 여부: False\n",
      "PyTorch CUDA 버전: None\n",
      "빌드 정보: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import glob, json, re, os, random, csv\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(torch.__version__, device)\n",
    "\n",
    "print(\"CUDA 사용 가능 여부:\", torch.cuda.is_available())\n",
    "print(\"PyTorch CUDA 버전:\", torch.version.cuda)\n",
    "print(\"빌드 정보:\", torch.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"사용 중인 GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49046719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train short:                                                      src  \\\n",
      "0      오거돈 전 부산시장의 성추행 사건이 불거진 후 정치권을 중심으로 여권이 이 사실을 ...   \n",
      "1      오거돈 전 부산시장의 성추행 사건이 불거진 후 정치권을 중심으로 여권이 이 사실을 ...   \n",
      "2       “동선 봐도 도움이 안 되는 것 같아요.\\n  어딘지 알아야 피해가고 조심할 텐데...   \n",
      "3       “동선 봐도 도움이 안 되는 것 같아요.\\n  어딘지 알아야 피해가고 조심할 텐데...   \n",
      "4      대구 대실요양병원에서 21일 신종 코로나바이러스 감염증(코로나19) 확진자가 52명...   \n",
      "...                                                  ...   \n",
      "21595   병원들은 지난 21일부터 전공의들이 단계적으로 파업에 돌입한 데 따라 인력 부족으...   \n",
      "21596     1일 0시 기준 수도권 신규 환자는 서울(45명)·경기(36명)·인천(0명)으...   \n",
      "21597     1일 0시 기준 수도권 신규 환자는 서울(45명)·경기(36명)·인천(0명)으...   \n",
      "21598  권준욱 질병관리청 중앙방역대책본부(방대본) 부본부장이 \"젊은 남성 운동선수들도 코로...   \n",
      "21599  권준욱 질병관리청 중앙방역대책본부(방대본) 부본부장이 \"젊은 남성 운동선수들도 코로...   \n",
      "\n",
      "                                                     tgt summary_type  domain  \n",
      "0      오 전 부산시장의 성추행 사건이 불거진 후 여권이 이 사실을 사전에 몰랐을까 하는 ...        short  news_r  \n",
      "1      오거돈 전 부산시장의 성추행 사건이 불거진 후 정치권을 중심으로 여권이 이 사실을 ...        short  news_r  \n",
      "2      코로나19 확진자 동선은 사생활 침해 논란으로 공개 범위가 한정되어 있었으나 지역사...        short  news_r  \n",
      "3      물류센터·교회 발 코로나19 확산이 지역사회 N차 감염으로 이어지면서 확진자 동선을...        short  news_r  \n",
      "4      대구 대실요양병원과 같은 건물 8층의 미주병원 직원과 환자들도 코로나19 검사 절차...        short  news_r  \n",
      "...                                                  ...          ...     ...  \n",
      "21595  병원들은 지난 21일부터 전공의들이 단계적으로 파업에 돌입한 데 따라 인력 부족으로...        short  news_r  \n",
      "21596  방역 당국과 지자체는 코로나19 사태를 겪으면서 밀집·밀폐도 등에 따라 고·중·저위...        short  news_r  \n",
      "21597  방역 당국과 지자체는 그동안 다중이용시설을 밀집·밀폐도 등에 따라 고·중·저위험시설...        short  news_r  \n",
      "21598  방대본 권 부본부장은 정부가 코로나19에 대해 적극적인 방역, 의료대응의 강화, 거...        short  news_r  \n",
      "21599  권 부본부장은 3일 충북 오송에서 열린 정례 브리핑에서 정부가 신종 코로나바이러스 ...        short  news_r  \n",
      "\n",
      "[21600 rows x 4 columns]\n",
      "train long:                                                      src  \\\n",
      "0      한국이 경공격기 FA-50을 아르헨티나로 수출하려던 계획이 점점 꼬여가고 있다.\\n...   \n",
      "1      올해 들어 3월까지 정부의 재정 상황을 보여주는 통합재정수지와 관리재정수지의 적자 ...   \n",
      "2       엄마라면 출생했다는 사실만으로 모자 관계를 인정받을 수 있지만, 아빠는 ‘인지’ ...   \n",
      "3      2년 전 이맘 때 김부겸 당시 행정안전부 장관은 더불어민주당의 차기 당 대표 1순위...   \n",
      "4      지난 18일 오후 8시 제주국제공항 국내선 도착장.\\n  도착 게이트를 통해 인파가...   \n",
      "...                                                  ...   \n",
      "10795  병원 탐방 센트럴서울안과 건강은 ‘보이는’ 만큼 지킬 수 있다.\\n  시력이 떨어지...   \n",
      "10796  미국 차기 대통령을 선출할 결전의 날이 다가왔다.\\n  대부분 여론조사 분석기관이 ...   \n",
      "10797  “이혼하고 혼자 살면서 나를 괴롭힌 건 두 가지 사건이었다.\\n  나는 특급 호텔 ...   \n",
      "10798    일론 머스크의 우주탐사기업 스페이스X가 만든 민간 최초 유인 우주선이 발사에 성...   \n",
      "10799  Q 서울 강남구에 거주하는 정모(49)씨.\\n  의사로 전업주부인 부인과 사이에 대...   \n",
      "\n",
      "                                                     tgt summary_type  domain  \n",
      "0      한국이 경공격기 FA-50을 아르헨티나로 수출하려던 계획이 점점 꼬여가고 있다. 아...         long  news_r  \n",
      "1      경기 부진으로 세수는 줄어드는데 코로나 대응을 위해 적극적인 확장 재정을 펼친 영향...         long  news_r  \n",
      "2      만약 생모가 아이를 낳고 연락이 끊기거나 출생 신고에 협조하지 않는다면 미혼부는 혼...         long  news_r  \n",
      "3      2년 전 이맘 때 김부겸 당시 행정안전부 장관은 더불어민주당의 차기 당 대표 1순위...         long  news_r  \n",
      "4      신종 코로나바이러스 감염증(코로나19) 사태 이후 제주 내·외국인 관광시장 상황이 ...         long  news_r  \n",
      "...                                                  ...          ...     ...  \n",
      "10795  문제는 백내장의 20%가량은 망막 질환이나 녹내장 등 다른 눈 질환이 동반된 ‘난치...         long  news_r  \n",
      "10796  미국 차기 대통령을 선출할 결전의 날이 다가왔다. 대부분 여론조사 분석기관이 조 바...         long  news_r  \n",
      "10797  “이혼하고 혼자 살면서 나를 괴롭힌 건 두 가지 사건이었다. 나는 특급 호텔 수준의...         long  news_r  \n",
      "10798  이번 발사는 2011년 미국의 우주왕복선 프로그램 종료 이후 9년 만에 미국 영토에...         long  news_r  \n",
      "10799  한달 소득이 1500만원으로 적지 않지만 교육비로만 400만원이 나가고, 아파트와 ...         long  news_r  \n",
      "\n",
      "[10800 rows x 4 columns]\n",
      "valid short:                                                     src  \\\n",
      "0     조주빈, 25일 오전 포토라인에경찰이 텔레그램 성 착취 대화방을 운영한 ‘박사’ 조...   \n",
      "1     조주빈, 25일 오전 포토라인에경찰이 텔레그램 성 착취 대화방을 운영한 ‘박사’ 조...   \n",
      "2      침구와 함께 린넨 돗자리와 플라스틱 바구니, 수첩과 포스터 등 브랜드 로고를 입힌...   \n",
      "3      침구와 함께 린넨 돗자리와 플라스틱 바구니, 수첩과 포스터 등 브랜드 로고를 입힌...   \n",
      "4      세액공제 받은 금액은 불로소득이 아니라 가입자의 노후를 위해 세금으로 지원해 준다...   \n",
      "...                                                 ...   \n",
      "2695  스웨덴에서는 지갑을 몸에 지니지 않아도 일상생활에 불편을 겪지 않는 이들이 있다.\\...   \n",
      "2696  날 어떻게 찾아냈지?\"미국 기자가 최근 가진 의문이다.\\n  코로나19가 재확산 중...   \n",
      "2697  날 어떻게 찾아냈지?\"미국 기자가 최근 가진 의문이다.\\n  코로나19가 재확산 중...   \n",
      "2698  표심을 잡기 위해 수천만 달러(수백억 원)를 펑펑 쓴다.\\n  북미에선 그 열기가 ...   \n",
      "2699  표심을 잡기 위해 수천만 달러(수백억 원)를 펑펑 쓴다.\\n  북미에선 그 열기가 ...   \n",
      "\n",
      "                                                    tgt summary_type  domain  \n",
      "0     경찰이 텔레그램 성 착취 대화방을 운영한 박사 조 씨의 신상을 공개하며 주민등록 사...        short  news_r  \n",
      "1     조주빈, 25일 오전 포토라인에경찰이 텔레그램 성 착취 대화방을 운영한 ‘박사’ 조...        short  news_r  \n",
      "2     요가복과 운동 용품을 판매하는 매장에서 정기적으로 모임을 여는 커뮤니티 전략을 구사...        short  news_r  \n",
      "3     스포츠웨어 브랜드 ‘룰루레몬’은 커뮤니티 전략을 잘 구사하는 브랜드다. 요가복과 운...        short  news_r  \n",
      "4     퇴직연금펀드의 환매수수료에 대해 인지하지 못한 소비자 민원이 발생됨에 따라 사전에 ...        short  news_r  \n",
      "...                                                 ...          ...     ...  \n",
      "2695  스웨덴에서는 지갑을 몸에 지니지 않아도 일상생활에 불편을 겪지 않는 이들이 있다. ...        short  news_r  \n",
      "2696  기자는 코로나19 검사를 받으라는 중국 보건당국의 연락을 받고 검사 과정을 기사로 ...        short  news_r  \n",
      "2697  자신과 일면식이 없던 중국 보건당국의 연락을 받고 코로나19 검사를 받았다. 기자는...        short  news_r  \n",
      "2698  좋은 결과를 얻는다면 한국영화 산업 측면에서 의미가 있을 거라고 봉감독이 말했던 아...        short  news_r  \n",
      "2699  아카데미 시상식은 미국에서만 매해 2000여만 명이 시청하는 등 전 세계 이목이 쏠...        short  news_r  \n",
      "\n",
      "[2700 rows x 4 columns]\n",
      "valid long:                                                     src  \\\n",
      "0     옵티머스자산운용이 대규모 환매중단 사태가 발생하기 전 주요 시중은행에도 “펀드 판매...   \n",
      "1     미국 대통령 선거에 출사표를 던진 마이클 블룸버그 전 뉴욕 시장이 '본격 등판'을 ...   \n",
      "2     강남구 논현동에 위치한 스타트업 '필드쉐어'는 오는 4~5월이 고비다.\\n  스포츠...   \n",
      "3      4월 18일에는 홍콩 경찰이 지난해 시위 가담을 이유로 범민주파 중진 15인을 한...   \n",
      "4      시인·소설가·문학평론가 등으로 구성된 선정위원회가 구성돼 있다.\\n  30자 안팎...   \n",
      "...                                                 ...   \n",
      "1345  지난 6일 서울고등법원의 미국 송환 불허 결정으로 석방된 세계 최대 아동 성착취 음...   \n",
      "1346  북한이 노동당 창건 75주년인 10일 새벽 0시 평양 김일성 광장에서 병력과 장비를...   \n",
      "1347   온·오프라인으로 병행하여 진행되는 이번 포럼은 ‘인공지능(AI) 국가전략’에 따른...   \n",
      "1348  10년간 임대료 인상 없이 한 집에서 살 수 있다면.\\n  쉼터도, 일터도 될 수 ...   \n",
      "1349  코로나19 팬데믹이 전 세계를 덮친 지난 봄, 글로벌 명품 업계가 술렁였다.\\n  ...   \n",
      "\n",
      "                                                    tgt summary_type  domain  \n",
      "0     21일 은행업계에 따르면 옵티머스운용은 2018~2019년에 걸쳐 복수의 주요 시중...         long  news_r  \n",
      "1     블룸버그는 아이오와·뉴햄프셔 등 첫 4개 경선을 건너뛰고 다음 달 3일 열리는 '수...         long  news_r  \n",
      "2     매출이 증가한 배달·온라인쇼핑 등 비대면 업종도 상황을 낙관하긴 힘들다. 단기적으로...         long  news_r  \n",
      "3     중련판 주임으로 부임한 뤄후이닝이 홍콩 야당의 필리버스터를 비난하고 국가보안법을 제...         long  news_r  \n",
      "4     계절 감각에 맞게 봄철에는 주로 생명과 희망의 메시지로 전해왔다. 고은 시인의 ‘떠...         long  news_r  \n",
      "...                                                 ...          ...     ...  \n",
      "1345  지난 6일 서울고등법원의 미국 송환 불허 결정으로 석방된 세계 최대 아동 성착취 음...         long  news_r  \n",
      "1346  북한이 노동당 창건 75주년인 10일 새벽 0시 평양 김일성 광장에서 병력과 장비를...         long  news_r  \n",
      "1347  오산시는 교육을 기반으로 한 AI특별도시로 거듭나기 위해 4차 산업혁명시대에 부응하...         long  news_r  \n",
      "1348  서울 은평구 응암동에 신축한 ‘풍년 빌라’의 이야기다. 풍년빌라에는 보증금이 없다....         long  news_r  \n",
      "1349  코로나19 사태가 여전히 진행 중인 지금, 글로벌 명품 브랜드들이 중국 라이브커머스...         long  news_r  \n",
      "\n",
      "[1350 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 전처리 - AI HUB 요약문 및 레포트 뉴스(news) 데이터셋 적용\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 기본 경로\n",
    "base_dir = './llm_data/ai_hub_summary_news_r'\n",
    "\n",
    "def parse_json_folder(input_dir, summary_type):\n",
    "    rows = []\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if not file_name.endswith('.json'):\n",
    "            continue\n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        passage = data['Meta(Refine)']['passage']\n",
    "        doc_type = data['Meta(Acqusition)']['doc_type']\n",
    "\n",
    "        if summary_type == 'short':\n",
    "            for key in ['summary1', 'summary2']:\n",
    "                summary = data['Annotation'].get(key)\n",
    "                if summary:\n",
    "                    rows.append({\n",
    "                        'src': passage,\n",
    "                        'tgt': summary,\n",
    "                        'summary_type': 'short',\n",
    "                        'domain': doc_type\n",
    "                    })\n",
    "        elif summary_type == 'long':\n",
    "            summary3 = data['Annotation'].get('summary3')\n",
    "            if summary3:\n",
    "                rows.append({\n",
    "                    'src': passage,\n",
    "                    'tgt': summary3,\n",
    "                    'summary_type': 'long',\n",
    "                    'domain': doc_type\n",
    "                })\n",
    "    # 판다스 데이터프레이으로 생성 후 리턴\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# 학습 데이터 로딩\n",
    "train_short = parse_json_folder(os.path.join(base_dir, 'train/2-3sent'), 'short')\n",
    "train_long = parse_json_folder(os.path.join(base_dir, 'train/20per'), 'long')\n",
    "\n",
    "# 검증 데이터 로딩\n",
    "valid_short = parse_json_folder(os.path.join(base_dir, 'valid/2-3sent'), 'short')\n",
    "valid_long = parse_json_folder(os.path.join(base_dir, 'valid/20per'), 'long')\n",
    "\n",
    "# 확인\n",
    "print('train short:', train_short)\n",
    "print('train long:', train_long)\n",
    "print('valid short:', valid_short)\n",
    "print('valid long:', valid_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae92a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 저장 완료: train/valid 데이터셋 분리 저장\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 저장\n",
    "train_short.to_csv(os.path.join(base_dir, 'train/2-3sent/train.csv'), index=False, encoding='utf-8-sig')\n",
    "train_long.to_csv(os.path.join(base_dir, 'train/20per/train.csv'), index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 검증 데이터 저장\n",
    "valid_short.to_csv(os.path.join(base_dir, 'valid/2-3sent/valid.csv'), index=False, encoding='utf-8-sig')\n",
    "valid_long.to_csv(os.path.join(base_dir, 'valid/20per/valid.csv'), index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"CSV 저장 완료: train/valid 데이터셋 분리 저장\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c86be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 584,170,752 || trainable%: 0.3029\n"
     ]
    }
   ],
   "source": [
    "# 모델 & 토크나이저 로드\n",
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# 베이스 모델명\n",
    "model_name = \"google/mt5-base\"\n",
    "# 토크나이저\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "# 모델\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# LoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,   # mT5는 Seq2Seq 구조\n",
    "    r=16,                              # 랭크 (작을수록 가볍고 빠름)\n",
    "    lora_alpha=32,                     # LoRA scaling factor\n",
    "    lora_dropout=0.1,                  # 드롭아웃\n",
    "    target_modules=[\"q\", \"v\"]          # 주로 attention의 query, value projection에 적용\n",
    ")\n",
    "\n",
    "# 기존 베이스 mT5 모델에 LoRA 적용\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 적용 확인\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# trainable params: 1,769,472 || all params: 584,170,752 || trainable%: 0.3029\n",
    "# 전체 파라미터 수: 약 5억 8천만 개 (mT5-base 전체 크기)\n",
    "# 학습 가능한 파라미터 수: 약 176만 개\n",
    "# 학습 비율: 약 0.3%만 학습 → 나머지는 고정(frozen)\n",
    "# 즉, LoRA 덕분에 전체 모델을 학습시키지 않고도 극히 일부 모듈만 학습해서 GPU 메모리와 시간 절약이 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89422158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # m5T 간단 test\n",
    "\n",
    "# # 입력(한국어 요약 테스트)\n",
    "# src_text = \"오거돈 전 부산시장의 성추행 사건이 불거진 후 정치권을 중심으로...\"\n",
    "# inputs = tokenizer(src_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "\n",
    "# # 타겟 요약(학습시 필요) - 정답 요약문을 토큰화, 학습시 labels를 이용해 모델이 출력과 비교하여 loss 계산\n",
    "# labels = tokenizer(\"오 전 부산시장의 성추행 사건이 불거졌다.\", return_tensors='pt', max_length=128, truncation=True).input_ids\n",
    "\n",
    "# # Forward pass\n",
    "# outputs = model(**inputs, labels=labels) # 입력과 정답 요약을 모델에 전달\n",
    "# loss = outputs.loss # CrossEntropy Loss 값, 모델이 얼마나 잘 요약했는지 측정\n",
    "\n",
    "# # 요약 생성(추론), 학습된 모델을 이용해 요약문 생성, 첫 단어를 예측할때 상위 4개 후보를 선택\n",
    "# summary_ids = model.generate(inputs['input_ids'], max_length=128, num_beams=4)\n",
    "# # 텍스트로 변환, <pad>/<eos> 같은 특수 토큰 제거\n",
    "# print(tokenizer.decode(summary_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "804160db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_concat :  200\n",
      "valid_concat :  200\n"
     ]
    }
   ],
   "source": [
    "# CSV 데이터셋 로드\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "# 기본 경로\n",
    "base_dir = './llm_data/ai_hub_summary_news_r'\n",
    "# 전체 데이터셋 로드(short/long 모두 포함)\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files={\n",
    "        'train_short': os.path.join(base_dir, 'train/2-3sent/train.csv'),\n",
    "        'train_long': os.path.join(base_dir, 'train/20per/train.csv'),\n",
    "        'valid_short': os.path.join(base_dir, 'valid/2-3sent/valid.csv'),\n",
    "        'valid_long': os.path.join(base_dir, 'valid/20per/valid.csv')\n",
    "    }\n",
    ")\n",
    "\n",
    "# 두 split을 합쳐서 하나의 데이터셋으로 만들기\n",
    "train_concat = concatenate_datasets([\n",
    "    dataset['train_short'].select(range(100)),\n",
    "    dataset['train_long'].select(range(100))\n",
    "])\n",
    "\n",
    "valid_concat = concatenate_datasets([\n",
    "    dataset['valid_short'].select(range(100)),\n",
    "    dataset['valid_long'].select(range(100))\n",
    "])\n",
    "\n",
    "print('train_concat : ', len(train_concat))\n",
    "print('valid_concat : ', len(valid_concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "648d0d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 200/200 [00:00<00:00, 212.46 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 258.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 전처리 함수 & 데이터셋 토큰화\n",
    "\n",
    "# 데이터셋 전처리\n",
    "def preprocess(batch):\n",
    "    # summary_type을 prefix로 활용\n",
    "    inputs = [ f'[{stype.upper()}] {src}' for src, stype in zip(batch['src'], batch['summary_type'])]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding='max_length')\n",
    "\n",
    "    labels = tokenizer(batch['tgt'], max_length=128, truncation=True, padding='max_length')\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "# 합쳐진 데이터셋에 바로 토큰화 적용\n",
    "tokenized_train = train_concat.map(preprocess, batched=True)\n",
    "tokenized_valid = valid_concat.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35875440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 파이프라인\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# DataCollator 적용\n",
    "# Seq2SeqTrainer에서는 DataCollatorForSeq2Seq를 사용하면 자동으로 길이에 대해서 패딩을 맞춰준다\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "# 학습 설정\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./llm_models/results_lora_ai_hub_news_r\",       # 결과 저장 경로\n",
    "    eval_strategy=\"epoch\",                                      # 매 epoch마다 평가\n",
    "    learning_rate=5e-4,                                         # 학습률, # LoRA는 보통 조금 더 큰 lr 사용 가능\n",
    "    per_device_train_batch_size=16,                              # 학습 배치 크기\n",
    "    per_device_eval_batch_size=16,                               # 검증 배치 크기\n",
    "    num_train_epochs=1,                                         # 학습 epoch 수\n",
    "    weight_decay=0.01,                                          # 가중치 감쇠\n",
    "    save_total_limit=2,                                         # 체크포인트 최대 개수\n",
    "    logging_dir=\"./llm_models/results_lora_logs_ai_hub_news_r\", # 로그 저장 경로\n",
    "    logging_steps=50,                                           # 로그 출력 주기\n",
    "    predict_with_generate=True                                  # 평가 시 generate() 사용\n",
    ")\n",
    "\n",
    "# Trainer 정의\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,    # LoRA 적용 모델\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator     # HuggingFace Trainer는 배치 단위로 묶을 때 모든 시퀀스 길이가 동일하게 맞추기 위함\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "360a456a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 53:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>18.582268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13, training_loss=21.143897423377403, metrics={'train_runtime': 3551.3361, 'train_samples_per_second': 0.056, 'train_steps_per_second': 0.004, 'total_flos': 240896389939200.0, 'train_loss': 21.143897423377403, 'epoch': 1.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 진행\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43af07e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약 결과: <extra_id_0> AI의 윤리적 활용\n"
     ]
    }
   ],
   "source": [
    "# 추론\n",
    "from transformers import pipeline\n",
    "\n",
    "# 학습된 모델과 토크나이저 로드\n",
    "summarizer = pipeline( # Hugging Face pipeline은 모델과 토크나이저를 묶어서 간단히 추론 API\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 테스트 입력 문장\n",
    "test_text = \"\"\"\n",
    "지난주 열린 국제 AI 컨퍼런스에서는 생성형 AI의 윤리적 활용과\n",
    "기업 내 도입 전략에 대한 다양한 논의가 이루어졌다.\n",
    "특히 데이터 프라이버시와 저작권 문제에 대한 해결책이 주요 의제로 다뤄졌다.\n",
    "\"\"\"\n",
    "\n",
    "# 요약 생성\n",
    "# summary = summarizer( # Greedy Decoding (탐욕적 디코딩)\n",
    "#     f\"[SHORT] {test_text}\", # summary_type prefix 활용, prefix([SHORT], [LONG])\n",
    "#     max_length=128,\n",
    "#     min_length=20,\n",
    "#     do_sample=False         # 샘플링 없이 greedy decoding으로 결정적 결과\n",
    "# )\n",
    "# Beam Search (빔 탐색)\n",
    "summary = summarizer(\n",
    "    f\"[SHORT] {test_text}\",\n",
    "    max_length=128,\n",
    "    num_beams=5,      # 빔 개수\n",
    "    early_stopping=True\n",
    ")\n",
    "# Sampling?(샘플링)\n",
    "# summary = summarizer(\n",
    "#     f\"[SHORT] {test_text}\",\n",
    "#     max_length=128,\n",
    "#     do_sample=True,   # 샘플링 켬\n",
    "#     top_k=50,         # 확률 상위 50개 중 선택\n",
    "#     top_p=0.95,       # 누적 확률 95% 내에서 선택\n",
    "#     num_return_sequences=3\n",
    "# )\n",
    "\n",
    "# summary[0] 리스트의 첫 번째 결과 (딕셔너리), summary[0][\"generated_text\"] 딕셔너리 안에서 모델이 실제로 생성한 요약문 텍스트\n",
    "print('요약 결과:', summary[0][\"generated_text\"])\n",
    "# for i, s in enumerate(summary_2):\n",
    "#     print(f\"요약 {i+1}: {s['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81f8931f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./llm_models/summary_model_ai_hub_news_r_lora/tokenizer_config.json',\n",
       " './llm_models/summary_model_ai_hub_news_r_lora/special_tokens_map.json',\n",
       " './llm_models/summary_model_ai_hub_news_r_lora/spiece.model',\n",
       " './llm_models/summary_model_ai_hub_news_r_lora/added_tokens.json')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LoRA 적용된 모델 저장\n",
    "model.save_pretrained(\"./llm_models/summary_model_ai_hub_news_r_lora\")\n",
    "tokenizer.save_pretrained(\"./llm_models/summary_model_ai_hub_news_r_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "646becf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# 모델 로드\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\n",
    "    \"./llm_models/summary_model_ai_hub_news_r_lora\"\n",
    ")\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    \"./llm_models/summary_model_ai_hub_news_r_lora\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d731c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약 결과: <extra_id_0> AI의 윤리적 활용\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드 & 추론\n",
    "from transformers import pipeline\n",
    "\n",
    "# 학습된 모델과 토크나이저 로드\n",
    "summarizer = pipeline( # Hugging Face pipeline은 모델과 토크나이저를 묶어서 간단히 추론 API\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# 테스트 입력 문장\n",
    "test_text = \"\"\"\n",
    "지난주 열린 국제 AI 컨퍼런스에서는 생성형 AI의 윤리적 활용과\n",
    "기업 내 도입 전략에 대한 다양한 논의가 이루어졌다.\n",
    "특히 데이터 프라이버시와 저작권 문제에 대한 해결책이 주요 의제로 다뤄졌다.\n",
    "\"\"\"\n",
    "\n",
    "# 요약 생성\n",
    "# summary = summarizer( # Greedy Decoding (탐욕적 디코딩)\n",
    "#     f\"[SHORT] {test_text}\", # summary_type prefix 활용, prefix([SHORT], [LONG])\n",
    "#     max_length=128,\n",
    "#     min_length=20,\n",
    "#     do_sample=False         # 샘플링 없이 greedy decoding으로 결정적 결과\n",
    "# )\n",
    "# Beam Search (빔 탐색)\n",
    "summary = summarizer(\n",
    "    f\"[SHORT] {test_text}\",\n",
    "    max_length=128,\n",
    "    num_beams=5,      # 빔 개수\n",
    "    early_stopping=True\n",
    ")\n",
    "# Sampling?(샘플링)\n",
    "# summary = summarizer(\n",
    "#     f\"[SHORT] {test_text}\",\n",
    "#     max_length=128,\n",
    "#     do_sample=True,   # 샘플링 켬\n",
    "#     top_k=50,         # 확률 상위 50개 중 선택\n",
    "#     top_p=0.95,       # 누적 확률 95% 내에서 선택\n",
    "#     num_return_sequences=3\n",
    "# )\n",
    "\n",
    "# summary[0] 리스트의 첫 번째 결과 (딕셔너리), summary[0][\"generated_text\"] 딕셔너리 안에서 모델이 실제로 생성한 요약문 텍스트\n",
    "print('요약 결과:', summary[0][\"generated_text\"])\n",
    "# for i, s in enumerate(summary_2):\n",
    "#     print(f\"요약 {i+1}: {s['generated_text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
