# app_10_transfer_learning_model_dog_image.py
# Streamlit ì•± - ê°•ì•„ì§€ ì¢… ë¶„ë¥˜ê¸°

import streamlit as st
import torch
from torchvision import models, transforms
from PIL import Image
import numpy as np
from model_utils import TransferLearningModel  # í˜„ìš©ë‹˜ì´ ë§Œë“  í´ë˜ìŠ¤
import os, json
import pandas as pd

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ ë¡œë”©
@st.cache_resource # - @st.cache_resource: ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë”©í•˜ê³  ìºì‹œí•˜ì—¬ ì•± ì†ë„ í–¥ìƒ
def load_model():
    base_model = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT) # - vit_b_16: Vision Transformer ì‚¬ì „í•™ìŠµ ëª¨ë¸
    model = TransferLearningModel(base_model, feature_extractor=True, num_classes=4).to(device) # - feature_extractor=True: íŠ¹ì§• ì¶”ì¶œê¸°ë¡œ ì‚¬ìš©, num_classes=2: ê°•ì•„ì§€ 4 í´ë˜ìŠ¤

    model_path = os.path.join("models", "model_transfer_learning_dog_image.ckpt") # - í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    if not os.path.exists(model_path):
        st.error(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        st.stop()

    model.load_state_dict(torch.load(model_path, map_location=device)) # - í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    model.eval() # - ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜
    return model

model = load_model()

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def detect_and_preprocess(image):
    import cv2
    from PIL import Image
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    img_cv = np.array(image)
    gray = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.1, 4)

    if len(faces) == 0:
        return preprocess_image(image)  # fallback: ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©

    x, y, w, h = faces[0]
    face_img = img_cv[y:y+h, x:x+w]
    face_pil = Image.fromarray(face_img)
    return preprocess_image(face_pil)

def preprocess_image(image):
    transform = transforms.Compose([
        transforms.Resize((224, 224)), # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 224Ã—224ë¡œ ì¡°ì • (ViT ì…ë ¥ í¬ê¸°)
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    return transform(image).unsqueeze(0).to(device) # - unsqueeze(0): ë°°ì¹˜ ì°¨ì› ì¶”ê°€ â†’ [1, 3, 224, 224], ë°°ì¹˜ ì°¨ì› ì¶”ê°€ ë° ë””ë°”ì´ìŠ¤ë¡œ ì´ë™

# ì˜ˆì¸¡ í•¨ìˆ˜
def predict(image_tensor):
    with torch.no_grad(): # - ì¶”ë¡  ì‹œì—ëŠ” ê¸°ìš¸ê¸° ê³„ì‚° ë¶ˆí•„ìš”
        outputs = model(image_tensor) # - ëª¨ë¸ì— ì´ë¯¸ì§€ í…ì„œ ì…ë ¥
        probabilities = torch.nn.functional.softmax(outputs, dim=1) # - ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¡œ í™•ë¥  ê³„ì‚°
        predicted = torch.argmax(probabilities, dim=1).item() # - ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ í´ë˜ìŠ¤ ì„ íƒ
        probabilities = probabilities.cpu().numpy()[0] # - í™•ë¥ ì„ CPUë¡œ ì˜®ê¸°ê³  numpy ë°°ì—´ë¡œ ë³€í™˜
    return predicted, probabilities # - ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ ë°˜í™˜ (0~3), ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë°°ì—´ ë°˜í™˜

# ë¼ë²¨ ë§µ ë¡œë”© - labels_map.json íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ì™€ ê°•ì•„ì§€ ì´ë¦„ ë§¤í•‘
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
labels_path = os.path.join(BASE_DIR, 'labels_map.json') # ì˜ˆ: í´ë˜ìŠ¤ ì¸ë±ìŠ¤ â†’ ê°•ì•„ì§€ ì´ë¦„

if not os.path.exists(labels_path): # labels_map.json íŒŒì¼ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
    st.error(f"labels_map.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {labels_path}")
    st.stop() # - íŒŒì¼ì´ ì—†ìœ¼ë©´ ì•± ì¤‘ì§€

with open(labels_path, 'r') as f: # - labels_map.json íŒŒì¼ ì—´ê¸°
    labels_map = {int(k):v for k, v in json.load(f).items()} # - JSON íŒŒì¼ì—ì„œ ë”•ì…”ë„ˆë¦¬ë¡œ ë¡œë“œ, í‚¤ë¥¼ intë¡œ ë³€í™˜

# Streamlit UI
st.title("ê°•ì•„ì§€ ì¢… ë¶„ë¥˜ê¸°") # - ì•± ì œëª©
st.write("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ë¬´ìŠ¨ ê°•ì•„ì§€ì¸ì§€ ì˜ˆì¸¡í•´ì¤ë‹ˆë‹¤!") # - ì•± ì„¤ëª…

# ë‹¨ì¼ ì´ë¯¸ì§€ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png" ]) # - íŒŒì¼ ì—…ë¡œë”
if uploaded_file is not None: # - íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆì„ ë•Œ
    image = Image.open(uploaded_file).convert("RGB") # - ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜
    # st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)
    st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True) # - use_container_width=True: ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ê²Œ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •

    try:
        image_tensor = preprocess_image(image) # - ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        # image_tensor = detect_and_preprocess(image) # - ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        prediction, probabilities = predict(image_tensor) # - ì˜ˆì¸¡ ìˆ˜í–‰
        label = labels_map[prediction]

        emoji_map = {
            "Chihuahua": "ğŸ•",
            "jindo_dog": "ğŸ¦®",
            "shepherd": "ğŸ¶",
            "yorkshire_terrier": "ğŸ©"
        }
        st.success(f'ì˜ˆì¸¡ ê²°ê³¼: **{label}** {emoji_map.get(label, "")}')

        st.subheader("ì˜ˆì¸¡ í™•ë¥ ")
        st.bar_chart( {labels_map[i]: prob for i, prob in enumerate(probabilities)} )
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ì›¹ìº  ì…ë ¥
camera_image = st.camera_input("ğŸ“· ì›¹ìº ìœ¼ë¡œ ì‚¬ì§„ ì´¬ì˜")

if camera_image is not None:
    image = Image.open(camera_image).convert("RGB")
    st.image(image, caption="ì´¬ì˜ëœ ì´ë¯¸ì§€", use_container_width=True)

    try:
        image_tensor = preprocess_image(image) # - ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        # image_tensor = detect_and_preprocess(image) # - ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        prediction, probabilities = predict(image_tensor)
        label = labels_map[prediction]

        emoji_map = {
            "Chihuahua": "ğŸ•",
            "jindo_dog": "ğŸ¦®",
            "shepherd": "ğŸ¶",
            "yorkshire_terrier": "ğŸ©"
        }
        st.success(f'ì˜ˆì¸¡ ê²°ê³¼: **{label}** {emoji_map.get(label, "")}')

        st.subheader("ì˜ˆì¸¡ í™•ë¥ ")
        st.bar_chart({labels_map[i]: prob for i, prob in enumerate(probabilities)})
    except Exception as e:
        st.error(f"ì›¹ìº  ì˜ˆì¸¡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ë‹¤ì¤‘ ì´ë¯¸ì§€ ì—…ë¡œë“œ (ì˜µì…˜)
uploaded_files = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—¬ëŸ¬ ì¥ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

if uploaded_files:
    results = []  # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    st.write(f"{len(uploaded_files)}ê°œì˜ ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    for uploaded_file in uploaded_files:
        image = Image.open(uploaded_file).convert("RGB")
        st.image(image, caption=uploaded_file.name, use_container_width=True)

        try:
            image_tensor = preprocess_image(image) # - ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            # image_tensor = detect_and_preprocess(image) # - ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            prediction, probabilities = predict(image_tensor)
            label = labels_map[prediction]

            emoji_map = {
                "Chihuahua": "ğŸ•",
                "jindo_dog": "ğŸ¦®",
                "shepherd": "ğŸ¶",
                "yorkshire_terrier": "ğŸ©"
            }
            st.success(f'ì˜ˆì¸¡ ê²°ê³¼: **{label}** {emoji_map.get(label, "")}')
            # ê²°ê³¼ ì €ì¥
            results.append({
                "íŒŒì¼ëª…": uploaded_file.name,
                "ì˜ˆì¸¡ í´ë˜ìŠ¤": label,
                "í™•ë¥ ": f"{probabilities[prediction]:.4f}"
            })
            st.bar_chart({labels_map[i]: prob for i, prob in enumerate(probabilities)})
        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    if results:
        import pandas as pd
        df = pd.DataFrame(results)
        st.subheader("ğŸ“„ ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½")
        st.dataframe(df)

        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button(
            label="ğŸ“¥ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name="prediction_results.csv",
            mime="text/csv"
        )

st.markdown("---")
st.caption("Powered by Vision Transformer (ViT) + Transfer Learning")